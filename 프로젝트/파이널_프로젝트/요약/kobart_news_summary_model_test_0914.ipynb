{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"mQKDlSmxVVr3","executionInfo":{"status":"ok","timestamp":1694690567831,"user_tz":-540,"elapsed":4946,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}}},"outputs":[],"source":["!pip install accelerate>=0.20.1"]},{"cell_type":"markdown","source":["# 필요한 모듈 install"],"metadata":{"id":"3dT4v3a_aZMi"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"wkMpgdZzVfVN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1694690597711,"user_tz":-540,"elapsed":29886,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"61cc7073-b99c-420b-f8c7-9efeecd4f849"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"nsKTJfE8VgNK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1694690614831,"user_tz":-540,"elapsed":17128,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"6ede185e-d64f-4e55-e41b-24a8a2264f88"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.33.1-py3-none-any.whl (7.6 MB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/7.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/7.6 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/7.6 MB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m84.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n","Collecting huggingface-hub<1.0,>=0.15.1 (from transformers)\n","  Downloading huggingface_hub-0.17.1-py3-none-any.whl (294 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.8/294.8 kB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m107.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n","  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m81.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n","Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.17.1 safetensors-0.3.3 tokenizers-0.13.3 transformers-4.33.1\n","Collecting pytorch-lightning\n","  Downloading pytorch_lightning-2.0.8-py3-none-any.whl (727 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m727.0/727.0 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (1.23.5)\n","Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2.0.1+cu118)\n","Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.66.1)\n","Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (6.0.1)\n","Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2023.6.0)\n","Collecting torchmetrics>=0.7.0 (from pytorch-lightning)\n","  Downloading torchmetrics-1.1.2-py3-none-any.whl (764 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m764.8/764.8 kB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (23.1)\n","Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.5.0)\n","Collecting lightning-utilities>=0.7.0 (from pytorch-lightning)\n","  Downloading lightning_utilities-0.9.0-py3-none-any.whl (23 kB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (2.31.0)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (3.8.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning) (3.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.11.0->pytorch-lightning) (3.27.4.1)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.11.0->pytorch-lightning) (16.0.6)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (3.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (4.0.3)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.3.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->pytorch-lightning) (2.1.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (2023.7.22)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->pytorch-lightning) (1.3.0)\n","Installing collected packages: lightning-utilities, torchmetrics, pytorch-lightning\n","Successfully installed lightning-utilities-0.9.0 pytorch-lightning-2.0.8 torchmetrics-1.1.2\n"]}],"source":[" !pip install transformers\n"," !pip install pytorch-lightning"]},{"cell_type":"code","source":["from transformers import (\n","    AutoModelForSeq2SeqLM,\n","    AutoTokenizer,\n","    Seq2SeqTrainingArguments,\n","    Seq2SeqTrainer,\n","    DataCollatorForSeq2Seq,\n","    BartConfig\n",")\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader, Dataset\n","import pandas as pd"],"metadata":{"id":"VcgWlnZLA4Ex","executionInfo":{"status":"ok","timestamp":1694690623311,"user_tz":-540,"elapsed":8484,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["# 데이터 로드 - 데이터 개수 110개 - train:100, val:10"],"metadata":{"id":"a5rwJChqHobs"}},{"cell_type":"code","execution_count":81,"metadata":{"id":"K4uY9GJLVhG4","executionInfo":{"status":"ok","timestamp":1694698742232,"user_tz":-540,"elapsed":5940,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}}},"outputs":[],"source":["import pandas as pd\n","train_df = pd.read_csv('/content/drive/MyDrive/data/news_summary_train_dataset.tsv', sep='\\t')\n","df = train_df[:110]"]},{"cell_type":"markdown","source":["# 모델, tokenizer 설정"],"metadata":{"id":"dBNWzu5RHuJ1"}},{"cell_type":"code","execution_count":6,"metadata":{"id":"WSQ6VN52VjRR","colab":{"base_uri":"https://localhost:8080/","height":216,"referenced_widgets":["6e2ad56f06e84030a2bf00398cbc5ad0","db658122d53041d7ad0e953f105594d6","7af3225744604a75a3b46dcadb463cd8","8582a9fda231494ea4e6d6d9a58a46cd","ec06c561b3c94c6b85ca0f6af95470ef","95f2fe0bcf9344e2babd7cb90fc1e75a","f81824342be344eabf57b0019f60bed1","7fe97d07911e40048e7d252509b91a70","4c02092915ae44f7b2957a6ab6cb5a64","fbb3654848024b99b4792c44afed0e2f","251ea3d4b57046ee8fd25a1b21152522","942cb6366cfe4bb497686e1b59811a95","48d5c881418846bb96af1a2b5552184e","a5a3e017ee9e4a0ba53caefb9112de4f","bfa2ec05b4eb4399861e702ff854c326","7708b7c352a44c1f9ee41599b714fa7b","269c28039a104f51be21a109a184083f","deac5c3f67be443f86b9001f7daf7e67","29156a01afb34329a42e7514f3c34271","b2a53188d2714013b4eb17f90ec8bb7b","69de46f44a5944f5b9018e20e4fe70a6","db36fd1a71e7494cbb1301b2eae071e6","71f652929bed4483ba70809bbc9d0f07","459d960d9f084f75bda05d5bb446aeaf","6adfb0880b644929a16f60600685d5f1","4ab123dc0418453785b7ad2d038385d5","e7e00598d84b431194c6cdc6aa337ac2","fc0e1b33215544ba9edca14f102ff45b","12862119406e4084b1652f109c47b9a1","3b639f8e32fe406880deaa01a70a68a0","3a87dde0315d4c72b0c0d00c0a0e252c","221fd0d2481549a59c1f2d1ec6fecf7c","06a905f1dfae4e7fbcb61f10d5365367","8f6b988cc4ca4eb1b27720fb09ac66a2","c164c1c7a99149a5a60d9fd4c16ba89c","9fc3f619b3d04b4e855cb1053d49b4f6","5a5387c3da3049359bb77b1e650a02f6","d940ad4942154b5493540ecec944d849","1fa20d4ec57044cd8d7aa78d4de50a4d","f5007bdb517144ec9b3f589f7f1c9e30","8ba71a9c7af641dfbc91d721725c09ab","749a1216f3464607bfb8698b45c7ab9e","0180fca78054435fb75f29c86e07f939","51f4514e7faf4705be4b93faa0fe6170","778e352793a849cb904efd98db81f1c8","af496a8eadfa43ef8c38a74b7fe997c7","9c5d2adf0f23412281ba26da08f48199","a6a5a6da8d1c43c982dadbea51b31b60","559c7e2874ae4e08a2b79a8483368d03","00ec86ecad5f4c6b8f2f209d02432fe3","e4f1f436006c48b998ebe30eb5403d60","8e79483cb87a402a9de7564801f02512","9d977f90a9bb463096fde8a5f2139c34","7a4427c9ccb842b5a077d46138bbc4e2","3eb82072782d4b3d94dccdd66d22e0f1"]},"executionInfo":{"status":"ok","timestamp":1694690640235,"user_tz":-540,"elapsed":8182,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"e2d66226-7d39-459b-bfc7-988c928b89b9"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/295 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e2ad56f06e84030a2bf00398cbc5ad0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)/main/tokenizer.json:   0%|          | 0.00/682k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"942cb6366cfe4bb497686e1b59811a95"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)cial_tokens_map.json:   0%|          | 0.00/109 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"71f652929bed4483ba70809bbc9d0f07"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/1.20k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f6b988cc4ca4eb1b27720fb09ac66a2"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/496M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"778e352793a849cb904efd98db81f1c8"}},"metadata":{}}],"source":["model_name = 'digit82/kobart-summarization'\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"]},{"cell_type":"markdown","source":["# 데이터 전처리\n","- target 데이터에 bos, eos 붙이기\n","- max_length : 1024"],"metadata":{"id":"Z6mM0ZstH_R6"}},{"cell_type":"code","execution_count":82,"metadata":{"id":"KS2MRypDVyB3","executionInfo":{"status":"ok","timestamp":1694698742233,"user_tz":-540,"elapsed":5,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}}},"outputs":[],"source":["class CustomDataset(Dataset):\n","    def __init__(self, data, tokenizer, num_data=None, max_length=1024):\n","        self.num_data = num_data\n","        self.max_length = max_length\n","        self.data = data[:num_data]\n","        self.tokenizer = tokenizer\n","        self.input_tokenized, self.target_tokenized = self.tokenizing()\n","\n","    def tokenizing(self):\n","        input_tokenized = []\n","        target_tokenized = []\n","\n","        for i in range(len(self.data)):\n","            input_text = self.data.iloc[i, 0]\n","            target_text = self.data.iloc[i, 1]\n","\n","            input_ids = self.tokenizer(input_text, padding=\"max_length\", max_length=self.max_length, truncation=True)[\"input_ids\"]\n","            target_ids = self.tokenizer('<s>' + target_text + '</s>', padding=\"max_length\", max_length=self.max_length, truncation=True)[\"input_ids\"]\n","\n","            input_tokenized.append(input_ids)\n","            target_tokenized.append(target_ids)\n","\n","        return torch.LongTensor(input_tokenized), torch.LongTensor(target_tokenized)\n","\n","    def __len__(self):\n","        return len(self.input_tokenized)\n","\n","    def __getitem__(self, idx):\n","        return {\n","            'input_ids': self.input_tokenized[idx],\n","            'labels': self.target_tokenized[idx]\n","        }"]},{"cell_type":"code","execution_count":83,"metadata":{"id":"o7Nd9BlfVytf","executionInfo":{"status":"ok","timestamp":1694698742707,"user_tz":-540,"elapsed":477,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}}},"outputs":[],"source":["data_train = df.iloc[:100, :]\n","data_val = df.iloc[100:110, :]\n","\n","dataset_train = CustomDataset(data_train,tokenizer=tokenizer)\n","dataset_val = CustomDataset(data_val,tokenizer=tokenizer)"]},{"cell_type":"code","source":["dataset_train[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6THiYe0rQSUf","executionInfo":{"status":"ok","timestamp":1694697608168,"user_tz":-540,"elapsed":503,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"2a414f70-e118-495f-ac95-79d8c1f1e069"},"execution_count":72,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': tensor([15634, 11764, 16186,  ...,     3,     3,     3]),\n"," 'labels': tensor([    0, 15529,   271,  ...,     3,     3,     3])}"]},"metadata":{},"execution_count":72}]},{"cell_type":"code","source":["dataset_val[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KlR2xYKTQWxW","executionInfo":{"status":"ok","timestamp":1694697608731,"user_tz":-540,"elapsed":2,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"e76fe5c8-38fe-4fe1-ab48-88edf74385ec"},"execution_count":73,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': tensor([14437, 15639, 16415,  ...,     3,     3,     3]),\n"," 'labels': tensor([    0, 14140, 17954,  ...,     3,     3,     3])}"]},"metadata":{},"execution_count":73}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qJf6m07yV1zQ"},"outputs":[],"source":["# # from torch.utils.data import DataLoader\n","\n","# # train_dataset = CustomDataset(input_train, output_train)\n","# # test_dataset = CustomDataset(input_test,output_test)\n","\n","# # dl_train = DataLoader(train_dataset, batch_size=5, shuffle=False)\n","# # dl_test = DataLoader(test_dataset, batch_size=5, shuffle=False)\n","\n","# train_dataset = CustomDataset(input_train, output_train)\n","# test_dataset = CustomDataset(input_test,output_test)"]},{"cell_type":"code","execution_count":49,"metadata":{"id":"LAmZ3e6hV2k3","colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"status":"ok","timestamp":1694693430875,"user_tz":-540,"elapsed":4,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"d7164b1b-5490-4cb5-dd0b-0b917f4b2cd4"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'cuda'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":49}],"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","device"]},{"cell_type":"code","source":["torch.cuda.empty_cache()"],"metadata":{"id":"zfamcVq6JMNW","executionInfo":{"status":"ok","timestamp":1694693651874,"user_tz":-540,"elapsed":2,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}}},"execution_count":59,"outputs":[]},{"cell_type":"markdown","source":["# Fine-Tuning\n","- decoder_layers : 디코더 개수\n","- lm_head : 마지막 linear 레이어"],"metadata":{"id":"WuvpzS9XR2rD"}},{"cell_type":"code","source":["class CustomModel(nn.Module):\n","  def __init__(self, model_name, decoder_layers=6, lm_head=None, dropout=None):\n","    super().__init__()\n","\n","    config = BartConfig.from_pretrained(model_name)\n","\n","    config.decoder_layers = decoder_layers\n","\n","    self.model = AutoModelForSeq2SeqLM.from_pretrained(model_name, config = config)\n","\n","    if lm_head:\n","      self.model.lm_head = lm_head\n","\n","    if dropout:\n","      self.model.dropout = dropout\n","\n","    # encoder freezing\n","    for param in self.model.get_encoder().parameters():\n","        param.requires_grad = False\n","\n","  def return_model(self):\n","      return self.model"],"metadata":{"id":"zf5e4DQIR15Z","executionInfo":{"status":"ok","timestamp":1694693706728,"user_tz":-540,"elapsed":515,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}}},"execution_count":60,"outputs":[]},{"cell_type":"code","source":["# custom_fc = nn.Sequential(nn.Linear(in_features = 768, out_features = 2048, bias = False),\n","#                                     nn.ReLU(),\n","#                                     nn.Linear(in_features=2048, out_features=30000, bias = False))"],"metadata":{"id":"i1gHr3MtSc2q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Model set\n","- model1 : 6개 디코더 그대로\n","- model2 : 1개 디코더 + fclayer 수정 (768 -> 2048 ->30000)\n","- model3 : 2개 디코더 + fclayer 수정 (768 -> 2048 ->30000)"],"metadata":{"id":"-LZRAwkfSzsR"}},{"cell_type":"code","source":["model1 = CustomModel(model_name = model_name).return_model()\n","model2 = CustomModel(model_name = model_name, decoder_layers=1, lm_head = custom_fc).return_model()\n","model3 =  CustomModel(model_name = model_name, decoder_layers=2, lm_head = custom_fc).return_model()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CWRQN1cwSBXT","executionInfo":{"status":"ok","timestamp":1694654712489,"user_tz":-540,"elapsed":5548,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"71423cea-68c9-4176-8aca-f9436a959171"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n","You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n","Some weights of the model checkpoint at digit82/kobart-summarization were not used when initializing BartForConditionalGeneration: ['model.decoder.layers.3.self_attn.out_proj.weight', 'model.decoder.layers.3.self_attn_layer_norm.bias', 'model.decoder.layers.2.encoder_attn.q_proj.bias', 'model.decoder.layers.1.encoder_attn.v_proj.weight', 'model.decoder.layers.1.self_attn.q_proj.weight', 'model.decoder.layers.3.encoder_attn.v_proj.bias', 'model.decoder.layers.5.self_attn.k_proj.bias', 'model.decoder.layers.5.encoder_attn.q_proj.weight', 'model.decoder.layers.1.encoder_attn.k_proj.bias', 'model.decoder.layers.5.self_attn.out_proj.bias', 'model.decoder.layers.4.fc2.weight', 'model.decoder.layers.3.self_attn_layer_norm.weight', 'model.decoder.layers.1.self_attn.v_proj.bias', 'model.decoder.layers.4.encoder_attn.k_proj.weight', 'model.decoder.layers.3.fc2.weight', 'model.decoder.layers.1.encoder_attn.v_proj.bias', 'model.decoder.layers.5.encoder_attn_layer_norm.bias', 'model.decoder.layers.2.self_attn.q_proj.bias', 'model.decoder.layers.3.encoder_attn.out_proj.weight', 'model.decoder.layers.5.encoder_attn.v_proj.bias', 'model.decoder.layers.1.encoder_attn.out_proj.weight', 'model.decoder.layers.2.encoder_attn_layer_norm.weight', 'model.decoder.layers.5.fc1.bias', 'model.decoder.layers.4.self_attn.v_proj.bias', 'model.decoder.layers.2.self_attn.out_proj.weight', 'model.decoder.layers.2.encoder_attn.k_proj.bias', 'model.decoder.layers.3.encoder_attn.q_proj.weight', 'model.decoder.layers.4.self_attn_layer_norm.weight', 'model.decoder.layers.5.encoder_attn.v_proj.weight', 'model.decoder.layers.4.encoder_attn.q_proj.bias', 'model.decoder.layers.4.self_attn.q_proj.weight', 'model.decoder.layers.5.encoder_attn.k_proj.bias', 'model.decoder.layers.4.encoder_attn_layer_norm.bias', 'model.decoder.layers.1.self_attn.q_proj.bias', 'model.decoder.layers.2.self_attn.k_proj.weight', 'model.decoder.layers.4.encoder_attn.v_proj.weight', 'model.decoder.layers.4.fc2.bias', 'model.decoder.layers.1.self_attn.out_proj.weight', 'model.decoder.layers.2.self_attn.out_proj.bias', 'model.decoder.layers.1.fc1.weight', 'model.decoder.layers.4.encoder_attn.out_proj.weight', 'model.decoder.layers.4.encoder_attn.q_proj.weight', 'model.decoder.layers.5.fc1.weight', 'model.decoder.layers.5.self_attn_layer_norm.bias', 'model.decoder.layers.3.self_attn.v_proj.bias', 'model.decoder.layers.4.self_attn.k_proj.bias', 'model.decoder.layers.1.self_attn_layer_norm.weight', 'model.decoder.layers.3.encoder_attn.q_proj.bias', 'model.decoder.layers.5.self_attn.k_proj.weight', 'model.decoder.layers.5.self_attn_layer_norm.weight', 'model.decoder.layers.3.encoder_attn.k_proj.weight', 'model.decoder.layers.4.encoder_attn.out_proj.bias', 'model.decoder.layers.3.final_layer_norm.bias', 'model.decoder.layers.3.encoder_attn_layer_norm.weight', 'model.decoder.layers.3.final_layer_norm.weight', 'model.decoder.layers.3.encoder_attn_layer_norm.bias', 'model.decoder.layers.4.self_attn.q_proj.bias', 'model.decoder.layers.4.self_attn.out_proj.bias', 'model.decoder.layers.1.encoder_attn.k_proj.weight', 'model.decoder.layers.2.self_attn.k_proj.bias', 'model.decoder.layers.2.final_layer_norm.weight', 'model.decoder.layers.3.self_attn.k_proj.bias', 'model.decoder.layers.2.encoder_attn.q_proj.weight', 'model.decoder.layers.1.encoder_attn.q_proj.bias', 'model.decoder.layers.2.final_layer_norm.bias', 'model.decoder.layers.3.self_attn.v_proj.weight', 'model.decoder.layers.3.self_attn.q_proj.bias', 'model.decoder.layers.5.encoder_attn.out_proj.bias', 'model.decoder.layers.1.self_attn.k_proj.bias', 'model.decoder.layers.1.self_attn.out_proj.bias', 'model.decoder.layers.5.final_layer_norm.weight', 'model.decoder.layers.4.self_attn.v_proj.weight', 'model.decoder.layers.1.fc2.bias', 'model.decoder.layers.2.encoder_attn.v_proj.bias', 'model.decoder.layers.3.encoder_attn.k_proj.bias', 'model.decoder.layers.5.encoder_attn.q_proj.bias', 'model.decoder.layers.2.self_attn.q_proj.weight', 'model.decoder.layers.5.fc2.weight', 'model.decoder.layers.1.final_layer_norm.bias', 'model.decoder.layers.2.encoder_attn.out_proj.weight', 'model.decoder.layers.5.self_attn.q_proj.weight', 'model.decoder.layers.3.fc1.weight', 'model.decoder.layers.2.self_attn_layer_norm.weight', 'model.decoder.layers.2.fc1.weight', 'model.decoder.layers.2.encoder_attn_layer_norm.bias', 'model.decoder.layers.1.self_attn.v_proj.weight', 'model.decoder.layers.2.encoder_attn.v_proj.weight', 'model.decoder.layers.3.fc1.bias', 'model.decoder.layers.4.self_attn.out_proj.weight', 'model.decoder.layers.3.self_attn.out_proj.bias', 'model.decoder.layers.3.self_attn.q_proj.weight', 'model.decoder.layers.5.fc2.bias', 'model.decoder.layers.2.fc1.bias', 'model.decoder.layers.3.encoder_attn.v_proj.weight', 'model.decoder.layers.1.self_attn_layer_norm.bias', 'model.decoder.layers.1.encoder_attn.q_proj.weight', 'model.decoder.layers.1.fc2.weight', 'model.decoder.layers.4.encoder_attn_layer_norm.weight', 'model.decoder.layers.1.encoder_attn_layer_norm.weight', 'model.decoder.layers.4.encoder_attn.k_proj.bias', 'model.decoder.layers.1.encoder_attn_layer_norm.bias', 'model.decoder.layers.2.fc2.weight', 'model.decoder.layers.4.fc1.weight', 'model.decoder.layers.5.self_attn.q_proj.bias', 'model.decoder.layers.2.self_attn.v_proj.bias', 'model.decoder.layers.5.self_attn.v_proj.bias', 'model.decoder.layers.5.self_attn.v_proj.weight', 'model.decoder.layers.3.self_attn.k_proj.weight', 'model.decoder.layers.1.encoder_attn.out_proj.bias', 'model.decoder.layers.2.encoder_attn.k_proj.weight', 'model.decoder.layers.3.encoder_attn.out_proj.bias', 'model.decoder.layers.4.final_layer_norm.bias', 'model.decoder.layers.2.self_attn.v_proj.weight', 'model.decoder.layers.5.self_attn.out_proj.weight', 'model.decoder.layers.1.self_attn.k_proj.weight', 'model.decoder.layers.4.self_attn.k_proj.weight', 'model.decoder.layers.4.self_attn_layer_norm.bias', 'model.decoder.layers.4.final_layer_norm.weight', 'model.decoder.layers.5.encoder_attn.k_proj.weight', 'model.decoder.layers.2.self_attn_layer_norm.bias', 'model.decoder.layers.1.fc1.bias', 'model.decoder.layers.1.final_layer_norm.weight', 'model.decoder.layers.4.fc1.bias', 'model.decoder.layers.2.encoder_attn.out_proj.bias', 'model.decoder.layers.5.encoder_attn_layer_norm.weight', 'model.decoder.layers.3.fc2.bias', 'model.decoder.layers.5.final_layer_norm.bias', 'model.decoder.layers.2.fc2.bias', 'model.decoder.layers.5.encoder_attn.out_proj.weight', 'model.decoder.layers.4.encoder_attn.v_proj.bias']\n","- This IS expected if you are initializing BartForConditionalGeneration from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BartForConditionalGeneration from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n","Some weights of the model checkpoint at digit82/kobart-summarization were not used when initializing BartForConditionalGeneration: ['model.decoder.layers.2.self_attn.k_proj.bias', 'model.decoder.layers.3.self_attn.out_proj.weight', 'model.decoder.layers.3.self_attn_layer_norm.bias', 'model.decoder.layers.2.encoder_attn.q_proj.bias', 'model.decoder.layers.2.final_layer_norm.weight', 'model.decoder.layers.3.self_attn.k_proj.bias', 'model.decoder.layers.2.encoder_attn.q_proj.weight', 'model.decoder.layers.2.final_layer_norm.bias', 'model.decoder.layers.3.self_attn.v_proj.weight', 'model.decoder.layers.3.self_attn.q_proj.bias', 'model.decoder.layers.5.encoder_attn.out_proj.bias', 'model.decoder.layers.3.encoder_attn.v_proj.bias', 'model.decoder.layers.5.self_attn.k_proj.bias', 'model.decoder.layers.5.final_layer_norm.weight', 'model.decoder.layers.4.self_attn.v_proj.weight', 'model.decoder.layers.5.encoder_attn.q_proj.weight', 'model.decoder.layers.2.encoder_attn.v_proj.bias', 'model.decoder.layers.3.encoder_attn.k_proj.bias', 'model.decoder.layers.5.encoder_attn.q_proj.bias', 'model.decoder.layers.2.self_attn.q_proj.weight', 'model.decoder.layers.5.self_attn.out_proj.bias', 'model.decoder.layers.4.fc2.weight', 'model.decoder.layers.5.fc2.weight', 'model.decoder.layers.2.encoder_attn.out_proj.weight', 'model.decoder.layers.3.self_attn_layer_norm.weight', 'model.decoder.layers.5.self_attn.q_proj.weight', 'model.decoder.layers.4.encoder_attn.k_proj.weight', 'model.decoder.layers.3.fc1.weight', 'model.decoder.layers.2.self_attn_layer_norm.weight', 'model.decoder.layers.3.fc2.weight', 'model.decoder.layers.2.fc1.weight', 'model.decoder.layers.2.encoder_attn_layer_norm.bias', 'model.decoder.layers.2.encoder_attn.v_proj.weight', 'model.decoder.layers.3.fc1.bias', 'model.decoder.layers.4.self_attn.out_proj.weight', 'model.decoder.layers.3.self_attn.out_proj.bias', 'model.decoder.layers.3.self_attn.q_proj.weight', 'model.decoder.layers.5.fc2.bias', 'model.decoder.layers.2.fc1.bias', 'model.decoder.layers.3.encoder_attn.v_proj.weight', 'model.decoder.layers.5.encoder_attn_layer_norm.bias', 'model.decoder.layers.2.self_attn.q_proj.bias', 'model.decoder.layers.3.encoder_attn.out_proj.weight', 'model.decoder.layers.5.encoder_attn.v_proj.bias', 'model.decoder.layers.2.encoder_attn_layer_norm.weight', 'model.decoder.layers.5.fc1.bias', 'model.decoder.layers.4.encoder_attn_layer_norm.weight', 'model.decoder.layers.4.self_attn.v_proj.bias', 'model.decoder.layers.4.encoder_attn.k_proj.bias', 'model.decoder.layers.2.self_attn.out_proj.weight', 'model.decoder.layers.2.encoder_attn.k_proj.bias', 'model.decoder.layers.3.encoder_attn.q_proj.weight', 'model.decoder.layers.4.self_attn_layer_norm.weight', 'model.decoder.layers.5.encoder_attn.v_proj.weight', 'model.decoder.layers.4.encoder_attn.q_proj.bias', 'model.decoder.layers.4.self_attn.q_proj.weight', 'model.decoder.layers.5.encoder_attn.k_proj.bias', 'model.decoder.layers.4.encoder_attn_layer_norm.bias', 'model.decoder.layers.2.fc2.weight', 'model.decoder.layers.4.fc1.weight', 'model.decoder.layers.5.self_attn.q_proj.bias', 'model.decoder.layers.2.self_attn.v_proj.bias', 'model.decoder.layers.2.self_attn.k_proj.weight', 'model.decoder.layers.5.self_attn.v_proj.bias', 'model.decoder.layers.4.encoder_attn.v_proj.weight', 'model.decoder.layers.5.self_attn.v_proj.weight', 'model.decoder.layers.3.self_attn.k_proj.weight', 'model.decoder.layers.2.encoder_attn.k_proj.weight', 'model.decoder.layers.3.encoder_attn.out_proj.bias', 'model.decoder.layers.4.fc2.bias', 'model.decoder.layers.4.final_layer_norm.bias', 'model.decoder.layers.2.self_attn.v_proj.weight', 'model.decoder.layers.2.self_attn.out_proj.bias', 'model.decoder.layers.5.self_attn.out_proj.weight', 'model.decoder.layers.4.encoder_attn.out_proj.weight', 'model.decoder.layers.4.self_attn.k_proj.weight', 'model.decoder.layers.4.encoder_attn.q_proj.weight', 'model.decoder.layers.5.fc1.weight', 'model.decoder.layers.4.self_attn_layer_norm.bias', 'model.decoder.layers.4.final_layer_norm.weight', 'model.decoder.layers.5.self_attn_layer_norm.bias', 'model.decoder.layers.5.encoder_attn.k_proj.weight', 'model.decoder.layers.3.self_attn.v_proj.bias', 'model.decoder.layers.2.self_attn_layer_norm.bias', 'model.decoder.layers.4.self_attn.k_proj.bias', 'model.decoder.layers.4.fc1.bias', 'model.decoder.layers.3.encoder_attn.q_proj.bias', 'model.decoder.layers.5.self_attn.k_proj.weight', 'model.decoder.layers.5.self_attn_layer_norm.weight', 'model.decoder.layers.2.encoder_attn.out_proj.bias', 'model.decoder.layers.3.encoder_attn.k_proj.weight', 'model.decoder.layers.5.encoder_attn_layer_norm.weight', 'model.decoder.layers.4.encoder_attn.out_proj.bias', 'model.decoder.layers.3.fc2.bias', 'model.decoder.layers.3.final_layer_norm.bias', 'model.decoder.layers.3.encoder_attn_layer_norm.weight', 'model.decoder.layers.3.final_layer_norm.weight', 'model.decoder.layers.3.encoder_attn_layer_norm.bias', 'model.decoder.layers.4.self_attn.q_proj.bias', 'model.decoder.layers.4.self_attn.out_proj.bias', 'model.decoder.layers.5.final_layer_norm.bias', 'model.decoder.layers.2.fc2.bias', 'model.decoder.layers.5.encoder_attn.out_proj.weight', 'model.decoder.layers.4.encoder_attn.v_proj.bias']\n","- This IS expected if you are initializing BartForConditionalGeneration from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BartForConditionalGeneration from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}]},{"cell_type":"code","source":["model4 = CustomModel(model_name = model_name).return_model()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wqGBiJHblG70","executionInfo":{"status":"ok","timestamp":1694678174981,"user_tz":-540,"elapsed":2349,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"085ff20e-53e7-4b09-f2dd-ae0b91554655"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"]}]},{"cell_type":"code","source":["model5 = CustomModel(model_name = model_name).return_model()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7-4rUt5WbZxO","executionInfo":{"status":"ok","timestamp":1694690644449,"user_tz":-540,"elapsed":2489,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"f95d0fc0-5c0e-46a5-9250-e63b52807ab8"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"]}]},{"cell_type":"code","source":["model6 = CustomModel(model_name = model_name).return_model()\n","for param in model6.get_encoder().parameters():\n","    param.requires_grad = False\n","\n","for i in range(1, 5):\n","    model6.get_decoder().layers[i].fc1 = nn.Linear(768, 3600)\n","    model6.get_decoder().layers[i].fc2 = nn.Linear(3600, 768)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g9fi7787mdoT","executionInfo":{"status":"ok","timestamp":1694693712023,"user_tz":-540,"elapsed":2729,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"3272375a-d4fc-4e97-8ef4-7d233eb8d795"},"execution_count":61,"outputs":[{"output_type":"stream","name":"stderr","text":["You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"]}]},{"cell_type":"code","source":["model7 = CustomModel(model_name = model_name).return_model()\n","for param in model7.get_encoder().parameters():\n","    param.requires_grad = False\n","\n","for i in range(1, 5):\n","    model7.get_decoder().layers[i].fc1 = nn.Sequential(nn.Linear(in_features = 768, out_features = 2048, bias = False),\n","                                                      nn.ReLU(),\n","                                                      nn.Linear(in_features=2048, out_features=1024, bias = False))\n","    model7.get_decoder().layers[i].fc2 = nn.Linear(1024, 768)\n","\n","model7"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G_eiIRo6mimt","executionInfo":{"status":"ok","timestamp":1694697504487,"user_tz":-540,"elapsed":3696,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"11e1bb4e-a19a-4aa1-d422-b6f9dfe01d92"},"execution_count":70,"outputs":[{"output_type":"stream","name":"stderr","text":["You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"]},{"output_type":"execute_result","data":{"text/plain":["BartForConditionalGeneration(\n","  (model): BartModel(\n","    (shared): Embedding(30000, 768, padding_idx=3)\n","    (encoder): BartEncoder(\n","      (embed_tokens): Embedding(30000, 768, padding_idx=3)\n","      (embed_positions): BartLearnedPositionalEmbedding(1028, 768)\n","      (layers): ModuleList(\n","        (0-5): 6 x BartEncoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (activation_fn): GELUActivation()\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (decoder): BartDecoder(\n","      (embed_tokens): Embedding(30000, 768, padding_idx=3)\n","      (embed_positions): BartLearnedPositionalEmbedding(1028, 768)\n","      (layers): ModuleList(\n","        (0): BartDecoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (activation_fn): GELUActivation()\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (1-4): 4 x BartDecoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (activation_fn): GELUActivation()\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Sequential(\n","            (0): Linear(in_features=768, out_features=2048, bias=False)\n","            (1): ReLU()\n","            (2): Linear(in_features=2048, out_features=1024, bias=False)\n","          )\n","          (fc2): Linear(in_features=1024, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (5): BartDecoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (activation_fn): GELUActivation()\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","    )\n","  )\n","  (lm_head): Linear(in_features=768, out_features=30000, bias=False)\n",")"]},"metadata":{},"execution_count":70}]},{"cell_type":"code","source":["model6"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ccgU9mc5TNZw","executionInfo":{"status":"ok","timestamp":1694693712023,"user_tz":-540,"elapsed":5,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"dc52498e-c22c-4b49-bafc-78f898bddfa4"},"execution_count":62,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BartForConditionalGeneration(\n","  (model): BartModel(\n","    (shared): Embedding(30000, 768, padding_idx=3)\n","    (encoder): BartEncoder(\n","      (embed_tokens): Embedding(30000, 768, padding_idx=3)\n","      (embed_positions): BartLearnedPositionalEmbedding(1028, 768)\n","      (layers): ModuleList(\n","        (0-5): 6 x BartEncoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (activation_fn): GELUActivation()\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (decoder): BartDecoder(\n","      (embed_tokens): Embedding(30000, 768, padding_idx=3)\n","      (embed_positions): BartLearnedPositionalEmbedding(1028, 768)\n","      (layers): ModuleList(\n","        (0): BartDecoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (activation_fn): GELUActivation()\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (1-4): 4 x BartDecoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (activation_fn): GELUActivation()\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3600, bias=True)\n","          (fc2): Linear(in_features=3600, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (5): BartDecoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (activation_fn): GELUActivation()\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","    )\n","  )\n","  (lm_head): Linear(in_features=768, out_features=30000, bias=False)\n",")"]},"metadata":{},"execution_count":62}]},{"cell_type":"code","source":["model2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CAumzlKVTO9a","executionInfo":{"status":"ok","timestamp":1694654856868,"user_tz":-540,"elapsed":316,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"45f8d788-1510-4f06-ac2d-3b37802c5993"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BartForConditionalGeneration(\n","  (model): BartModel(\n","    (shared): Embedding(30000, 768, padding_idx=3)\n","    (encoder): BartEncoder(\n","      (embed_tokens): Embedding(30000, 768, padding_idx=3)\n","      (embed_positions): BartLearnedPositionalEmbedding(1028, 768)\n","      (layers): ModuleList(\n","        (0-5): 6 x BartEncoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (activation_fn): GELUActivation()\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (decoder): BartDecoder(\n","      (embed_tokens): Embedding(30000, 768, padding_idx=3)\n","      (embed_positions): BartLearnedPositionalEmbedding(1028, 768)\n","      (layers): ModuleList(\n","        (0): BartDecoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (activation_fn): GELUActivation()\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","    )\n","  )\n","  (lm_head): Sequential(\n","    (0): Linear(in_features=768, out_features=2048, bias=False)\n","    (1): ReLU()\n","    (2): Linear(in_features=2048, out_features=30000, bias=False)\n","  )\n",")"]},"metadata":{},"execution_count":42}]},{"cell_type":"code","source":["model2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IRSxG3FWTQ6t","executionInfo":{"status":"ok","timestamp":1694654864683,"user_tz":-540,"elapsed":3,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"93b0c5d6-19b5-4932-bed5-aa41d24d352f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BartForConditionalGeneration(\n","  (model): BartModel(\n","    (shared): Embedding(30000, 768, padding_idx=3)\n","    (encoder): BartEncoder(\n","      (embed_tokens): Embedding(30000, 768, padding_idx=3)\n","      (embed_positions): BartLearnedPositionalEmbedding(1028, 768)\n","      (layers): ModuleList(\n","        (0-5): 6 x BartEncoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (activation_fn): GELUActivation()\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (decoder): BartDecoder(\n","      (embed_tokens): Embedding(30000, 768, padding_idx=3)\n","      (embed_positions): BartLearnedPositionalEmbedding(1028, 768)\n","      (layers): ModuleList(\n","        (0): BartDecoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (activation_fn): GELUActivation()\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","    )\n","  )\n","  (lm_head): Sequential(\n","    (0): Linear(in_features=768, out_features=2048, bias=False)\n","    (1): ReLU()\n","    (2): Linear(in_features=2048, out_features=30000, bias=False)\n","  )\n",")"]},"metadata":{},"execution_count":43}]},{"cell_type":"code","source":["# encoder -> freeze\n","for param in model1.get_encoder().parameters():\n","    param.requires_grad = False\n","\n","for param in model2.get_encoder().parameters():\n","    param.requires_grad = False\n","\n","for param in model3.get_encoder().parameters():\n","    param.requires_grad = False"],"metadata":{"id":"6Tb-cYXEFfK2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for param in model4.get_encoder().parameters():\n","    param.requires_grad = False"],"metadata":{"id":"pCAPBek5lKAH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for param in model4.get_decoder().layers[0].parameters():\n","    param.requires_grad = False"],"metadata":{"id":"BQq_oUyjlwH2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i in range(1, 5):\n","    model4.get_decoder().layers[i].fc1 = nn.Linear(768, 3600)\n","    model4.get_decoder().layers[i].fc2 = nn.Linear(3600, 768)"],"metadata":{"id":"8TOq5m0qlN5W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for param in model5.get_encoder().parameters():\n","    param.requires_grad = False\n","\n","for i in range(1, 5):\n","    model5.get_decoder().layers[i].fc1 = nn.Linear(768, 2048)\n","    model5.get_decoder().layers[i].fc2 = nn.Linear(2048, 768)"],"metadata":{"id":"AARFXmgMbniq","executionInfo":{"status":"ok","timestamp":1694690703138,"user_tz":-540,"elapsed":5,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["model5"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KZo9d7y0bnaP","executionInfo":{"status":"ok","timestamp":1694690703139,"user_tz":-540,"elapsed":4,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"ea56814c-4ce8-46b3-ce71-80d171328aa9"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BartForConditionalGeneration(\n","  (model): BartModel(\n","    (shared): Embedding(30000, 768, padding_idx=3)\n","    (encoder): BartEncoder(\n","      (embed_tokens): Embedding(30000, 768, padding_idx=3)\n","      (embed_positions): BartLearnedPositionalEmbedding(1028, 768)\n","      (layers): ModuleList(\n","        (0-5): 6 x BartEncoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (activation_fn): GELUActivation()\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (decoder): BartDecoder(\n","      (embed_tokens): Embedding(30000, 768, padding_idx=3)\n","      (embed_positions): BartLearnedPositionalEmbedding(1028, 768)\n","      (layers): ModuleList(\n","        (0): BartDecoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (activation_fn): GELUActivation()\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (1-4): 4 x BartDecoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (activation_fn): GELUActivation()\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=2048, bias=True)\n","          (fc2): Linear(in_features=2048, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (5): BartDecoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (activation_fn): GELUActivation()\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","    )\n","  )\n","  (lm_head): Linear(in_features=768, out_features=30000, bias=False)\n",")"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["model4"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fPL6e8oXlbgi","executionInfo":{"status":"ok","timestamp":1694678200561,"user_tz":-540,"elapsed":4,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"a0accc82-f9e2-4149-8d59-78d3ba71b269"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BartForConditionalGeneration(\n","  (model): BartModel(\n","    (shared): Embedding(30000, 768, padding_idx=3)\n","    (encoder): BartEncoder(\n","      (embed_tokens): Embedding(30000, 768, padding_idx=3)\n","      (embed_positions): BartLearnedPositionalEmbedding(1028, 768)\n","      (layers): ModuleList(\n","        (0-5): 6 x BartEncoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (activation_fn): GELUActivation()\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (decoder): BartDecoder(\n","      (embed_tokens): Embedding(30000, 768, padding_idx=3)\n","      (embed_positions): BartLearnedPositionalEmbedding(1028, 768)\n","      (layers): ModuleList(\n","        (0): BartDecoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (activation_fn): GELUActivation()\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (1-4): 4 x BartDecoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (activation_fn): GELUActivation()\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3600, bias=True)\n","          (fc2): Linear(in_features=3600, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (5): BartDecoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (activation_fn): GELUActivation()\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","    )\n","  )\n","  (lm_head): Linear(in_features=768, out_features=30000, bias=False)\n",")"]},"metadata":{},"execution_count":357}]},{"cell_type":"markdown","source":["## 모델6"],"metadata":{"id":"5UAusDWwm06-"}},{"cell_type":"code","source":["model_path = \"/content/drive/MyDrive/hong/model/\"\n","\n","training_args = Seq2SeqTrainingArguments(\n","    output_dir=model_path, #The output directory\n","    overwrite_output_dir=True, #overwrite the content of the output directory\n","    num_train_epochs=50, # number of training epochs\n","    per_device_train_batch_size=20, # batch size for training\n","    per_device_eval_batch_size=20,  # batch size for evaluation\n","    eval_steps=100, # Number of update steps between two evaluations.\n","    save_steps=1000, # after # steps model is saved\n","    logging_steps=100,\n","    warmup_steps=300,# number of warmup steps for learning rate scheduler\n","    prediction_loss_only=True,\n","    evaluation_strategy=\"steps\",\n","    save_total_limit=3\n","    )\n","\n","trainer = Seq2SeqTrainer(\n","    model=model6,\n","    args=training_args,\n","    train_dataset=dataset_train,\n","    eval_dataset=dataset_val,\n",")"],"metadata":{"id":"SkHqxZtBm0cY","executionInfo":{"status":"ok","timestamp":1694693753851,"user_tz":-540,"elapsed":459,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}}},"execution_count":63,"outputs":[]},{"cell_type":"code","source":["result6 = trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":860},"id":"gjsBAEzDm5uR","executionInfo":{"status":"ok","timestamp":1694696573801,"user_tz":-540,"elapsed":2818368,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"0d631a3e-f0ce-4d1c-e369-e84a6684c1f7"},"execution_count":64,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='2500' max='2500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2500/2500 46:57, Epoch 50/50]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>100</td>\n","      <td>6.729400</td>\n","      <td>4.593542</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>4.592400</td>\n","      <td>4.567587</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>4.571200</td>\n","      <td>4.560586</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>4.557300</td>\n","      <td>4.560133</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>4.546100</td>\n","      <td>4.558870</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>4.535900</td>\n","      <td>4.561585</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>4.527300</td>\n","      <td>4.562807</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>4.519800</td>\n","      <td>4.564507</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>4.513500</td>\n","      <td>4.564821</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>4.508000</td>\n","      <td>4.566031</td>\n","    </tr>\n","    <tr>\n","      <td>1100</td>\n","      <td>4.503400</td>\n","      <td>4.566619</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>4.499600</td>\n","      <td>4.568806</td>\n","    </tr>\n","    <tr>\n","      <td>1300</td>\n","      <td>4.496600</td>\n","      <td>4.569390</td>\n","    </tr>\n","    <tr>\n","      <td>1400</td>\n","      <td>4.494000</td>\n","      <td>4.569806</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>4.492000</td>\n","      <td>4.570045</td>\n","    </tr>\n","    <tr>\n","      <td>1600</td>\n","      <td>4.490100</td>\n","      <td>4.570789</td>\n","    </tr>\n","    <tr>\n","      <td>1700</td>\n","      <td>4.488700</td>\n","      <td>4.571767</td>\n","    </tr>\n","    <tr>\n","      <td>1800</td>\n","      <td>4.487400</td>\n","      <td>4.570881</td>\n","    </tr>\n","    <tr>\n","      <td>1900</td>\n","      <td>4.486400</td>\n","      <td>4.571802</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>4.485500</td>\n","      <td>4.572598</td>\n","    </tr>\n","    <tr>\n","      <td>2100</td>\n","      <td>4.484900</td>\n","      <td>4.572070</td>\n","    </tr>\n","    <tr>\n","      <td>2200</td>\n","      <td>4.484300</td>\n","      <td>4.572488</td>\n","    </tr>\n","    <tr>\n","      <td>2300</td>\n","      <td>4.483900</td>\n","      <td>4.572405</td>\n","    </tr>\n","    <tr>\n","      <td>2400</td>\n","      <td>4.483600</td>\n","      <td>4.572101</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>4.483400</td>\n","      <td>4.572280</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}}]},{"cell_type":"code","source":["result = []\n","for i in range(1000):\n","    input_ids = tokenizer(df.iloc[i, 0], return_tensors=\"pt\")[\"input_ids\"]\n","    output = model6.generate(input_ids.to(device), max_length = 68)\n","    output_ = tokenizer.decode(output[0], skip_special_tokens=True)\n","    output_ = tokenizer(output_)['input_ids']\n","    result.append(output_)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":261},"id":"8zTr2kFwm7FT","executionInfo":{"status":"error","timestamp":1694697284284,"user_tz":-540,"elapsed":280748,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"f5ab6f82-e3ac-4bec-e899-03a4bd5f8084"},"execution_count":65,"outputs":[{"output_type":"error","ename":"IndexError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-65-18738839483a>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_tokenized\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_tokenized\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: list index out of range"]}]},{"cell_type":"code","source":["target_tokenized = []\n","for i in range(len(df)):\n","    target_text = df.iloc[i, 1]\n","    target_ids = tokenizer(target_text)[\"input_ids\"]\n","    target_tokenized.append(target_ids)\n","\n","count = 0\n","total = 0\n","for i in range(1000):\n","    if len(result[i]) < len(target_tokenized[i]):\n","        total += len(target_tokenized[i])\n","        for j in range(len(result[i])):\n","            count += int(result[i][j] == target_tokenized[i][j])\n","    else:\n","        total += len(result[i])\n","        for j in range(len(target_tokenized[i])):\n","            count += int(result[i][j] == target_tokenized[i][j])\n","\n","print(count/total)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Gd08YaGt1YGN","executionInfo":{"status":"ok","timestamp":1694697369142,"user_tz":-540,"elapsed":474,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"bc408239-8398-4c58-cac8-8453ba0022e5"},"execution_count":68,"outputs":[{"output_type":"stream","name":"stdout","text":["0.13891928508154863\n"]}]},{"cell_type":"code","source":["len(result)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0Xg6iPEo1Jvg","executionInfo":{"status":"ok","timestamp":1694697336462,"user_tz":-540,"elapsed":2,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"5dcb40cc-e230-455f-9894-a7c6424579b9"},"execution_count":67,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1000"]},"metadata":{},"execution_count":67}]},{"cell_type":"code","source":["torch.save(model6, \"/content/drive/MyDrive/hong/models/model6_50epoch.pt\")"],"metadata":{"id":"Vp5WYRhC01Xx","executionInfo":{"status":"ok","timestamp":1694697463325,"user_tz":-540,"elapsed":1225,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}}},"execution_count":69,"outputs":[]},{"cell_type":"markdown","source":["## model7 fclayer 768 - 2048 - 1024 - 768"],"metadata":{"id":"HfMk-j322FXX"}},{"cell_type":"code","source":["model_path = \"/content/drive/MyDrive/hong/model/\"\n","\n","training_args = Seq2SeqTrainingArguments(\n","    output_dir=model_path, #The output directory\n","    overwrite_output_dir=True, #overwrite the content of the output directory\n","    num_train_epochs=100, # number of training epochs\n","    per_device_train_batch_size=10, # batch size for training\n","    per_device_eval_batch_size=10,  # batch size for evaluation\n","    eval_steps=10, # Number of update steps between two evaluations.\n","    save_steps=1000, # after # steps model is saved\n","    logging_steps=10,\n","    warmup_steps=300,# number of warmup steps for learning rate scheduler\n","    prediction_loss_only=True,\n","    evaluation_strategy=\"steps\",\n","    save_total_limit=3\n","    )\n","\n","trainer = Seq2SeqTrainer(\n","    model=model7,\n","    args=training_args,\n","    train_dataset=dataset_train,\n","    eval_dataset=dataset_val,\n",")"],"metadata":{"id":"4avla-Cdm7SL","executionInfo":{"status":"ok","timestamp":1694697645941,"user_tz":-540,"elapsed":3,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}}},"execution_count":74,"outputs":[]},{"cell_type":"code","source":["result7 = trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"1aS_fAps2ern","executionInfo":{"status":"ok","timestamp":1694698231772,"user_tz":-540,"elapsed":573759,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"94cd0d5e-edae-4b7e-9be1-2ba4ec6d1f95"},"execution_count":75,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1000/1000 09:31, Epoch 100/100]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>13.988500</td>\n","      <td>13.234152</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>11.765600</td>\n","      <td>10.201788</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>8.990800</td>\n","      <td>7.621949</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>7.063100</td>\n","      <td>6.104478</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>5.796200</td>\n","      <td>5.233985</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>5.103300</td>\n","      <td>4.843260</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>4.822000</td>\n","      <td>4.692523</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>4.703000</td>\n","      <td>4.639733</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>4.652300</td>\n","      <td>4.621217</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>4.627400</td>\n","      <td>4.607360</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>4.614200</td>\n","      <td>4.599283</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>4.601400</td>\n","      <td>4.594510</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>4.592900</td>\n","      <td>4.590316</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>4.584300</td>\n","      <td>4.587589</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>4.578800</td>\n","      <td>4.586376</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>4.573900</td>\n","      <td>4.585567</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>4.567400</td>\n","      <td>4.584446</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>4.561900</td>\n","      <td>4.584077</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>4.557200</td>\n","      <td>4.583980</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>4.552600</td>\n","      <td>4.584470</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>4.547600</td>\n","      <td>4.583824</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>4.543800</td>\n","      <td>4.584500</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>4.537900</td>\n","      <td>4.585088</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>4.533200</td>\n","      <td>4.584190</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>4.529300</td>\n","      <td>4.586243</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>4.523600</td>\n","      <td>4.586143</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>4.519500</td>\n","      <td>4.587520</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>4.515700</td>\n","      <td>4.585802</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>4.512900</td>\n","      <td>4.590369</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>4.509100</td>\n","      <td>4.589711</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>4.506600</td>\n","      <td>4.591003</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>4.502700</td>\n","      <td>4.592298</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>4.500000</td>\n","      <td>4.590387</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>4.497600</td>\n","      <td>4.591550</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>4.495000</td>\n","      <td>4.591950</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>4.493300</td>\n","      <td>4.594219</td>\n","    </tr>\n","    <tr>\n","      <td>370</td>\n","      <td>4.492200</td>\n","      <td>4.591560</td>\n","    </tr>\n","    <tr>\n","      <td>380</td>\n","      <td>4.490500</td>\n","      <td>4.593087</td>\n","    </tr>\n","    <tr>\n","      <td>390</td>\n","      <td>4.489300</td>\n","      <td>4.593575</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>4.488200</td>\n","      <td>4.594013</td>\n","    </tr>\n","    <tr>\n","      <td>410</td>\n","      <td>4.487200</td>\n","      <td>4.594917</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>4.486500</td>\n","      <td>4.595538</td>\n","    </tr>\n","    <tr>\n","      <td>430</td>\n","      <td>4.486100</td>\n","      <td>4.594131</td>\n","    </tr>\n","    <tr>\n","      <td>440</td>\n","      <td>4.485800</td>\n","      <td>4.594051</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>4.485100</td>\n","      <td>4.592896</td>\n","    </tr>\n","    <tr>\n","      <td>460</td>\n","      <td>4.484000</td>\n","      <td>4.596535</td>\n","    </tr>\n","    <tr>\n","      <td>470</td>\n","      <td>4.483500</td>\n","      <td>4.594258</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>4.482800</td>\n","      <td>4.595102</td>\n","    </tr>\n","    <tr>\n","      <td>490</td>\n","      <td>4.482700</td>\n","      <td>4.594894</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>4.482600</td>\n","      <td>4.596550</td>\n","    </tr>\n","    <tr>\n","      <td>510</td>\n","      <td>4.481700</td>\n","      <td>4.596974</td>\n","    </tr>\n","    <tr>\n","      <td>520</td>\n","      <td>4.481700</td>\n","      <td>4.596664</td>\n","    </tr>\n","    <tr>\n","      <td>530</td>\n","      <td>4.481300</td>\n","      <td>4.597548</td>\n","    </tr>\n","    <tr>\n","      <td>540</td>\n","      <td>4.481200</td>\n","      <td>4.596230</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>4.481000</td>\n","      <td>4.596022</td>\n","    </tr>\n","    <tr>\n","      <td>560</td>\n","      <td>4.480900</td>\n","      <td>4.596748</td>\n","    </tr>\n","    <tr>\n","      <td>570</td>\n","      <td>4.480600</td>\n","      <td>4.597535</td>\n","    </tr>\n","    <tr>\n","      <td>580</td>\n","      <td>4.480300</td>\n","      <td>4.598023</td>\n","    </tr>\n","    <tr>\n","      <td>590</td>\n","      <td>4.480100</td>\n","      <td>4.597116</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>4.480200</td>\n","      <td>4.597157</td>\n","    </tr>\n","    <tr>\n","      <td>610</td>\n","      <td>4.479600</td>\n","      <td>4.597629</td>\n","    </tr>\n","    <tr>\n","      <td>620</td>\n","      <td>4.479200</td>\n","      <td>4.598701</td>\n","    </tr>\n","    <tr>\n","      <td>630</td>\n","      <td>4.479500</td>\n","      <td>4.597804</td>\n","    </tr>\n","    <tr>\n","      <td>640</td>\n","      <td>4.479100</td>\n","      <td>4.597560</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>4.479200</td>\n","      <td>4.598678</td>\n","    </tr>\n","    <tr>\n","      <td>660</td>\n","      <td>4.479300</td>\n","      <td>4.597262</td>\n","    </tr>\n","    <tr>\n","      <td>670</td>\n","      <td>4.478900</td>\n","      <td>4.598072</td>\n","    </tr>\n","    <tr>\n","      <td>680</td>\n","      <td>4.478800</td>\n","      <td>4.598538</td>\n","    </tr>\n","    <tr>\n","      <td>690</td>\n","      <td>4.478900</td>\n","      <td>4.598543</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>4.478500</td>\n","      <td>4.599077</td>\n","    </tr>\n","    <tr>\n","      <td>710</td>\n","      <td>4.478400</td>\n","      <td>4.598746</td>\n","    </tr>\n","    <tr>\n","      <td>720</td>\n","      <td>4.478400</td>\n","      <td>4.598083</td>\n","    </tr>\n","    <tr>\n","      <td>730</td>\n","      <td>4.478700</td>\n","      <td>4.598283</td>\n","    </tr>\n","    <tr>\n","      <td>740</td>\n","      <td>4.478300</td>\n","      <td>4.598378</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>4.478200</td>\n","      <td>4.598592</td>\n","    </tr>\n","    <tr>\n","      <td>760</td>\n","      <td>4.478200</td>\n","      <td>4.598626</td>\n","    </tr>\n","    <tr>\n","      <td>770</td>\n","      <td>4.478000</td>\n","      <td>4.599189</td>\n","    </tr>\n","    <tr>\n","      <td>780</td>\n","      <td>4.478200</td>\n","      <td>4.599166</td>\n","    </tr>\n","    <tr>\n","      <td>790</td>\n","      <td>4.478000</td>\n","      <td>4.598869</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>4.477700</td>\n","      <td>4.598407</td>\n","    </tr>\n","    <tr>\n","      <td>810</td>\n","      <td>4.477900</td>\n","      <td>4.598079</td>\n","    </tr>\n","    <tr>\n","      <td>820</td>\n","      <td>4.477700</td>\n","      <td>4.598507</td>\n","    </tr>\n","    <tr>\n","      <td>830</td>\n","      <td>4.477800</td>\n","      <td>4.599517</td>\n","    </tr>\n","    <tr>\n","      <td>840</td>\n","      <td>4.477700</td>\n","      <td>4.599733</td>\n","    </tr>\n","    <tr>\n","      <td>850</td>\n","      <td>4.477600</td>\n","      <td>4.599165</td>\n","    </tr>\n","    <tr>\n","      <td>860</td>\n","      <td>4.477900</td>\n","      <td>4.598938</td>\n","    </tr>\n","    <tr>\n","      <td>870</td>\n","      <td>4.477700</td>\n","      <td>4.599153</td>\n","    </tr>\n","    <tr>\n","      <td>880</td>\n","      <td>4.477700</td>\n","      <td>4.599137</td>\n","    </tr>\n","    <tr>\n","      <td>890</td>\n","      <td>4.477400</td>\n","      <td>4.599034</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>4.477400</td>\n","      <td>4.598388</td>\n","    </tr>\n","    <tr>\n","      <td>910</td>\n","      <td>4.477500</td>\n","      <td>4.598142</td>\n","    </tr>\n","    <tr>\n","      <td>920</td>\n","      <td>4.477500</td>\n","      <td>4.598194</td>\n","    </tr>\n","    <tr>\n","      <td>930</td>\n","      <td>4.477400</td>\n","      <td>4.598405</td>\n","    </tr>\n","    <tr>\n","      <td>940</td>\n","      <td>4.477500</td>\n","      <td>4.598826</td>\n","    </tr>\n","    <tr>\n","      <td>950</td>\n","      <td>4.477400</td>\n","      <td>4.599174</td>\n","    </tr>\n","    <tr>\n","      <td>960</td>\n","      <td>4.477400</td>\n","      <td>4.599243</td>\n","    </tr>\n","    <tr>\n","      <td>970</td>\n","      <td>4.477400</td>\n","      <td>4.599118</td>\n","    </tr>\n","    <tr>\n","      <td>980</td>\n","      <td>4.477200</td>\n","      <td>4.599099</td>\n","    </tr>\n","    <tr>\n","      <td>990</td>\n","      <td>4.477300</td>\n","      <td>4.599067</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>4.477400</td>\n","      <td>4.599051</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}}]},{"cell_type":"code","source":["result = []\n","for i in range(100):\n","    input_ids = tokenizer(df.iloc[i, 0], return_tensors=\"pt\")[\"input_ids\"]\n","    output = model7.generate(input_ids.to(device), max_length = 68)\n","    output_ = tokenizer.decode(output[0], skip_special_tokens=True)\n","    output_ = tokenizer(output_)['input_ids']\n","    result.append(output_)\n","\n","target_tokenized = []\n","for i in range(len(df)):\n","    target_text = df.iloc[i, 1]\n","    target_ids = tokenizer(target_text)[\"input_ids\"]\n","    target_tokenized.append(target_ids)\n","\n","count = 0\n","total = 0\n","for i in range(100):\n","    if len(result[i]) < len(target_tokenized[i]):\n","        total += len(target_tokenized[i])\n","        for j in range(len(result[i])):\n","            count += int(result[i][j] == target_tokenized[i][j])\n","    else:\n","        total += len(result[i])\n","        for j in range(len(target_tokenized[i])):\n","            count += int(result[i][j] == target_tokenized[i][j])\n","\n","print(\"model7, 100epoch - accuracy:\", count/total)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vQq10LSK2hfW","executionInfo":{"status":"ok","timestamp":1694698495697,"user_tz":-540,"elapsed":28362,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"0a4ff087-50fd-4f30-c258-19831dab12bb"},"execution_count":77,"outputs":[{"output_type":"stream","name":"stdout","text":["model7, 100epoch - accuracy: 0.3186323092170466\n"]}]},{"cell_type":"code","source":["torch.save(model7, \"/content/drive/MyDrive/hong/models/model7_100epoch.pt\")"],"metadata":{"id":"El-7y2TW2odM","executionInfo":{"status":"ok","timestamp":1694698545212,"user_tz":-540,"elapsed":1238,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}}},"execution_count":78,"outputs":[]},{"cell_type":"code","source":["df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":597},"id":"_oZ-AP-l6f5R","executionInfo":{"status":"ok","timestamp":1694698704171,"user_tz":-540,"elapsed":4,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"da3a35b7-36e1-467b-b92e-f9585fef452d"},"execution_count":80,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                passage  \\\n","0     40억 달러 ‘딜’ 주인공 김봉진 우아한형제들 대표태풍 뒤의 고요함이랄까.   40...   \n","1     시진핑 방한과 새해 한·중관계 전망지난달 23일 베이징에서 열린 한·중 정상회담을 ...   \n","2      한·중이 사드에 관한 ‘3불(不)’이 ‘약속’인지 ‘입장표명’인지 표현을 놓고 갈...   \n","3     배달의민족이 독일 자본에 매각된 것을 놓고 말들이 많다.   민족 정서를 배반했다며...   \n","4     지난 28일부터 나흘간 진행된 7기 5차 노동당 전원회의에서 북한은 핵 무력 개발의...   \n","...                                                 ...   \n","1095  세계적인 경제 악재가 불거질 때마다 자금력이 약한 중소기업은 가장 큰 타격을 받아왔...   \n","1096  4일 오후 8시 제주시 노형동의 한 대형마트 위생용품 판매대.   마스크는 단 한장...   \n","1097  4ㆍ15 총선을 두 달여 앞두고 ‘호남 통합 정당’ 추진에 속도가 붙고 있다.   ...   \n","1098  \"정경심 교수님하고 방금 통화… VIP 보고해야 한다고, 빨리 보내라 닦달\" \"정경...   \n","1099  우리은행 영업점 직원들이 고객 2만3000여 명의 인터넷·모바일뱅킹 비밀번호를 무단...   \n","\n","                                                summary  \n","0     DH가 기업가치를 약 4조 8000억 원으로 평가한 우아한형제들의 김 대표는 국내 ...  \n","1     한·중관계가 중국 쪽으로 기울어진 비대칭관계로 바뀌면서 세계무대에서 한국의 경제 지...  \n","2     사드에 관한 3불이 결국은 중국이 한국을 압박할 수 있는 카드이며 미국이 중거리 미...  \n","3     배달의민족이 독일 자본에 매각된 것을 놓고 민족 정서를 배반했다며 분노가 터져 나왔...  \n","4     북한은 핵 무력 개발의 주역인 이 제1부부장을 정치국 위원과 당 부위원장, 부장에 ...  \n","...                                                 ...  \n","1095  신종 코로나바이러스 감염증 사태 속에 중국 상하이에 위치한 일부 공장들은 추가 가동...  \n","1096  중국인 관광객이 제주를 여행 후 코로나19 확진 판정을 받았다는 정보가 나온 후 도...  \n","1097  4·15 총선을 앞두고 호남 통합 정당 추진에 속도가 붙으며 손 바른미래당 대표는 ...  \n","1098  서울중앙지법 형사합의 25부는 동양대 정 교수의 3차 공판기일에서 VIP와 보고라는...  \n","1099  실적 점수를 올리기 위해 1년 이상 거래가 없는 고객의 온라인 비밀번호를 무단으로 ...  \n","\n","[1100 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-9a6f774c-a61f-4088-9e3f-247cebbec45d\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>passage</th>\n","      <th>summary</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>40억 달러 ‘딜’ 주인공 김봉진 우아한형제들 대표태풍 뒤의 고요함이랄까.   40...</td>\n","      <td>DH가 기업가치를 약 4조 8000억 원으로 평가한 우아한형제들의 김 대표는 국내 ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>시진핑 방한과 새해 한·중관계 전망지난달 23일 베이징에서 열린 한·중 정상회담을 ...</td>\n","      <td>한·중관계가 중국 쪽으로 기울어진 비대칭관계로 바뀌면서 세계무대에서 한국의 경제 지...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>한·중이 사드에 관한 ‘3불(不)’이 ‘약속’인지 ‘입장표명’인지 표현을 놓고 갈...</td>\n","      <td>사드에 관한 3불이 결국은 중국이 한국을 압박할 수 있는 카드이며 미국이 중거리 미...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>배달의민족이 독일 자본에 매각된 것을 놓고 말들이 많다.   민족 정서를 배반했다며...</td>\n","      <td>배달의민족이 독일 자본에 매각된 것을 놓고 민족 정서를 배반했다며 분노가 터져 나왔...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>지난 28일부터 나흘간 진행된 7기 5차 노동당 전원회의에서 북한은 핵 무력 개발의...</td>\n","      <td>북한은 핵 무력 개발의 주역인 이 제1부부장을 정치국 위원과 당 부위원장, 부장에 ...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1095</th>\n","      <td>세계적인 경제 악재가 불거질 때마다 자금력이 약한 중소기업은 가장 큰 타격을 받아왔...</td>\n","      <td>신종 코로나바이러스 감염증 사태 속에 중국 상하이에 위치한 일부 공장들은 추가 가동...</td>\n","    </tr>\n","    <tr>\n","      <th>1096</th>\n","      <td>4일 오후 8시 제주시 노형동의 한 대형마트 위생용품 판매대.   마스크는 단 한장...</td>\n","      <td>중국인 관광객이 제주를 여행 후 코로나19 확진 판정을 받았다는 정보가 나온 후 도...</td>\n","    </tr>\n","    <tr>\n","      <th>1097</th>\n","      <td>4ㆍ15 총선을 두 달여 앞두고 ‘호남 통합 정당’ 추진에 속도가 붙고 있다.   ...</td>\n","      <td>4·15 총선을 앞두고 호남 통합 정당 추진에 속도가 붙으며 손 바른미래당 대표는 ...</td>\n","    </tr>\n","    <tr>\n","      <th>1098</th>\n","      <td>\"정경심 교수님하고 방금 통화… VIP 보고해야 한다고, 빨리 보내라 닦달\" \"정경...</td>\n","      <td>서울중앙지법 형사합의 25부는 동양대 정 교수의 3차 공판기일에서 VIP와 보고라는...</td>\n","    </tr>\n","    <tr>\n","      <th>1099</th>\n","      <td>우리은행 영업점 직원들이 고객 2만3000여 명의 인터넷·모바일뱅킹 비밀번호를 무단...</td>\n","      <td>실적 점수를 올리기 위해 1년 이상 거래가 없는 고객의 온라인 비밀번호를 무단으로 ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1100 rows × 2 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9a6f774c-a61f-4088-9e3f-247cebbec45d')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-9a6f774c-a61f-4088-9e3f-247cebbec45d button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-9a6f774c-a61f-4088-9e3f-247cebbec45d');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-b5a310a7-c394-48ff-a5c9-5043a50216e0\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b5a310a7-c394-48ff-a5c9-5043a50216e0')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-b5a310a7-c394-48ff-a5c9-5043a50216e0 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":80}]},{"cell_type":"code","source":["predict = []\n","for sentence in df['passage']:\n","    input = torch.LongTensor(tokenizer(sentence, padding=\"max_length\", max_length=1024, truncation=True)[\"input_ids\"])\n","    result = tokenizer.decode(model5.generate(input.unsqueeze(0).to(device), max_length = 68)[0], skip_special_tokens=True)\n","    predict.append(result)\n","\n","df_tmp = pd.DataFrame(df['summary'])\n","df_tmp['predict'] = predict\n","df_tmp.to_csv(\"/content/drive/MyDrive/hong/models/model7_100epoch.csv\")"],"metadata":{"id":"8OTyxEjV3zsq","executionInfo":{"status":"ok","timestamp":1694698795782,"user_tz":-540,"elapsed":28824,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}}},"execution_count":84,"outputs":[]},{"cell_type":"code","source":["result7 = trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"EzHy8-o02zEr","executionInfo":{"status":"ok","timestamp":1694699467506,"user_tz":-540,"elapsed":572102,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"aa1765b6-0306-4ebc-cd55-6f08b571e731"},"execution_count":85,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1000/1000 09:30, Epoch 100/100]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>4.477200</td>\n","      <td>4.599046</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>4.477400</td>\n","      <td>4.599007</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>4.477200</td>\n","      <td>4.599160</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>4.477200</td>\n","      <td>4.599301</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>4.477300</td>\n","      <td>4.599407</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>4.477400</td>\n","      <td>4.598934</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>4.477300</td>\n","      <td>4.598620</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>4.477200</td>\n","      <td>4.598965</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>4.477100</td>\n","      <td>4.599835</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>4.477100</td>\n","      <td>4.600347</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>4.477100</td>\n","      <td>4.599903</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>4.477000</td>\n","      <td>4.599833</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>4.477000</td>\n","      <td>4.599515</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>4.477000</td>\n","      <td>4.599990</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>4.476800</td>\n","      <td>4.599751</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>4.476700</td>\n","      <td>4.599750</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>4.476800</td>\n","      <td>4.599880</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>4.476600</td>\n","      <td>4.599639</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>4.476600</td>\n","      <td>4.599753</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>4.476500</td>\n","      <td>4.598749</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>4.476400</td>\n","      <td>4.599830</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>4.476200</td>\n","      <td>4.600543</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>4.476100</td>\n","      <td>4.600060</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>4.476100</td>\n","      <td>4.600600</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>4.476100</td>\n","      <td>4.600009</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>4.476200</td>\n","      <td>4.601607</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>4.476000</td>\n","      <td>4.600823</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>4.475700</td>\n","      <td>4.600884</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>4.475900</td>\n","      <td>4.600404</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>4.475600</td>\n","      <td>4.603852</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>4.475700</td>\n","      <td>4.601597</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>4.475500</td>\n","      <td>4.599343</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>4.475300</td>\n","      <td>4.598939</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>4.475300</td>\n","      <td>4.599790</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>4.475100</td>\n","      <td>4.600480</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>4.475000</td>\n","      <td>4.600429</td>\n","    </tr>\n","    <tr>\n","      <td>370</td>\n","      <td>4.474900</td>\n","      <td>4.602147</td>\n","    </tr>\n","    <tr>\n","      <td>380</td>\n","      <td>4.474800</td>\n","      <td>4.602169</td>\n","    </tr>\n","    <tr>\n","      <td>390</td>\n","      <td>4.474800</td>\n","      <td>4.603198</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>4.474600</td>\n","      <td>4.600999</td>\n","    </tr>\n","    <tr>\n","      <td>410</td>\n","      <td>4.474600</td>\n","      <td>4.603087</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>4.474400</td>\n","      <td>4.601716</td>\n","    </tr>\n","    <tr>\n","      <td>430</td>\n","      <td>4.474300</td>\n","      <td>4.601630</td>\n","    </tr>\n","    <tr>\n","      <td>440</td>\n","      <td>4.474200</td>\n","      <td>4.599632</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>4.474300</td>\n","      <td>4.600562</td>\n","    </tr>\n","    <tr>\n","      <td>460</td>\n","      <td>4.473900</td>\n","      <td>4.602214</td>\n","    </tr>\n","    <tr>\n","      <td>470</td>\n","      <td>4.473900</td>\n","      <td>4.601197</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>4.474000</td>\n","      <td>4.603281</td>\n","    </tr>\n","    <tr>\n","      <td>490</td>\n","      <td>4.474000</td>\n","      <td>4.600997</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>4.473800</td>\n","      <td>4.601596</td>\n","    </tr>\n","    <tr>\n","      <td>510</td>\n","      <td>4.473800</td>\n","      <td>4.601642</td>\n","    </tr>\n","    <tr>\n","      <td>520</td>\n","      <td>4.473700</td>\n","      <td>4.603517</td>\n","    </tr>\n","    <tr>\n","      <td>530</td>\n","      <td>4.473700</td>\n","      <td>4.602824</td>\n","    </tr>\n","    <tr>\n","      <td>540</td>\n","      <td>4.473500</td>\n","      <td>4.601182</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>4.473400</td>\n","      <td>4.600772</td>\n","    </tr>\n","    <tr>\n","      <td>560</td>\n","      <td>4.473400</td>\n","      <td>4.601139</td>\n","    </tr>\n","    <tr>\n","      <td>570</td>\n","      <td>4.473400</td>\n","      <td>4.600513</td>\n","    </tr>\n","    <tr>\n","      <td>580</td>\n","      <td>4.473200</td>\n","      <td>4.599992</td>\n","    </tr>\n","    <tr>\n","      <td>590</td>\n","      <td>4.473100</td>\n","      <td>4.600730</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>4.473100</td>\n","      <td>4.602183</td>\n","    </tr>\n","    <tr>\n","      <td>610</td>\n","      <td>4.473000</td>\n","      <td>4.602337</td>\n","    </tr>\n","    <tr>\n","      <td>620</td>\n","      <td>4.473000</td>\n","      <td>4.602981</td>\n","    </tr>\n","    <tr>\n","      <td>630</td>\n","      <td>4.473000</td>\n","      <td>4.601666</td>\n","    </tr>\n","    <tr>\n","      <td>640</td>\n","      <td>4.472900</td>\n","      <td>4.600732</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>4.472900</td>\n","      <td>4.601887</td>\n","    </tr>\n","    <tr>\n","      <td>660</td>\n","      <td>4.472800</td>\n","      <td>4.601136</td>\n","    </tr>\n","    <tr>\n","      <td>670</td>\n","      <td>4.472800</td>\n","      <td>4.601025</td>\n","    </tr>\n","    <tr>\n","      <td>680</td>\n","      <td>4.472700</td>\n","      <td>4.601724</td>\n","    </tr>\n","    <tr>\n","      <td>690</td>\n","      <td>4.472800</td>\n","      <td>4.601394</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>4.472600</td>\n","      <td>4.601193</td>\n","    </tr>\n","    <tr>\n","      <td>710</td>\n","      <td>4.472600</td>\n","      <td>4.600904</td>\n","    </tr>\n","    <tr>\n","      <td>720</td>\n","      <td>4.472600</td>\n","      <td>4.600654</td>\n","    </tr>\n","    <tr>\n","      <td>730</td>\n","      <td>4.472500</td>\n","      <td>4.601079</td>\n","    </tr>\n","    <tr>\n","      <td>740</td>\n","      <td>4.472600</td>\n","      <td>4.602547</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>4.472500</td>\n","      <td>4.602559</td>\n","    </tr>\n","    <tr>\n","      <td>760</td>\n","      <td>4.472500</td>\n","      <td>4.602596</td>\n","    </tr>\n","    <tr>\n","      <td>770</td>\n","      <td>4.472500</td>\n","      <td>4.602086</td>\n","    </tr>\n","    <tr>\n","      <td>780</td>\n","      <td>4.472400</td>\n","      <td>4.601609</td>\n","    </tr>\n","    <tr>\n","      <td>790</td>\n","      <td>4.472300</td>\n","      <td>4.601708</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>4.472300</td>\n","      <td>4.602157</td>\n","    </tr>\n","    <tr>\n","      <td>810</td>\n","      <td>4.472400</td>\n","      <td>4.601548</td>\n","    </tr>\n","    <tr>\n","      <td>820</td>\n","      <td>4.472300</td>\n","      <td>4.601716</td>\n","    </tr>\n","    <tr>\n","      <td>830</td>\n","      <td>4.472300</td>\n","      <td>4.601806</td>\n","    </tr>\n","    <tr>\n","      <td>840</td>\n","      <td>4.472300</td>\n","      <td>4.602141</td>\n","    </tr>\n","    <tr>\n","      <td>850</td>\n","      <td>4.472200</td>\n","      <td>4.602208</td>\n","    </tr>\n","    <tr>\n","      <td>860</td>\n","      <td>4.472200</td>\n","      <td>4.602142</td>\n","    </tr>\n","    <tr>\n","      <td>870</td>\n","      <td>4.472400</td>\n","      <td>4.601966</td>\n","    </tr>\n","    <tr>\n","      <td>880</td>\n","      <td>4.472200</td>\n","      <td>4.601941</td>\n","    </tr>\n","    <tr>\n","      <td>890</td>\n","      <td>4.472100</td>\n","      <td>4.601691</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>4.472200</td>\n","      <td>4.601761</td>\n","    </tr>\n","    <tr>\n","      <td>910</td>\n","      <td>4.472200</td>\n","      <td>4.601909</td>\n","    </tr>\n","    <tr>\n","      <td>920</td>\n","      <td>4.472100</td>\n","      <td>4.602337</td>\n","    </tr>\n","    <tr>\n","      <td>930</td>\n","      <td>4.472100</td>\n","      <td>4.602487</td>\n","    </tr>\n","    <tr>\n","      <td>940</td>\n","      <td>4.472100</td>\n","      <td>4.602454</td>\n","    </tr>\n","    <tr>\n","      <td>950</td>\n","      <td>4.472100</td>\n","      <td>4.602459</td>\n","    </tr>\n","    <tr>\n","      <td>960</td>\n","      <td>4.472000</td>\n","      <td>4.602611</td>\n","    </tr>\n","    <tr>\n","      <td>970</td>\n","      <td>4.472100</td>\n","      <td>4.602637</td>\n","    </tr>\n","    <tr>\n","      <td>980</td>\n","      <td>4.472100</td>\n","      <td>4.602588</td>\n","    </tr>\n","    <tr>\n","      <td>990</td>\n","      <td>4.472100</td>\n","      <td>4.602540</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>4.472100</td>\n","      <td>4.602529</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}}]},{"cell_type":"code","source":["result = []\n","for i in range(100):\n","    input_ids = tokenizer(df.iloc[i, 0], return_tensors=\"pt\")[\"input_ids\"]\n","    output = model7.generate(input_ids.to(device), max_length = 68)\n","    output_ = tokenizer.decode(output[0], skip_special_tokens=True)\n","    output_ = tokenizer(output_)['input_ids']\n","    result.append(output_)\n","\n","target_tokenized = []\n","for i in range(len(df)):\n","    target_text = df.iloc[i, 1]\n","    target_ids = tokenizer(target_text)[\"input_ids\"]\n","    target_tokenized.append(target_ids)\n","\n","count = 0\n","total = 0\n","for i in range(100):\n","    if len(result[i]) < len(target_tokenized[i]):\n","        total += len(target_tokenized[i])\n","        for j in range(len(result[i])):\n","            count += int(result[i][j] == target_tokenized[i][j])\n","    else:\n","        total += len(result[i])\n","        for j in range(len(target_tokenized[i])):\n","            count += int(result[i][j] == target_tokenized[i][j])\n","\n","print(\"model7, 200epoch - accuracy:\", count/total)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fivjheia20fw","executionInfo":{"status":"ok","timestamp":1694699494240,"user_tz":-540,"elapsed":26747,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"7849dfa1-9048-4ebd-84ad-c49b5b8178d1"},"execution_count":86,"outputs":[{"output_type":"stream","name":"stdout","text":["model7, 200epoch - accuracy: 0.5772811918063314\n"]}]},{"cell_type":"code","source":["torch.save(model7, \"/content/drive/MyDrive/hong/models/model7_200epoch.pt\")"],"metadata":{"id":"iWp1_7Dg3Fyv","executionInfo":{"status":"ok","timestamp":1694699585937,"user_tz":-540,"elapsed":1097,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}}},"execution_count":87,"outputs":[]},{"cell_type":"code","source":["idxs = []\n","for idx, row in enumerate(df['passage']):\n","    if row.startswith(\" \"):\n","        idxs.append(idx)"],"metadata":{"id":"sL7Hhvdu-Lxf","executionInfo":{"status":"ok","timestamp":1694699767909,"user_tz":-540,"elapsed":2,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}}},"execution_count":93,"outputs":[]},{"cell_type":"code","source":["df_tmp"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":597},"id":"n9jzvtfm-lH3","executionInfo":{"status":"ok","timestamp":1694699877165,"user_tz":-540,"elapsed":4,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"feadd5c4-ae98-401c-f4f0-fa32c6ec863b"},"execution_count":99,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                               summary  \\\n","0    DH가 기업가치를 약 4조 8000억 원으로 평가한 우아한형제들의 김 대표는 국내 ...   \n","1    한·중관계가 중국 쪽으로 기울어진 비대칭관계로 바뀌면서 세계무대에서 한국의 경제 지...   \n","2    사드에 관한 3불이 결국은 중국이 한국을 압박할 수 있는 카드이며 미국이 중거리 미...   \n","3    배달의민족이 독일 자본에 매각된 것을 놓고 민족 정서를 배반했다며 분노가 터져 나왔...   \n","4    북한은 핵 무력 개발의 주역인 이 제1부부장을 정치국 위원과 당 부위원장, 부장에 ...   \n","..                                                 ...   \n","105  제34회 골든디스크 어워즈에서 방탄소년단이 작은 것들을 위한 시로 처음으로 음원 대...   \n","106  미국에서 개막하는 CES 2020에서 삼성전자와 LG전자는 베젤과 롤다운 8K TV...   \n","107               LG전자와 삼성전자가 유튜브 광고를 통해 비방광고전을 주고받았다.   \n","108  한국당의 황 대표가 4·15 총선에서 수도권 험지에 출마하겠다고 선언하자 당내에서는...   \n","109  회사 동료가 안랩 주식을 사서 수익을 냈다는 얘길 듣고 관심종목에 추가한 김 씨는 ...   \n","\n","                                               predict  \n","0    DH가 기업가치를 약 4조 8000억 원으로 평가한 우아한형제들의 김 대표는 국내 ...  \n","1    한·중관계가 중국 쪽으로 기울어진 비대칭관계로 서서히 바뀐 것은 격세지감을 느낄 정...  \n","2    사드에 관한 3불이 결국은 중국이 한국을 압박할 수 있는 카드이며 미국이 중거리 미...  \n","3    배달의민족이 독일 자본에 매각된 것을 놓고 민족 정서를 배반했다며 분노가 터져 나왔...  \n","4    북한은 후 국무위원장과 이일환 당 부위원장을 임명한 노동당 전원회의에서 노두철 경질...  \n","..                                                 ...  \n","105           서울탄소년단이 골든디스크 어워즈에서 본상과 최우수 부문 본상을 수상했다.  \n","106  삼성전자는와 LG전자는 8K TV의 왕좌를 노리며 세계 최초 베젤을 없앤 무 베젤이...  \n","107  8와K TV의 프리미엄 TV 시장이 기대하며 삼성전자는 8K TV 시장이 본격화되는...  \n","108  황 대표가 4ᆞ15 총선에서 출마하겠다고 선언했지만 당 일각에서는 통합 비대위를 구...  \n","109  여유 소액금혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜...  \n","\n","[110 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-e984b0db-7b2f-4556-b279-cd2c20720388\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>summary</th>\n","      <th>predict</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>DH가 기업가치를 약 4조 8000억 원으로 평가한 우아한형제들의 김 대표는 국내 ...</td>\n","      <td>DH가 기업가치를 약 4조 8000억 원으로 평가한 우아한형제들의 김 대표는 국내 ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>한·중관계가 중국 쪽으로 기울어진 비대칭관계로 바뀌면서 세계무대에서 한국의 경제 지...</td>\n","      <td>한·중관계가 중국 쪽으로 기울어진 비대칭관계로 서서히 바뀐 것은 격세지감을 느낄 정...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>사드에 관한 3불이 결국은 중국이 한국을 압박할 수 있는 카드이며 미국이 중거리 미...</td>\n","      <td>사드에 관한 3불이 결국은 중국이 한국을 압박할 수 있는 카드이며 미국이 중거리 미...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>배달의민족이 독일 자본에 매각된 것을 놓고 민족 정서를 배반했다며 분노가 터져 나왔...</td>\n","      <td>배달의민족이 독일 자본에 매각된 것을 놓고 민족 정서를 배반했다며 분노가 터져 나왔...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>북한은 핵 무력 개발의 주역인 이 제1부부장을 정치국 위원과 당 부위원장, 부장에 ...</td>\n","      <td>북한은 후 국무위원장과 이일환 당 부위원장을 임명한 노동당 전원회의에서 노두철 경질...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>105</th>\n","      <td>제34회 골든디스크 어워즈에서 방탄소년단이 작은 것들을 위한 시로 처음으로 음원 대...</td>\n","      <td>서울탄소년단이 골든디스크 어워즈에서 본상과 최우수 부문 본상을 수상했다.</td>\n","    </tr>\n","    <tr>\n","      <th>106</th>\n","      <td>미국에서 개막하는 CES 2020에서 삼성전자와 LG전자는 베젤과 롤다운 8K TV...</td>\n","      <td>삼성전자는와 LG전자는 8K TV의 왕좌를 노리며 세계 최초 베젤을 없앤 무 베젤이...</td>\n","    </tr>\n","    <tr>\n","      <th>107</th>\n","      <td>LG전자와 삼성전자가 유튜브 광고를 통해 비방광고전을 주고받았다.</td>\n","      <td>8와K TV의 프리미엄 TV 시장이 기대하며 삼성전자는 8K TV 시장이 본격화되는...</td>\n","    </tr>\n","    <tr>\n","      <th>108</th>\n","      <td>한국당의 황 대표가 4·15 총선에서 수도권 험지에 출마하겠다고 선언하자 당내에서는...</td>\n","      <td>황 대표가 4ᆞ15 총선에서 출마하겠다고 선언했지만 당 일각에서는 통합 비대위를 구...</td>\n","    </tr>\n","    <tr>\n","      <th>109</th>\n","      <td>회사 동료가 안랩 주식을 사서 수익을 냈다는 얘길 듣고 관심종목에 추가한 김 씨는 ...</td>\n","      <td>여유 소액금혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>110 rows × 2 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e984b0db-7b2f-4556-b279-cd2c20720388')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-e984b0db-7b2f-4556-b279-cd2c20720388 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-e984b0db-7b2f-4556-b279-cd2c20720388');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-7c20bc09-1f15-4ef5-8a0f-d3c3aa0b691a\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7c20bc09-1f15-4ef5-8a0f-d3c3aa0b691a')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-7c20bc09-1f15-4ef5-8a0f-d3c3aa0b691a button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":99}]},{"cell_type":"code","source":["predict = []\n","for sentence in df['passage']:\n","    input = torch.LongTensor(tokenizer(sentence, padding=\"max_length\", max_length=1024, truncation=True)[\"input_ids\"])\n","    result = tokenizer.decode(model5.generate(input.unsqueeze(0).to(device), max_length = 68)[0], skip_special_tokens=True)\n","    predict.append(result)\n","\n","df_tmp = pd.DataFrame(df['summary'])\n","df_tmp['predict'] = predict\n","df_tmp.to_csv(\"/content/drive/MyDrive/hong/models/model7_200epoch.csv\")"],"metadata":{"id":"7IqlRT-o3TNk","executionInfo":{"status":"ok","timestamp":1694699618585,"user_tz":-540,"elapsed":30366,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}}},"execution_count":88,"outputs":[]},{"cell_type":"code","source":["total_params = sum(p.numel() for p in model7.parameters())\n","print(f\"Total parameters: {total_params}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_60MiqqA3x0n","executionInfo":{"status":"ok","timestamp":1694699620696,"user_tz":-540,"elapsed":2,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"b2122fd7-8045-4c96-8749-44247a12ed3d"},"execution_count":89,"outputs":[{"output_type":"stream","name":"stdout","text":["Total parameters: 122799104\n"]}]},{"cell_type":"code","source":["result = []\n","for i in range(100):\n","    input_ids = tokenizer(df.iloc[i, 0], return_tensors=\"pt\")[\"input_ids\"]\n","    output = model7.generate(input_ids.to(device), max_length = 68)\n","    output_ = tokenizer.decode(output[0], skip_special_tokens=True)\n","    output_ = tokenizer(output_)['input_ids']\n","    result.append(output_)\n","\n","target_tokenized = []\n","for i in range(len(df)):\n","    target_text = df.iloc[i, 1]\n","    target_ids = tokenizer(target_text)[\"input_ids\"]\n","    target_tokenized.append(target_ids)\n","\n","count = 0\n","total = 0\n","for i in range(100):\n","    if len(result[i]) < len(target_tokenized[i]):\n","        total += len(target_tokenized[i])\n","        for j in range(len(result[i])):\n","            count += int(result[i][j] == target_tokenized[i][j])\n","    else:\n","        total += len(result[i])\n","        for j in range(len(target_tokenized[i])):\n","            count += int(result[i][j] == target_tokenized[i][j])\n","\n","print(\"model7, 200epoch - accuracy:\", count/total)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"baohCXgS4BUT","executionInfo":{"status":"ok","timestamp":1694700339799,"user_tz":-540,"elapsed":26511,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"6899c0b8-71c3-40d4-fe30-5049662e13d2"},"execution_count":101,"outputs":[{"output_type":"stream","name":"stdout","text":["model7, 200epoch - accuracy: 0.5772811918063314\n"]}]},{"cell_type":"code","source":["model_path = \"/content/drive/MyDrive/hong/model/\"\n","\n","training_args = Seq2SeqTrainingArguments(\n","    output_dir=model_path, #The output directory\n","    overwrite_output_dir=True, #overwrite the content of the output directory\n","    num_train_epochs=100, # number of training epochs\n","    per_device_train_batch_size=10, # batch size for training\n","    per_device_eval_batch_size=10,  # batch size for evaluation\n","    eval_steps=10, # Number of update steps between two evaluations.\n","    save_steps=1000, # after # steps model is saved\n","    logging_steps=10,\n","    warmup_steps=300,# number of warmup steps for learning rate scheduler\n","    prediction_loss_only=True,\n","    evaluation_strategy=\"steps\",\n","    save_total_limit=3\n","    )\n","\n","trainer = Seq2SeqTrainer(\n","    model=model5,\n","    args=training_args,\n","    train_dataset=dataset_train,\n","    eval_dataset=dataset_val,\n",")"],"metadata":{"id":"0lZCPC1Qb_EY","executionInfo":{"status":"ok","timestamp":1694690725935,"user_tz":-540,"elapsed":4982,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["result5 = trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"gj_BaEyVcD9O","executionInfo":{"status":"ok","timestamp":1694691338883,"user_tz":-540,"elapsed":594781,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"6acd2f3b-df0b-40c8-ee66-e965fa63bfa8"},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1000/1000 09:49, Epoch 100/100]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>13.711600</td>\n","      <td>13.130056</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>11.366300</td>\n","      <td>9.760736</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>8.723200</td>\n","      <td>7.440404</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>6.868600</td>\n","      <td>5.867265</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>5.631800</td>\n","      <td>5.122081</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>5.024700</td>\n","      <td>4.801648</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>4.798800</td>\n","      <td>4.687230</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>4.701800</td>\n","      <td>4.641274</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>4.655200</td>\n","      <td>4.619460</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>4.628600</td>\n","      <td>4.603962</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>4.613300</td>\n","      <td>4.596967</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>4.600100</td>\n","      <td>4.594079</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>4.591700</td>\n","      <td>4.590524</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>4.582900</td>\n","      <td>4.587924</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>4.577100</td>\n","      <td>4.587363</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>4.572000</td>\n","      <td>4.586465</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>4.564800</td>\n","      <td>4.585654</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>4.559500</td>\n","      <td>4.586246</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>4.554700</td>\n","      <td>4.585616</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>4.548800</td>\n","      <td>4.585922</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>4.543300</td>\n","      <td>4.585892</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>4.540800</td>\n","      <td>4.586331</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>4.534400</td>\n","      <td>4.587173</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>4.529400</td>\n","      <td>4.586549</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>4.526100</td>\n","      <td>4.588561</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>4.520000</td>\n","      <td>4.588889</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>4.516000</td>\n","      <td>4.590717</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>4.512000</td>\n","      <td>4.588166</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>4.509400</td>\n","      <td>4.593431</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>4.505200</td>\n","      <td>4.591849</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>4.502900</td>\n","      <td>4.592396</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>4.499400</td>\n","      <td>4.594151</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>4.497000</td>\n","      <td>4.593155</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>4.495000</td>\n","      <td>4.592473</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>4.492900</td>\n","      <td>4.593937</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>4.491500</td>\n","      <td>4.594635</td>\n","    </tr>\n","    <tr>\n","      <td>370</td>\n","      <td>4.490500</td>\n","      <td>4.593324</td>\n","    </tr>\n","    <tr>\n","      <td>380</td>\n","      <td>4.489000</td>\n","      <td>4.594695</td>\n","    </tr>\n","    <tr>\n","      <td>390</td>\n","      <td>4.488000</td>\n","      <td>4.593751</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>4.487000</td>\n","      <td>4.595349</td>\n","    </tr>\n","    <tr>\n","      <td>410</td>\n","      <td>4.486300</td>\n","      <td>4.595248</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>4.485900</td>\n","      <td>4.597026</td>\n","    </tr>\n","    <tr>\n","      <td>430</td>\n","      <td>4.485200</td>\n","      <td>4.595176</td>\n","    </tr>\n","    <tr>\n","      <td>440</td>\n","      <td>4.484700</td>\n","      <td>4.595025</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>4.484400</td>\n","      <td>4.595584</td>\n","    </tr>\n","    <tr>\n","      <td>460</td>\n","      <td>4.483700</td>\n","      <td>4.597587</td>\n","    </tr>\n","    <tr>\n","      <td>470</td>\n","      <td>4.482900</td>\n","      <td>4.595402</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>4.482400</td>\n","      <td>4.596257</td>\n","    </tr>\n","    <tr>\n","      <td>490</td>\n","      <td>4.482200</td>\n","      <td>4.596328</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>4.482300</td>\n","      <td>4.596862</td>\n","    </tr>\n","    <tr>\n","      <td>510</td>\n","      <td>4.481400</td>\n","      <td>4.596580</td>\n","    </tr>\n","    <tr>\n","      <td>520</td>\n","      <td>4.481300</td>\n","      <td>4.595942</td>\n","    </tr>\n","    <tr>\n","      <td>530</td>\n","      <td>4.480900</td>\n","      <td>4.597156</td>\n","    </tr>\n","    <tr>\n","      <td>540</td>\n","      <td>4.480800</td>\n","      <td>4.596087</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>4.480700</td>\n","      <td>4.595721</td>\n","    </tr>\n","    <tr>\n","      <td>560</td>\n","      <td>4.480700</td>\n","      <td>4.596955</td>\n","    </tr>\n","    <tr>\n","      <td>570</td>\n","      <td>4.480200</td>\n","      <td>4.598531</td>\n","    </tr>\n","    <tr>\n","      <td>580</td>\n","      <td>4.480100</td>\n","      <td>4.597884</td>\n","    </tr>\n","    <tr>\n","      <td>590</td>\n","      <td>4.479900</td>\n","      <td>4.595860</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>4.479800</td>\n","      <td>4.597192</td>\n","    </tr>\n","    <tr>\n","      <td>610</td>\n","      <td>4.479400</td>\n","      <td>4.597054</td>\n","    </tr>\n","    <tr>\n","      <td>620</td>\n","      <td>4.479100</td>\n","      <td>4.598186</td>\n","    </tr>\n","    <tr>\n","      <td>630</td>\n","      <td>4.479300</td>\n","      <td>4.598201</td>\n","    </tr>\n","    <tr>\n","      <td>640</td>\n","      <td>4.479000</td>\n","      <td>4.597663</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>4.479000</td>\n","      <td>4.596732</td>\n","    </tr>\n","    <tr>\n","      <td>660</td>\n","      <td>4.479200</td>\n","      <td>4.596631</td>\n","    </tr>\n","    <tr>\n","      <td>670</td>\n","      <td>4.478800</td>\n","      <td>4.597443</td>\n","    </tr>\n","    <tr>\n","      <td>680</td>\n","      <td>4.478600</td>\n","      <td>4.597589</td>\n","    </tr>\n","    <tr>\n","      <td>690</td>\n","      <td>4.478700</td>\n","      <td>4.597794</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>4.478500</td>\n","      <td>4.598276</td>\n","    </tr>\n","    <tr>\n","      <td>710</td>\n","      <td>4.478300</td>\n","      <td>4.598225</td>\n","    </tr>\n","    <tr>\n","      <td>720</td>\n","      <td>4.478300</td>\n","      <td>4.597510</td>\n","    </tr>\n","    <tr>\n","      <td>730</td>\n","      <td>4.478600</td>\n","      <td>4.596992</td>\n","    </tr>\n","    <tr>\n","      <td>740</td>\n","      <td>4.478200</td>\n","      <td>4.597873</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>4.478000</td>\n","      <td>4.598024</td>\n","    </tr>\n","    <tr>\n","      <td>760</td>\n","      <td>4.478100</td>\n","      <td>4.597790</td>\n","    </tr>\n","    <tr>\n","      <td>770</td>\n","      <td>4.477900</td>\n","      <td>4.598069</td>\n","    </tr>\n","    <tr>\n","      <td>780</td>\n","      <td>4.478100</td>\n","      <td>4.597726</td>\n","    </tr>\n","    <tr>\n","      <td>790</td>\n","      <td>4.477900</td>\n","      <td>4.597820</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>4.477600</td>\n","      <td>4.597597</td>\n","    </tr>\n","    <tr>\n","      <td>810</td>\n","      <td>4.477800</td>\n","      <td>4.597466</td>\n","    </tr>\n","    <tr>\n","      <td>820</td>\n","      <td>4.477600</td>\n","      <td>4.598090</td>\n","    </tr>\n","    <tr>\n","      <td>830</td>\n","      <td>4.477700</td>\n","      <td>4.599056</td>\n","    </tr>\n","    <tr>\n","      <td>840</td>\n","      <td>4.477500</td>\n","      <td>4.599282</td>\n","    </tr>\n","    <tr>\n","      <td>850</td>\n","      <td>4.477500</td>\n","      <td>4.598533</td>\n","    </tr>\n","    <tr>\n","      <td>860</td>\n","      <td>4.477700</td>\n","      <td>4.598130</td>\n","    </tr>\n","    <tr>\n","      <td>870</td>\n","      <td>4.477500</td>\n","      <td>4.598369</td>\n","    </tr>\n","    <tr>\n","      <td>880</td>\n","      <td>4.477600</td>\n","      <td>4.598389</td>\n","    </tr>\n","    <tr>\n","      <td>890</td>\n","      <td>4.477400</td>\n","      <td>4.598212</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>4.477300</td>\n","      <td>4.597920</td>\n","    </tr>\n","    <tr>\n","      <td>910</td>\n","      <td>4.477500</td>\n","      <td>4.597820</td>\n","    </tr>\n","    <tr>\n","      <td>920</td>\n","      <td>4.477400</td>\n","      <td>4.597966</td>\n","    </tr>\n","    <tr>\n","      <td>930</td>\n","      <td>4.477300</td>\n","      <td>4.598174</td>\n","    </tr>\n","    <tr>\n","      <td>940</td>\n","      <td>4.477400</td>\n","      <td>4.598364</td>\n","    </tr>\n","    <tr>\n","      <td>950</td>\n","      <td>4.477300</td>\n","      <td>4.598538</td>\n","    </tr>\n","    <tr>\n","      <td>960</td>\n","      <td>4.477100</td>\n","      <td>4.598557</td>\n","    </tr>\n","    <tr>\n","      <td>970</td>\n","      <td>4.477300</td>\n","      <td>4.598474</td>\n","    </tr>\n","    <tr>\n","      <td>980</td>\n","      <td>4.477200</td>\n","      <td>4.598405</td>\n","    </tr>\n","    <tr>\n","      <td>990</td>\n","      <td>4.477200</td>\n","      <td>4.598351</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>4.477300</td>\n","      <td>4.598350</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}}]},{"cell_type":"code","source":["torch.save(model5, \"/content/drive/MyDrive/hong/models/model_custom_decoder_200epoch.pt\")"],"metadata":{"id":"82syriCMf577","executionInfo":{"status":"ok","timestamp":1694692918995,"user_tz":-540,"elapsed":1945,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["result5 = trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"yX682yQjgHj5","executionInfo":{"status":"ok","timestamp":1694692662690,"user_tz":-540,"elapsed":553705,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"7a240673-c25b-426a-9210-22018f6aaa19"},"execution_count":32,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1000/1000 09:12, Epoch 100/100]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>4.477100</td>\n","      <td>4.598330</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>4.477200</td>\n","      <td>4.598260</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>4.477100</td>\n","      <td>4.598503</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>4.477100</td>\n","      <td>4.598865</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>4.477300</td>\n","      <td>4.599145</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>4.477300</td>\n","      <td>4.598672</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>4.477200</td>\n","      <td>4.597824</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>4.477000</td>\n","      <td>4.597941</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>4.477000</td>\n","      <td>4.598643</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>4.477000</td>\n","      <td>4.599148</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>4.477000</td>\n","      <td>4.599171</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>4.476900</td>\n","      <td>4.598754</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>4.476900</td>\n","      <td>4.599277</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>4.476800</td>\n","      <td>4.598938</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>4.476700</td>\n","      <td>4.599074</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>4.476700</td>\n","      <td>4.599229</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>4.476700</td>\n","      <td>4.599366</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>4.476500</td>\n","      <td>4.599542</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>4.476600</td>\n","      <td>4.598751</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>4.476400</td>\n","      <td>4.598117</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>4.476400</td>\n","      <td>4.599029</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>4.476200</td>\n","      <td>4.599727</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>4.476000</td>\n","      <td>4.601079</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>4.476000</td>\n","      <td>4.601434</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>4.476000</td>\n","      <td>4.600078</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>4.476100</td>\n","      <td>4.602242</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>4.475800</td>\n","      <td>4.599023</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>4.475500</td>\n","      <td>4.600886</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>4.475800</td>\n","      <td>4.601253</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>4.475500</td>\n","      <td>4.600450</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>4.475500</td>\n","      <td>4.600441</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>4.475400</td>\n","      <td>4.598876</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>4.475200</td>\n","      <td>4.599616</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>4.475100</td>\n","      <td>4.598157</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>4.475100</td>\n","      <td>4.599025</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>4.475000</td>\n","      <td>4.600902</td>\n","    </tr>\n","    <tr>\n","      <td>370</td>\n","      <td>4.474700</td>\n","      <td>4.600426</td>\n","    </tr>\n","    <tr>\n","      <td>380</td>\n","      <td>4.474800</td>\n","      <td>4.599641</td>\n","    </tr>\n","    <tr>\n","      <td>390</td>\n","      <td>4.474600</td>\n","      <td>4.600363</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>4.474600</td>\n","      <td>4.599690</td>\n","    </tr>\n","    <tr>\n","      <td>410</td>\n","      <td>4.474400</td>\n","      <td>4.601486</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>4.474400</td>\n","      <td>4.601941</td>\n","    </tr>\n","    <tr>\n","      <td>430</td>\n","      <td>4.474100</td>\n","      <td>4.601456</td>\n","    </tr>\n","    <tr>\n","      <td>440</td>\n","      <td>4.474200</td>\n","      <td>4.600572</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>4.474100</td>\n","      <td>4.601655</td>\n","    </tr>\n","    <tr>\n","      <td>460</td>\n","      <td>4.473800</td>\n","      <td>4.603135</td>\n","    </tr>\n","    <tr>\n","      <td>470</td>\n","      <td>4.473800</td>\n","      <td>4.601581</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>4.473800</td>\n","      <td>4.600896</td>\n","    </tr>\n","    <tr>\n","      <td>490</td>\n","      <td>4.473800</td>\n","      <td>4.601586</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>4.473700</td>\n","      <td>4.600708</td>\n","    </tr>\n","    <tr>\n","      <td>510</td>\n","      <td>4.473600</td>\n","      <td>4.599992</td>\n","    </tr>\n","    <tr>\n","      <td>520</td>\n","      <td>4.473600</td>\n","      <td>4.601884</td>\n","    </tr>\n","    <tr>\n","      <td>530</td>\n","      <td>4.473600</td>\n","      <td>4.602250</td>\n","    </tr>\n","    <tr>\n","      <td>540</td>\n","      <td>4.473400</td>\n","      <td>4.601195</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>4.473300</td>\n","      <td>4.600963</td>\n","    </tr>\n","    <tr>\n","      <td>560</td>\n","      <td>4.473400</td>\n","      <td>4.600205</td>\n","    </tr>\n","    <tr>\n","      <td>570</td>\n","      <td>4.473200</td>\n","      <td>4.599716</td>\n","    </tr>\n","    <tr>\n","      <td>580</td>\n","      <td>4.473200</td>\n","      <td>4.599963</td>\n","    </tr>\n","    <tr>\n","      <td>590</td>\n","      <td>4.473100</td>\n","      <td>4.600864</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>4.473000</td>\n","      <td>4.602294</td>\n","    </tr>\n","    <tr>\n","      <td>610</td>\n","      <td>4.472900</td>\n","      <td>4.601752</td>\n","    </tr>\n","    <tr>\n","      <td>620</td>\n","      <td>4.472900</td>\n","      <td>4.601963</td>\n","    </tr>\n","    <tr>\n","      <td>630</td>\n","      <td>4.472900</td>\n","      <td>4.602262</td>\n","    </tr>\n","    <tr>\n","      <td>640</td>\n","      <td>4.472800</td>\n","      <td>4.601466</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>4.472700</td>\n","      <td>4.601915</td>\n","    </tr>\n","    <tr>\n","      <td>660</td>\n","      <td>4.472700</td>\n","      <td>4.602088</td>\n","    </tr>\n","    <tr>\n","      <td>670</td>\n","      <td>4.472700</td>\n","      <td>4.602116</td>\n","    </tr>\n","    <tr>\n","      <td>680</td>\n","      <td>4.472600</td>\n","      <td>4.601943</td>\n","    </tr>\n","    <tr>\n","      <td>690</td>\n","      <td>4.472700</td>\n","      <td>4.601436</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>4.472500</td>\n","      <td>4.601377</td>\n","    </tr>\n","    <tr>\n","      <td>710</td>\n","      <td>4.472500</td>\n","      <td>4.601508</td>\n","    </tr>\n","    <tr>\n","      <td>720</td>\n","      <td>4.472500</td>\n","      <td>4.602199</td>\n","    </tr>\n","    <tr>\n","      <td>730</td>\n","      <td>4.472400</td>\n","      <td>4.601861</td>\n","    </tr>\n","    <tr>\n","      <td>740</td>\n","      <td>4.472500</td>\n","      <td>4.601796</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>4.472400</td>\n","      <td>4.601598</td>\n","    </tr>\n","    <tr>\n","      <td>760</td>\n","      <td>4.472400</td>\n","      <td>4.602016</td>\n","    </tr>\n","    <tr>\n","      <td>770</td>\n","      <td>4.472500</td>\n","      <td>4.601237</td>\n","    </tr>\n","    <tr>\n","      <td>780</td>\n","      <td>4.472400</td>\n","      <td>4.600903</td>\n","    </tr>\n","    <tr>\n","      <td>790</td>\n","      <td>4.472300</td>\n","      <td>4.600816</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>4.472300</td>\n","      <td>4.601081</td>\n","    </tr>\n","    <tr>\n","      <td>810</td>\n","      <td>4.472300</td>\n","      <td>4.601275</td>\n","    </tr>\n","    <tr>\n","      <td>820</td>\n","      <td>4.472300</td>\n","      <td>4.601859</td>\n","    </tr>\n","    <tr>\n","      <td>830</td>\n","      <td>4.472200</td>\n","      <td>4.601912</td>\n","    </tr>\n","    <tr>\n","      <td>840</td>\n","      <td>4.472200</td>\n","      <td>4.601947</td>\n","    </tr>\n","    <tr>\n","      <td>850</td>\n","      <td>4.472200</td>\n","      <td>4.601535</td>\n","    </tr>\n","    <tr>\n","      <td>860</td>\n","      <td>4.472200</td>\n","      <td>4.601359</td>\n","    </tr>\n","    <tr>\n","      <td>870</td>\n","      <td>4.472300</td>\n","      <td>4.601192</td>\n","    </tr>\n","    <tr>\n","      <td>880</td>\n","      <td>4.472100</td>\n","      <td>4.601365</td>\n","    </tr>\n","    <tr>\n","      <td>890</td>\n","      <td>4.472100</td>\n","      <td>4.601257</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>4.472100</td>\n","      <td>4.601348</td>\n","    </tr>\n","    <tr>\n","      <td>910</td>\n","      <td>4.472100</td>\n","      <td>4.601787</td>\n","    </tr>\n","    <tr>\n","      <td>920</td>\n","      <td>4.472000</td>\n","      <td>4.601933</td>\n","    </tr>\n","    <tr>\n","      <td>930</td>\n","      <td>4.472100</td>\n","      <td>4.602050</td>\n","    </tr>\n","    <tr>\n","      <td>940</td>\n","      <td>4.472000</td>\n","      <td>4.602159</td>\n","    </tr>\n","    <tr>\n","      <td>950</td>\n","      <td>4.472000</td>\n","      <td>4.602153</td>\n","    </tr>\n","    <tr>\n","      <td>960</td>\n","      <td>4.472000</td>\n","      <td>4.602202</td>\n","    </tr>\n","    <tr>\n","      <td>970</td>\n","      <td>4.472000</td>\n","      <td>4.602191</td>\n","    </tr>\n","    <tr>\n","      <td>980</td>\n","      <td>4.472100</td>\n","      <td>4.602025</td>\n","    </tr>\n","    <tr>\n","      <td>990</td>\n","      <td>4.472000</td>\n","      <td>4.601922</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>4.472100</td>\n","      <td>4.601903</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}}]},{"cell_type":"code","source":["model_path = \"/content/drive/MyDrive/hong/model/\"\n","\n","training_args = Seq2SeqTrainingArguments(\n","    output_dir=model_path, #The output directory\n","    overwrite_output_dir=True, #overwrite the content of the output directory\n","    num_train_epochs=100, # number of training epochs\n","    per_device_train_batch_size=10, # batch size for training\n","    per_device_eval_batch_size=10,  # batch size for evaluation\n","    eval_steps=10, # Number of update steps between two evaluations.\n","    save_steps=1000, # after # steps model is saved\n","    logging_steps=10,\n","    warmup_steps=300,# number of warmup steps for learning rate scheduler\n","    prediction_loss_only=True,\n","    evaluation_strategy=\"steps\",\n","    save_total_limit=3\n","    )\n","\n","trainer = Seq2SeqTrainer(\n","    model=model4,\n","    args=training_args,\n","    train_dataset=dataset_train,\n","    eval_dataset=dataset_val,\n",")"],"metadata":{"id":"7yp5e8E1ljy-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["result4 = trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"17Nkl73JljWw","executionInfo":{"status":"ok","timestamp":1694680138692,"user_tz":-540,"elapsed":572831,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"61fe6366-4d26-4812-d856-9317be3e6fdf"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1000/1000 09:31, Epoch 100/100]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>4.477200</td>\n","      <td>4.599986</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>4.477300</td>\n","      <td>4.599900</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>4.477300</td>\n","      <td>4.599900</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>4.477200</td>\n","      <td>4.599917</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>4.477300</td>\n","      <td>4.600117</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>4.477300</td>\n","      <td>4.599931</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>4.477400</td>\n","      <td>4.599210</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>4.477200</td>\n","      <td>4.599090</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>4.477100</td>\n","      <td>4.600179</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>4.477100</td>\n","      <td>4.600453</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>4.477100</td>\n","      <td>4.600018</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>4.477100</td>\n","      <td>4.600743</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>4.477000</td>\n","      <td>4.600945</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>4.476900</td>\n","      <td>4.600288</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>4.476900</td>\n","      <td>4.601099</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>4.476800</td>\n","      <td>4.600791</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>4.476800</td>\n","      <td>4.601114</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>4.476700</td>\n","      <td>4.600082</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>4.476700</td>\n","      <td>4.600635</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>4.476600</td>\n","      <td>4.600464</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>4.476500</td>\n","      <td>4.599487</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>4.476400</td>\n","      <td>4.600629</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>4.476300</td>\n","      <td>4.600585</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>4.476200</td>\n","      <td>4.601345</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>4.476200</td>\n","      <td>4.600446</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>4.476300</td>\n","      <td>4.599869</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>4.476100</td>\n","      <td>4.600966</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>4.475900</td>\n","      <td>4.601900</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>4.475900</td>\n","      <td>4.599568</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>4.475800</td>\n","      <td>4.603241</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>4.475800</td>\n","      <td>4.600118</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>4.475600</td>\n","      <td>4.598256</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>4.475400</td>\n","      <td>4.598922</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>4.475400</td>\n","      <td>4.598409</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>4.475200</td>\n","      <td>4.601119</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>4.475400</td>\n","      <td>4.600583</td>\n","    </tr>\n","    <tr>\n","      <td>370</td>\n","      <td>4.475100</td>\n","      <td>4.598849</td>\n","    </tr>\n","    <tr>\n","      <td>380</td>\n","      <td>4.475100</td>\n","      <td>4.600997</td>\n","    </tr>\n","    <tr>\n","      <td>390</td>\n","      <td>4.474900</td>\n","      <td>4.602853</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>4.474800</td>\n","      <td>4.601456</td>\n","    </tr>\n","    <tr>\n","      <td>410</td>\n","      <td>4.474700</td>\n","      <td>4.602456</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>4.474500</td>\n","      <td>4.601457</td>\n","    </tr>\n","    <tr>\n","      <td>430</td>\n","      <td>4.474300</td>\n","      <td>4.603179</td>\n","    </tr>\n","    <tr>\n","      <td>440</td>\n","      <td>4.474300</td>\n","      <td>4.602447</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>4.474200</td>\n","      <td>4.602853</td>\n","    </tr>\n","    <tr>\n","      <td>460</td>\n","      <td>4.474100</td>\n","      <td>4.603307</td>\n","    </tr>\n","    <tr>\n","      <td>470</td>\n","      <td>4.474000</td>\n","      <td>4.603941</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>4.474300</td>\n","      <td>4.603671</td>\n","    </tr>\n","    <tr>\n","      <td>490</td>\n","      <td>4.474000</td>\n","      <td>4.603364</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>4.473900</td>\n","      <td>4.603321</td>\n","    </tr>\n","    <tr>\n","      <td>510</td>\n","      <td>4.473700</td>\n","      <td>4.603380</td>\n","    </tr>\n","    <tr>\n","      <td>520</td>\n","      <td>4.473600</td>\n","      <td>4.603490</td>\n","    </tr>\n","    <tr>\n","      <td>530</td>\n","      <td>4.473800</td>\n","      <td>4.603578</td>\n","    </tr>\n","    <tr>\n","      <td>540</td>\n","      <td>4.473600</td>\n","      <td>4.603078</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>4.473500</td>\n","      <td>4.603269</td>\n","    </tr>\n","    <tr>\n","      <td>560</td>\n","      <td>4.473400</td>\n","      <td>4.602309</td>\n","    </tr>\n","    <tr>\n","      <td>570</td>\n","      <td>4.473300</td>\n","      <td>4.602181</td>\n","    </tr>\n","    <tr>\n","      <td>580</td>\n","      <td>4.473300</td>\n","      <td>4.602167</td>\n","    </tr>\n","    <tr>\n","      <td>590</td>\n","      <td>4.473200</td>\n","      <td>4.602066</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>4.473100</td>\n","      <td>4.602734</td>\n","    </tr>\n","    <tr>\n","      <td>610</td>\n","      <td>4.473000</td>\n","      <td>4.603118</td>\n","    </tr>\n","    <tr>\n","      <td>620</td>\n","      <td>4.473100</td>\n","      <td>4.603176</td>\n","    </tr>\n","    <tr>\n","      <td>630</td>\n","      <td>4.473100</td>\n","      <td>4.602757</td>\n","    </tr>\n","    <tr>\n","      <td>640</td>\n","      <td>4.472900</td>\n","      <td>4.602650</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>4.472900</td>\n","      <td>4.603423</td>\n","    </tr>\n","    <tr>\n","      <td>660</td>\n","      <td>4.472800</td>\n","      <td>4.603110</td>\n","    </tr>\n","    <tr>\n","      <td>670</td>\n","      <td>4.472800</td>\n","      <td>4.603889</td>\n","    </tr>\n","    <tr>\n","      <td>680</td>\n","      <td>4.472900</td>\n","      <td>4.603813</td>\n","    </tr>\n","    <tr>\n","      <td>690</td>\n","      <td>4.472800</td>\n","      <td>4.603519</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>4.472600</td>\n","      <td>4.603112</td>\n","    </tr>\n","    <tr>\n","      <td>710</td>\n","      <td>4.472700</td>\n","      <td>4.603602</td>\n","    </tr>\n","    <tr>\n","      <td>720</td>\n","      <td>4.472500</td>\n","      <td>4.604260</td>\n","    </tr>\n","    <tr>\n","      <td>730</td>\n","      <td>4.472500</td>\n","      <td>4.603612</td>\n","    </tr>\n","    <tr>\n","      <td>740</td>\n","      <td>4.472600</td>\n","      <td>4.603046</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>4.472500</td>\n","      <td>4.602696</td>\n","    </tr>\n","    <tr>\n","      <td>760</td>\n","      <td>4.472400</td>\n","      <td>4.603851</td>\n","    </tr>\n","    <tr>\n","      <td>770</td>\n","      <td>4.472500</td>\n","      <td>4.604501</td>\n","    </tr>\n","    <tr>\n","      <td>780</td>\n","      <td>4.472500</td>\n","      <td>4.603486</td>\n","    </tr>\n","    <tr>\n","      <td>790</td>\n","      <td>4.472400</td>\n","      <td>4.602867</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>4.472300</td>\n","      <td>4.603092</td>\n","    </tr>\n","    <tr>\n","      <td>810</td>\n","      <td>4.472400</td>\n","      <td>4.602589</td>\n","    </tr>\n","    <tr>\n","      <td>820</td>\n","      <td>4.472400</td>\n","      <td>4.602597</td>\n","    </tr>\n","    <tr>\n","      <td>830</td>\n","      <td>4.472300</td>\n","      <td>4.602754</td>\n","    </tr>\n","    <tr>\n","      <td>840</td>\n","      <td>4.472300</td>\n","      <td>4.602532</td>\n","    </tr>\n","    <tr>\n","      <td>850</td>\n","      <td>4.472300</td>\n","      <td>4.602199</td>\n","    </tr>\n","    <tr>\n","      <td>860</td>\n","      <td>4.472200</td>\n","      <td>4.602054</td>\n","    </tr>\n","    <tr>\n","      <td>870</td>\n","      <td>4.472400</td>\n","      <td>4.602292</td>\n","    </tr>\n","    <tr>\n","      <td>880</td>\n","      <td>4.472200</td>\n","      <td>4.602643</td>\n","    </tr>\n","    <tr>\n","      <td>890</td>\n","      <td>4.472100</td>\n","      <td>4.602983</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>4.472200</td>\n","      <td>4.602756</td>\n","    </tr>\n","    <tr>\n","      <td>910</td>\n","      <td>4.472200</td>\n","      <td>4.602805</td>\n","    </tr>\n","    <tr>\n","      <td>920</td>\n","      <td>4.472100</td>\n","      <td>4.603230</td>\n","    </tr>\n","    <tr>\n","      <td>930</td>\n","      <td>4.472100</td>\n","      <td>4.603383</td>\n","    </tr>\n","    <tr>\n","      <td>940</td>\n","      <td>4.472200</td>\n","      <td>4.603390</td>\n","    </tr>\n","    <tr>\n","      <td>950</td>\n","      <td>4.472200</td>\n","      <td>4.603278</td>\n","    </tr>\n","    <tr>\n","      <td>960</td>\n","      <td>4.472000</td>\n","      <td>4.603199</td>\n","    </tr>\n","    <tr>\n","      <td>970</td>\n","      <td>4.472100</td>\n","      <td>4.603196</td>\n","    </tr>\n","    <tr>\n","      <td>980</td>\n","      <td>4.472100</td>\n","      <td>4.603195</td>\n","    </tr>\n","    <tr>\n","      <td>990</td>\n","      <td>4.472000</td>\n","      <td>4.603196</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>4.472100</td>\n","      <td>4.603187</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}}]},{"cell_type":"code","source":["torch.save(model4, \"/content/drive/MyDrive/hong/models/model_decode1_4_customize.pt\")"],"metadata":{"id":"HGQVF7QWoHLO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"gPFUlyc6hUzO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_path = \"/content/drive/MyDrive/hong/model/\"\n","\n","training_args = Seq2SeqTrainingArguments(\n","    output_dir=model_path, #The output directory\n","    overwrite_output_dir=True, #overwrite the content of the output directory\n","    num_train_epochs=100, # number of training epochs\n","    per_device_train_batch_size=10, # batch size for training\n","    per_device_eval_batch_size=10,  # batch size for evaluation\n","    eval_steps=10, # Number of update steps between two evaluations.\n","    save_steps=1000, # after # steps model is saved\n","    logging_steps=10,\n","    warmup_steps=300,# number of warmup steps for learning rate scheduler\n","    prediction_loss_only=True,\n","    evaluation_strategy=\"steps\",\n","    save_total_limit=3\n","    )\n","\n","trainer = Seq2SeqTrainer(\n","    model=model1,\n","    args=training_args,\n","    train_dataset=dataset_train,\n","    eval_dataset=dataset_val,\n",")"],"metadata":{"id":"vF-RCL4HdpL8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["result1 = trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"3I_XLM0ueAH4","executionInfo":{"status":"ok","timestamp":1694681266630,"user_tz":-540,"elapsed":574686,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"23e78367-664e-4c9a-aab5-b80fb413c62f"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1000/1000 09:33, Epoch 100/100]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>4.474300</td>\n","      <td>4.587380</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>4.474300</td>\n","      <td>4.587429</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>4.474200</td>\n","      <td>4.587379</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>4.474200</td>\n","      <td>4.587667</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>4.474200</td>\n","      <td>4.587653</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>4.474100</td>\n","      <td>4.588059</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>4.474100</td>\n","      <td>4.588486</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>4.474100</td>\n","      <td>4.588823</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>4.474000</td>\n","      <td>4.589293</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>4.474000</td>\n","      <td>4.588699</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>4.473900</td>\n","      <td>4.589751</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>4.473900</td>\n","      <td>4.590137</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>4.473800</td>\n","      <td>4.589147</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>4.473800</td>\n","      <td>4.586020</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>4.473700</td>\n","      <td>4.589252</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>4.473600</td>\n","      <td>4.590744</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>4.473500</td>\n","      <td>4.589065</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>4.473500</td>\n","      <td>4.588004</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>4.473400</td>\n","      <td>4.589972</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>4.473300</td>\n","      <td>4.591144</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>4.473200</td>\n","      <td>4.589383</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>4.473100</td>\n","      <td>4.587601</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>4.473100</td>\n","      <td>4.588426</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>4.473000</td>\n","      <td>4.588984</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>4.472900</td>\n","      <td>4.589581</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>4.472800</td>\n","      <td>4.591101</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>4.472700</td>\n","      <td>4.590583</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>4.472600</td>\n","      <td>4.592129</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>4.472500</td>\n","      <td>4.590619</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>4.472400</td>\n","      <td>4.591323</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>4.472400</td>\n","      <td>4.589515</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>4.472300</td>\n","      <td>4.589322</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>4.472300</td>\n","      <td>4.589707</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>4.472800</td>\n","      <td>4.587746</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>4.473800</td>\n","      <td>4.586415</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>4.474500</td>\n","      <td>4.588518</td>\n","    </tr>\n","    <tr>\n","      <td>370</td>\n","      <td>4.473300</td>\n","      <td>4.584833</td>\n","    </tr>\n","    <tr>\n","      <td>380</td>\n","      <td>4.472800</td>\n","      <td>4.586930</td>\n","    </tr>\n","    <tr>\n","      <td>390</td>\n","      <td>4.472200</td>\n","      <td>4.589557</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>4.472100</td>\n","      <td>4.586030</td>\n","    </tr>\n","    <tr>\n","      <td>410</td>\n","      <td>4.472000</td>\n","      <td>4.587753</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>4.471800</td>\n","      <td>4.588959</td>\n","    </tr>\n","    <tr>\n","      <td>430</td>\n","      <td>4.471600</td>\n","      <td>4.589561</td>\n","    </tr>\n","    <tr>\n","      <td>440</td>\n","      <td>4.471600</td>\n","      <td>4.589268</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>4.471400</td>\n","      <td>4.591258</td>\n","    </tr>\n","    <tr>\n","      <td>460</td>\n","      <td>4.471300</td>\n","      <td>4.591585</td>\n","    </tr>\n","    <tr>\n","      <td>470</td>\n","      <td>4.471300</td>\n","      <td>4.592021</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>4.471400</td>\n","      <td>4.593346</td>\n","    </tr>\n","    <tr>\n","      <td>490</td>\n","      <td>4.471200</td>\n","      <td>4.592971</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>4.471100</td>\n","      <td>4.593750</td>\n","    </tr>\n","    <tr>\n","      <td>510</td>\n","      <td>4.471000</td>\n","      <td>4.589377</td>\n","    </tr>\n","    <tr>\n","      <td>520</td>\n","      <td>4.471100</td>\n","      <td>4.593243</td>\n","    </tr>\n","    <tr>\n","      <td>530</td>\n","      <td>4.471200</td>\n","      <td>4.596045</td>\n","    </tr>\n","    <tr>\n","      <td>540</td>\n","      <td>4.470900</td>\n","      <td>4.592538</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>4.470800</td>\n","      <td>4.592530</td>\n","    </tr>\n","    <tr>\n","      <td>560</td>\n","      <td>4.470700</td>\n","      <td>4.592659</td>\n","    </tr>\n","    <tr>\n","      <td>570</td>\n","      <td>4.470600</td>\n","      <td>4.591048</td>\n","    </tr>\n","    <tr>\n","      <td>580</td>\n","      <td>4.470700</td>\n","      <td>4.590173</td>\n","    </tr>\n","    <tr>\n","      <td>590</td>\n","      <td>4.470700</td>\n","      <td>4.589050</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>4.470800</td>\n","      <td>4.590181</td>\n","    </tr>\n","    <tr>\n","      <td>610</td>\n","      <td>4.470500</td>\n","      <td>4.591941</td>\n","    </tr>\n","    <tr>\n","      <td>620</td>\n","      <td>4.470400</td>\n","      <td>4.592202</td>\n","    </tr>\n","    <tr>\n","      <td>630</td>\n","      <td>4.470400</td>\n","      <td>4.591656</td>\n","    </tr>\n","    <tr>\n","      <td>640</td>\n","      <td>4.470300</td>\n","      <td>4.590843</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>4.470300</td>\n","      <td>4.590922</td>\n","    </tr>\n","    <tr>\n","      <td>660</td>\n","      <td>4.470200</td>\n","      <td>4.590419</td>\n","    </tr>\n","    <tr>\n","      <td>670</td>\n","      <td>4.470300</td>\n","      <td>4.590182</td>\n","    </tr>\n","    <tr>\n","      <td>680</td>\n","      <td>4.470100</td>\n","      <td>4.590821</td>\n","    </tr>\n","    <tr>\n","      <td>690</td>\n","      <td>4.470100</td>\n","      <td>4.590858</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>4.470100</td>\n","      <td>4.591011</td>\n","    </tr>\n","    <tr>\n","      <td>710</td>\n","      <td>4.470000</td>\n","      <td>4.590763</td>\n","    </tr>\n","    <tr>\n","      <td>720</td>\n","      <td>4.470100</td>\n","      <td>4.591298</td>\n","    </tr>\n","    <tr>\n","      <td>730</td>\n","      <td>4.470000</td>\n","      <td>4.591371</td>\n","    </tr>\n","    <tr>\n","      <td>740</td>\n","      <td>4.470000</td>\n","      <td>4.591155</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>4.469900</td>\n","      <td>4.591037</td>\n","    </tr>\n","    <tr>\n","      <td>760</td>\n","      <td>4.470000</td>\n","      <td>4.590493</td>\n","    </tr>\n","    <tr>\n","      <td>770</td>\n","      <td>4.469900</td>\n","      <td>4.590034</td>\n","    </tr>\n","    <tr>\n","      <td>780</td>\n","      <td>4.469800</td>\n","      <td>4.590060</td>\n","    </tr>\n","    <tr>\n","      <td>790</td>\n","      <td>4.469800</td>\n","      <td>4.590117</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>4.469800</td>\n","      <td>4.590320</td>\n","    </tr>\n","    <tr>\n","      <td>810</td>\n","      <td>4.469800</td>\n","      <td>4.590575</td>\n","    </tr>\n","    <tr>\n","      <td>820</td>\n","      <td>4.469700</td>\n","      <td>4.590622</td>\n","    </tr>\n","    <tr>\n","      <td>830</td>\n","      <td>4.469700</td>\n","      <td>4.590705</td>\n","    </tr>\n","    <tr>\n","      <td>840</td>\n","      <td>4.469700</td>\n","      <td>4.590587</td>\n","    </tr>\n","    <tr>\n","      <td>850</td>\n","      <td>4.469800</td>\n","      <td>4.590165</td>\n","    </tr>\n","    <tr>\n","      <td>860</td>\n","      <td>4.469700</td>\n","      <td>4.589424</td>\n","    </tr>\n","    <tr>\n","      <td>870</td>\n","      <td>4.469800</td>\n","      <td>4.588962</td>\n","    </tr>\n","    <tr>\n","      <td>880</td>\n","      <td>4.469700</td>\n","      <td>4.588733</td>\n","    </tr>\n","    <tr>\n","      <td>890</td>\n","      <td>4.469600</td>\n","      <td>4.589203</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>4.469600</td>\n","      <td>4.589700</td>\n","    </tr>\n","    <tr>\n","      <td>910</td>\n","      <td>4.469600</td>\n","      <td>4.589860</td>\n","    </tr>\n","    <tr>\n","      <td>920</td>\n","      <td>4.469600</td>\n","      <td>4.589950</td>\n","    </tr>\n","    <tr>\n","      <td>930</td>\n","      <td>4.469500</td>\n","      <td>4.590014</td>\n","    </tr>\n","    <tr>\n","      <td>940</td>\n","      <td>4.469600</td>\n","      <td>4.589827</td>\n","    </tr>\n","    <tr>\n","      <td>950</td>\n","      <td>4.469500</td>\n","      <td>4.589821</td>\n","    </tr>\n","    <tr>\n","      <td>960</td>\n","      <td>4.469600</td>\n","      <td>4.589919</td>\n","    </tr>\n","    <tr>\n","      <td>970</td>\n","      <td>4.469600</td>\n","      <td>4.589978</td>\n","    </tr>\n","    <tr>\n","      <td>980</td>\n","      <td>4.469500</td>\n","      <td>4.590059</td>\n","    </tr>\n","    <tr>\n","      <td>990</td>\n","      <td>4.469500</td>\n","      <td>4.590096</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>4.469500</td>\n","      <td>4.590083</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}}]},{"cell_type":"code","source":["result1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xUQyKkFdf23O","executionInfo":{"status":"ok","timestamp":1694663698252,"user_tz":-540,"elapsed":5,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"07981b30-b410-4110-ab5a-cd3e16b6a323"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=500, training_loss=4.4771444091796875, metrics={'train_runtime': 285.93, 'train_samples_per_second': 17.487, 'train_steps_per_second': 1.749, 'total_flos': 3048682291200000.0, 'train_loss': 4.4771444091796875, 'epoch': 50.0})"]},"metadata":{},"execution_count":198}]},{"cell_type":"code","source":["trainer2 = Seq2SeqTrainer(\n","    model=model2,\n","    args=training_args,\n","    train_dataset=dataset_train,\n","    eval_dataset=dataset_val,\n",")\n","result2 = trainer2.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"KnJ_0mZZUaWD","executionInfo":{"status":"ok","timestamp":1694663891397,"user_tz":-540,"elapsed":193147,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"1b6fedfa-fa2d-403f-8a5c-552f943d0646"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [500/500 03:12, Epoch 50/50]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>0.152800</td>\n","      <td>0.356226</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.151900</td>\n","      <td>0.351845</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.150500</td>\n","      <td>0.345255</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.149100</td>\n","      <td>0.338310</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.148000</td>\n","      <td>0.333093</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.146800</td>\n","      <td>0.330847</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.145900</td>\n","      <td>0.331223</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.144500</td>\n","      <td>0.332150</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.143400</td>\n","      <td>0.332085</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.142200</td>\n","      <td>0.332469</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>0.140600</td>\n","      <td>0.333131</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>0.139100</td>\n","      <td>0.334511</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>0.137500</td>\n","      <td>0.335522</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>0.135600</td>\n","      <td>0.336452</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.133700</td>\n","      <td>0.339196</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>0.131700</td>\n","      <td>0.340016</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>0.129600</td>\n","      <td>0.341937</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>0.127400</td>\n","      <td>0.344256</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>0.125100</td>\n","      <td>0.345519</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.122600</td>\n","      <td>0.346417</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>0.120000</td>\n","      <td>0.350132</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>0.117500</td>\n","      <td>0.351136</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>0.114500</td>\n","      <td>0.353435</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>0.111800</td>\n","      <td>0.354826</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.108800</td>\n","      <td>0.358023</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>0.105500</td>\n","      <td>0.359063</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>0.102300</td>\n","      <td>0.361966</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>0.098900</td>\n","      <td>0.363467</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>0.095400</td>\n","      <td>0.366463</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.091900</td>\n","      <td>0.369100</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>0.088400</td>\n","      <td>0.369627</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>0.084800</td>\n","      <td>0.372101</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>0.081700</td>\n","      <td>0.375482</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>0.078400</td>\n","      <td>0.377573</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.075700</td>\n","      <td>0.377768</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>0.073200</td>\n","      <td>0.380702</td>\n","    </tr>\n","    <tr>\n","      <td>370</td>\n","      <td>0.070700</td>\n","      <td>0.382035</td>\n","    </tr>\n","    <tr>\n","      <td>380</td>\n","      <td>0.068500</td>\n","      <td>0.383758</td>\n","    </tr>\n","    <tr>\n","      <td>390</td>\n","      <td>0.066500</td>\n","      <td>0.383941</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.064700</td>\n","      <td>0.386133</td>\n","    </tr>\n","    <tr>\n","      <td>410</td>\n","      <td>0.063100</td>\n","      <td>0.386814</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>0.061700</td>\n","      <td>0.388015</td>\n","    </tr>\n","    <tr>\n","      <td>430</td>\n","      <td>0.060400</td>\n","      <td>0.389312</td>\n","    </tr>\n","    <tr>\n","      <td>440</td>\n","      <td>0.059300</td>\n","      <td>0.389438</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.058300</td>\n","      <td>0.390113</td>\n","    </tr>\n","    <tr>\n","      <td>460</td>\n","      <td>0.057500</td>\n","      <td>0.390996</td>\n","    </tr>\n","    <tr>\n","      <td>470</td>\n","      <td>0.056900</td>\n","      <td>0.391085</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>0.056400</td>\n","      <td>0.391353</td>\n","    </tr>\n","    <tr>\n","      <td>490</td>\n","      <td>0.056100</td>\n","      <td>0.391523</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.055900</td>\n","      <td>0.391585</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}}]},{"cell_type":"code","source":["result2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_r4ZiS34bjoe","executionInfo":{"status":"ok","timestamp":1694663891399,"user_tz":-540,"elapsed":8,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"e11a67ae-7d85-4961-d618-027bd6a3dc9d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=500, training_loss=0.10406408536434174, metrics={'train_runtime': 193.2364, 'train_samples_per_second': 25.875, 'train_steps_per_second': 2.588, 'total_flos': 3532644679680000.0, 'train_loss': 0.10406408536434174, 'epoch': 50.0})"]},"metadata":{},"execution_count":200}]},{"cell_type":"code","source":["trainer3 = Seq2SeqTrainer(\n","    model=model3,\n","    args=training_args,\n","    train_dataset=dataset_train,\n","    eval_dataset=dataset_val,\n",")\n","result3 = trainer3.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"3g9ieNMycyVf","executionInfo":{"status":"ok","timestamp":1694664119501,"user_tz":-540,"elapsed":228107,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"5d1697d6-e07e-4c80-985c-5369adb29693"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [500/500 03:47, Epoch 50/50]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>0.091400</td>\n","      <td>0.372703</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.090400</td>\n","      <td>0.367883</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.089800</td>\n","      <td>0.362608</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.089100</td>\n","      <td>0.360477</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.088300</td>\n","      <td>0.362141</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.087300</td>\n","      <td>0.363116</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.086400</td>\n","      <td>0.361883</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.085400</td>\n","      <td>0.363213</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.084200</td>\n","      <td>0.362709</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.083200</td>\n","      <td>0.364506</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>0.081700</td>\n","      <td>0.363959</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>0.080400</td>\n","      <td>0.365484</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>0.079100</td>\n","      <td>0.366477</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>0.077400</td>\n","      <td>0.367144</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.075800</td>\n","      <td>0.367309</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>0.074000</td>\n","      <td>0.371205</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>0.072300</td>\n","      <td>0.369741</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>0.070300</td>\n","      <td>0.372742</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>0.068400</td>\n","      <td>0.372623</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.066300</td>\n","      <td>0.374809</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>0.064200</td>\n","      <td>0.375716</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>0.062000</td>\n","      <td>0.378560</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>0.059700</td>\n","      <td>0.378426</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>0.057700</td>\n","      <td>0.382618</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.055200</td>\n","      <td>0.385042</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>0.052900</td>\n","      <td>0.379970</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>0.050500</td>\n","      <td>0.384364</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>0.048100</td>\n","      <td>0.387967</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>0.045800</td>\n","      <td>0.389389</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.043300</td>\n","      <td>0.391062</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>0.041000</td>\n","      <td>0.393100</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>0.038900</td>\n","      <td>0.393324</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>0.036900</td>\n","      <td>0.398053</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>0.035100</td>\n","      <td>0.394676</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.033500</td>\n","      <td>0.401690</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>0.032000</td>\n","      <td>0.401261</td>\n","    </tr>\n","    <tr>\n","      <td>370</td>\n","      <td>0.030900</td>\n","      <td>0.401769</td>\n","    </tr>\n","    <tr>\n","      <td>380</td>\n","      <td>0.029700</td>\n","      <td>0.403340</td>\n","    </tr>\n","    <tr>\n","      <td>390</td>\n","      <td>0.028600</td>\n","      <td>0.403967</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.027700</td>\n","      <td>0.404957</td>\n","    </tr>\n","    <tr>\n","      <td>410</td>\n","      <td>0.027000</td>\n","      <td>0.406686</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>0.026300</td>\n","      <td>0.406177</td>\n","    </tr>\n","    <tr>\n","      <td>430</td>\n","      <td>0.025500</td>\n","      <td>0.407711</td>\n","    </tr>\n","    <tr>\n","      <td>440</td>\n","      <td>0.025100</td>\n","      <td>0.407971</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.024700</td>\n","      <td>0.409777</td>\n","    </tr>\n","    <tr>\n","      <td>460</td>\n","      <td>0.024200</td>\n","      <td>0.409690</td>\n","    </tr>\n","    <tr>\n","      <td>470</td>\n","      <td>0.024100</td>\n","      <td>0.409849</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>0.023800</td>\n","      <td>0.410054</td>\n","    </tr>\n","    <tr>\n","      <td>490</td>\n","      <td>0.023600</td>\n","      <td>0.410408</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.023600</td>\n","      <td>0.410408</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}}]},{"cell_type":"markdown","source":["## 학습 돌리기"],"metadata":{"id":"mol0R9HrM5vI"}},{"cell_type":"code","source":["result = model1.generate(dataset_train[0]['input_ids'].unsqueeze(0).to(device), max_length = 68)\n","predict_text = tokenizer.decode(result[0], skip_special_tokens=True)\n","print(predict_text)\n","print(df['summary'][0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YeHmzRuqeETg","executionInfo":{"status":"ok","timestamp":1694668850061,"user_tz":-540,"elapsed":587,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"f9ae3ffa-aa58-4b05-fd89-0d326635f48c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["DH가 기업가치를 약 4조 8000억 원으로 평가한 우아한형제들의 김 대표는 국내 스타트업 사상 최대 규모의 M&A에 대해 고민하고 있다.\n","DH가 기업가치를 약 4조 8000억 원으로 평가한 우아한형제들의 김 대표는 국내 스타트업 사상 최대 규모의 M&A 이후 합작법인 우아DH아시아의 책임자가 된다.\n"]}]},{"cell_type":"code","source":["result2 = model2.generate(dataset_train[0]['input_ids'].unsqueeze(0).to(device), max_length = 68)\n","predict_text2 = tokenizer.decode(result2[0], skip_special_tokens=True)\n","print(predict_text2)\n","print(df['summary'][0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7J2aLUHveTec","executionInfo":{"status":"ok","timestamp":1694668865106,"user_tz":-540,"elapsed":4,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"4114028b-d8bf-42cd-b411-aaa044130280"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["새해 첫날에도 골프장에 있을 정도로 소문난 골프장에 있을 정도로 소문난 골프장에 있을 정도로 회사가 힘들었는데 이제야 직원 월급을 좀 보전해 중동 지역에 군사적 긴장이 고조되고 있다.\n","DH가 기업가치를 약 4조 8000억 원으로 평가한 우아한형제들의 김 대표는 국내 스타트업 사상 최대 규모의 M&A 이후 합작법인 우아DH아시아의 책임자가 된다.\n"]}]},{"cell_type":"code","source":["result3 = model3.generate(dataset_train[0]['input_ids'].unsqueeze(0).to(device), max_length = 68)\n","predict_text3 = tokenizer.decode(result3[0], skip_special_tokens=True)\n","print(predict_text3)\n","print(df['summary'][0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e3R8F_-EfleO","executionInfo":{"status":"ok","timestamp":1694668866899,"user_tz":-540,"elapsed":601,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"dfecce61-56a0-4ddb-a5f2-66f2cc3ed958"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["이라크 군 기지를 공격받은 미국이 KH에 보복을 가하자 이라크 내 친이란 세력이 반격에 나섰고 주민 2000여명이 찜질방 등으로 대피했으며 공공기관이 아파트 복구를 지원하고 있다.\n","DH가 기업가치를 약 4조 8000억 원으로 평가한 우아한형제들의 김 대표는 국내 스타트업 사상 최대 규모의 M&A 이후 합작법인 우아DH아시아의 책임자가 된다.\n"]}]},{"cell_type":"code","source":["results = []\n","for i in range(100):\n","    result = model1.generate(dataset_train[i]['input_ids'].unsqueeze(0).to(device), max_length = 68)\n","    results.append(result[0])"],"metadata":{"id":"t-A6QKSrgIUT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## ACCURACY찍기!"],"metadata":{"id":"V5cRi0D3n0wV"}},{"cell_type":"markdown","source":["## model1 - decoder 6\n","- 50epoch : accuracy = 0.28719424460431653\n","- 100epoch : accuracy = 0.5628776978417266"],"metadata":{"id":"8WshOb6OlqQL"}},{"cell_type":"code","source":["result = []\n","for i in range(100):\n","    input_ids = tokenizer(df.iloc[i, 0], return_tensors=\"pt\")[\"input_ids\"]\n","    output = model1.generate(input_ids.to(device), max_length = 68)\n","    output_ = tokenizer.decode(output[0], skip_special_tokens=True)\n","    output_ = tokenizer(output_)['input_ids']\n","    result.append(output_)"],"metadata":{"id":"OnWgdl4fv-eW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# label토큰에서 pad빼기 귀찮으니까 그냥 다시 토큰화 해버리기, special token없이\n","target_tokenized = []\n","for i in range(len(df)):\n","    target_text = df.iloc[i, 1]\n","    target_ids = tokenizer(target_text)[\"input_ids\"]\n","    target_tokenized.append(target_ids)"],"metadata":{"id":"JQQicedWcT0S","executionInfo":{"status":"ok","timestamp":1694691510482,"user_tz":-540,"elapsed":1,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["len(target_tokenized)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hxzu8Pd3cIcc","executionInfo":{"status":"ok","timestamp":1694673990969,"user_tz":-540,"elapsed":282,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"03f0acb6-bc6f-4045-a3cc-df8a51d92c85"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["110"]},"metadata":{},"execution_count":305}]},{"cell_type":"code","source":["len(result)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4CfphvqBcSHD","executionInfo":{"status":"ok","timestamp":1694674010631,"user_tz":-540,"elapsed":331,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"d484b9e0-f17e-418f-f7b5-ca3f39ff67b7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["74"]},"metadata":{},"execution_count":306}]},{"cell_type":"code","source":["# count는 예측이랑 정답의 같은 위치에 같은 토큰이 있을경우 +1\n","# total은 정답 토큰 총 개수\n","result = []\n","for i in range(100):\n","    input_ids = tokenizer(df.iloc[i, 0], return_tensors=\"pt\")[\"input_ids\"]\n","    output = model1.generate(input_ids.to(device), max_length = 68)\n","    output_ = tokenizer.decode(output[0], skip_special_tokens=True)\n","    output_ = tokenizer(output_)['input_ids']\n","    result.append(output_)\n","\n","\n","count = 0\n","total = 0\n","for i in range(100):\n","    if len(result[i]) < len(target_tokenized[i]):\n","        total += len(target_tokenized[i])\n","        for j in range(len(result[i])):\n","            count += int(result[i][j] == target_tokenized[i][j])\n","    else:\n","        total += len(result[i])\n","        for j in range(len(target_tokenized[i])):\n","            count += int(result[i][j] == target_tokenized[i][j])\n","\n","print(count/total)"],"metadata":{"id":"8aqeyJNSc1M9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1694681343701,"user_tz":-540,"elapsed":403,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"6dd429cf-5525-4f42-d7e1-20ebe21cd68d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.7379875635952515\n"]}]},{"cell_type":"markdown","source":["## model2 - decoder 1 + custom_fclayer\n","- 50epoch : accuracy = 0.0031654676258992807\n","- 100epoch : accuracy = 0.005179856115107914"],"metadata":{"id":"MK3Y8O6tmhcj"}},{"cell_type":"code","source":["result2 = []\n","for i in range(100):\n","    input_ids = tokenizer(df.iloc[i, 0], return_tensors=\"pt\")[\"input_ids\"]\n","    output = model2.generate(input_ids.to(device), max_length = 68)\n","    output_ = tokenizer.decode(output[0], skip_special_tokens=True)\n","    output_ = tokenizer(output_)['input_ids']\n","    result2.append(output_)"],"metadata":{"id":"sGfCFWatmTpe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["count = 0\n","total = 0\n","for i in range(100):\n","    if len(result2[i]) < len(target_tokenized[i]):\n","        total += len(target_tokenized[i])\n","        for j in range(len(result2[i])):\n","            count += int(result2[i][j] == target_tokenized[i][j])\n","    else:\n","        total += len(result2[i])\n","        for j in range(len(target_tokenized[i])):\n","            count += int(result2[i][j] == target_tokenized[i][j])\n","\n","print(count/total)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JrS8BKpwnFID","executionInfo":{"status":"ok","timestamp":1694673884091,"user_tz":-540,"elapsed":327,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"e21e517a-682c-47cc-bfa4-3e3cd7251974"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.00456158134820071\n"]}]},{"cell_type":"markdown","source":["## model3 - decoder 2 + custom_fclayer\n","- 50epoch : accuracy = 0.004028776978417266\n","- 100epoch : accuracy = 0.004316546762589928"],"metadata":{"id":"G4TcpBRlsZwH"}},{"cell_type":"code","source":["result3 = []\n","for i in range(100):\n","    input_ids = tokenizer(df.iloc[i, 0], return_tensors=\"pt\")[\"input_ids\"]\n","    output = model3.generate(input_ids.to(device), max_length = 68)\n","    output_ = tokenizer.decode(output[0], skip_special_tokens=True)\n","    output_ = tokenizer(output_)['input_ids']\n","    result3.append(output_)"],"metadata":{"id":"vJghFyv3sZL5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["count = 0\n","total = 0\n","for i in range(100):\n","    total += len(target_tokenized[i])\n","    if len(result3[i]) < len(target_tokenized[i]):\n","        for j in range(len(result3[i])):\n","            count += int(result3[i][j] == target_tokenized[i][j])\n","    else:\n","        for j in range(len(target_tokenized[i])):\n","            count += int(result3[i][j] == target_tokenized[i][j])\n","\n","print(count/total)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sKkqjD9nskjZ","executionInfo":{"status":"ok","timestamp":1694667246171,"user_tz":-540,"elapsed":296,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"8e649c45-fe62-4541-fdb5-da3ec8bd06e5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.004316546762589928\n"]}]},{"cell_type":"markdown","source":["## model4 - decoder[0] + custom_decoder[1:5] + decoder[5]\n","- 50epoch : accuracy = 0.004028776978417266\n","- 100epoch : accuracy = 0.004316546762589928"],"metadata":{"id":"zCSuzKclq1sG"}},{"cell_type":"code","source":["result4 = []\n","for i in range(100):\n","    input_ids = tokenizer(df.iloc[i, 0], return_tensors=\"pt\")[\"input_ids\"]\n","    output = model4.generate(input_ids.to(device), max_length = 68)\n","    output_ = tokenizer.decode(output[0], skip_special_tokens=True)\n","    output_ = tokenizer(output_)['input_ids']\n","    result4.append(output_)"],"metadata":{"id":"idxrn88uq1dk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["count = 0\n","total = 0\n","for i in range(100):\n","    total += len(target_tokenized[i])\n","    if len(result4[i]) < len(target_tokenized[i]):\n","        for j in range(len(result4[i])):\n","            count += int(result4[i][j] == target_tokenized[i][j])\n","    else:\n","        for j in range(len(target_tokenized[i])):\n","            count += int(result4[i][j] == target_tokenized[i][j])\n","\n","print(count/total)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iyee2eidrPxM","executionInfo":{"status":"ok","timestamp":1694680219046,"user_tz":-540,"elapsed":272,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"6dab0d4d-0ca9-4c12-e540-872f1ce44fc7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.6463309352517985\n"]}]},{"cell_type":"code","source":["print(df['summary'][101])\n","input = torch.LongTensor(tokenizer(df['summary'][101], padding=\"max_length\", max_length=1024, truncation=True)[\"input_ids\"])\n","print(\"model1 :\", tokenizer.decode(model4.generate(input.unsqueeze(0).to(device), max_length = 68)[0], skip_special_tokens=True))\n","print(\"-\"*50)\n","print(df['summary'][102])\n","input = torch.LongTensor(tokenizer(df['summary'][102], padding=\"max_length\", max_length=1024, truncation=True)[\"input_ids\"])\n","print(\"model1 :\", tokenizer.decode(model4.generate(input.unsqueeze(0).to(device), max_length = 68)[0], skip_special_tokens=True))\n","print(\"-\"*50)\n","print(df['summary'][103])\n","input = torch.LongTensor(tokenizer(df['summary'][103], padding=\"max_length\", max_length=1024, truncation=True)[\"input_ids\"])\n","print(\"model1 :\", tokenizer.decode(model4.generate(input.unsqueeze(0).to(device), max_length = 68)[0], skip_special_tokens=True))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5__K02VnrWd8","executionInfo":{"status":"ok","timestamp":1694680521868,"user_tz":-540,"elapsed":1872,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"e1781774-85b0-4e65-e192-6ddcb3cb3bcc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["미국과 이란의 상태가 심상치 않은 것은 바다 건너 불구경할 일이 아니며 한국 주식시장에서 보유한 주식의 값어치를 떨어뜨릴 수도 있고 휘발유 가격은 더 올릴 공산이 크다.\n","model1 : 미국과 이란 이란의 상태가 심상치 않은 상태가 심상치 않은 상태가 심상치 않은 상태가 심상치 않은 상태가 심상치 않은 상태가 상태가 상태가 심상치 않은 상태가 심상치 않은 상태가 상태가 심상치 않은 상태가 심상치 않은 상태가 심상치 않은 상태가 심상치 않은 상태가 심상치 않은 상태가 심상치 않은 상태가 심상치 않은 상태가 심상치\n","--------------------------------------------------\n","경기 하락에 따른 소비 심리 부진 등의 영향으로 자동차 시장은 혹한기였지만 현대차는 신차 효과에 힘입어 베스트셀링카 경쟁에서 톱 1~3위를 휩쓸었다.\n","model1 : 경기 하락 하락 하락 하락 하락 하락 하락 하락 하락 하락 하락 하락 하락 하락 하락 하락 하락 하락 하락 하락 하락 하락 하락 하락 하락 하락 하락 하락 하락 하락 하락 하락 하락 하락 하락 하락 하락 하락 하락 하락 하락 하락 하락 하락 하락 하락 하락 하락 하락 하락 하락 하락 하락 하락 하락 하락 하락 하락 하락 하락 하락 하락 하락 하락 하락\n","--------------------------------------------------\n","구설에 오르고 있는 청와대 국가안보실의 김 2차장과 최 평화기획비서관의 갈등설에 대해 외교관들이 소문을 과장시키고 있다고 청와대는 의심하고 있다.\n","model1 : 구설에설에설에설에설에설에설에설에설에설에설에설에설에설에설에설에설에설에설에설에설에설에설에설에설에설에설에설에설에설에설에설에설에설에설에설에설에설에설에설에설에설에설에설에설에설에설에설에설에설에설에설에설에설에설에설에설에설에설에설에설에설에설에설에설에\n"]}]},{"cell_type":"markdown","source":["## Model5 - decoder[0] + custom_decoder[1:5] + decoder[5]\n","\n","- 전체 디코더 학습\n","-fclayer: 768 - 2048 - 768"],"metadata":{"id":"GXJOTgRAeg7D"}},{"cell_type":"code","source":["result5 = []\n","for i in range(100):\n","    input_ids = tokenizer(df.iloc[i, 0], return_tensors=\"pt\")[\"input_ids\"]\n","    output = model5.generate(input_ids.to(device), max_length = 68)\n","    output_ = tokenizer.decode(output[0], skip_special_tokens=True)\n","    output_ = tokenizer(output_)['input_ids']\n","    result5.append(output_)"],"metadata":{"id":"hyq3fd7fepDT","executionInfo":{"status":"ok","timestamp":1694692959391,"user_tz":-540,"elapsed":25398,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["count = 0\n","total = 0\n","for i in range(100):\n","    total += len(target_tokenized[i])\n","    if len(result5[i]) < len(target_tokenized[i]):\n","        for j in range(len(result5[i])):\n","            count += int(result5[i][j] == target_tokenized[i][j])\n","    else:\n","        for j in range(len(target_tokenized[i])):\n","            count += int(result5[i][j] == target_tokenized[i][j])\n","\n","print(count/total)"],"metadata":{"id":"390IWkYorWYq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1694692959391,"user_tz":-540,"elapsed":7,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"cf29a69f-d6a4-42bb-99e1-79720fa85e51"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["0.6287769784172662\n"]}]},{"cell_type":"code","source":["print(df['summary'][101])\n","input = torch.LongTensor(tokenizer(df['summary'][101], padding=\"max_length\", max_length=1024, truncation=True)[\"input_ids\"])\n","print(\"model1 :\", tokenizer.decode(model5.generate(input.unsqueeze(0).to(device), max_length = 68)[0], skip_special_tokens=True))\n","print(\"-\"*50)\n","print(df['summary'][102])\n","input = torch.LongTensor(tokenizer(df['summary'][102], padding=\"max_length\", max_length=1024, truncation=True)[\"input_ids\"])\n","print(\"model1 :\", tokenizer.decode(model5.generate(input.unsqueeze(0).to(device), max_length = 68)[0], skip_special_tokens=True))\n","print(\"-\"*50)\n","print(df['summary'][103])\n","input = torch.LongTensor(tokenizer(df['summary'][103], padding=\"max_length\", max_length=1024, truncation=True)[\"input_ids\"])\n","print(\"model1 :\", tokenizer.decode(model5.generate(input.unsqueeze(0).to(device), max_length = 68)[0], skip_special_tokens=True))\n"],"metadata":{"id":"nfsaiQPgrWRb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1694692961011,"user_tz":-540,"elapsed":1624,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"70d83761-64a5-4382-dd7a-fc09578e6ce7"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["미국과 이란의 상태가 심상치 않은 것은 바다 건너 불구경할 일이 아니며 한국 주식시장에서 보유한 주식의 값어치를 떨어뜨릴 수도 있고 휘발유 가격은 더 올릴 공산이 크다.\n","model1 : 미국과 이란 이란의 상태가 심상치 않은 상태가 심상 심상 심상 심상 않은 상태가 심상 심상 심상 않은 상태가 상태가 상태가 상태가 상태가 상태가 상태가 상태가 상태가 상태가 상태가 상태가 상태가 상태가 상태가 상태가 상태가 상태가 상태가 상태가 상태가 상태가 상태가 상태가 상태가 상태가 상태가 상태가 상태가 상태가 상태가 상태가 상태가 상태가 상태가 상태가 상태가 심상 심상 심상 심상 심상 심상 심상 심상 심상 심상\n","--------------------------------------------------\n","경기 하락에 따른 소비 심리 부진 등의 영향으로 자동차 시장은 혹한기였지만 현대차는 신차 효과에 힘입어 베스트셀링카 경쟁에서 톱 1~3위를 휩쓸었다.\n","model1 : 베스트셀링카 경쟁에서 톱 1~3위를 차지했지만 신차 효과에 힘입어 베스트셀링카 경쟁에서 톱 1~3위를 휩쓸은 신차 효과에 뛰어난 뛰어난 뛰어난 뛰어난 뛰어난 뛰어난 뛰어난 뛰어난 뛰어난 뛰어난 뛰어난 뛰어난 뛰어난 뛰어난 뛰어난 뛰어난 뛰어난 뛰어난 뛰어난 뛰어난 뛰어난 뛰어난 뛰어난 뛰어난 뛰어난 뛰어난 뛰어난 뛰어난 뛰어난 뛰어난 뛰어난 뛰어난 뛰어난\n","--------------------------------------------------\n","구설에 오르고 있는 청와대 국가안보실의 김 2차장과 최 평화기획비서관의 갈등설에 대해 외교관들이 소문을 과장시키고 있다고 청와대는 의심하고 있다.\n","model1 : 설에 대한설에설에 대한 외교관들이 소문을 과장시키고 있다고 청와대는 의심하고 있으며 외교관들이 소문을 과장하는데 외교관들이 소문에 과장하는데 외교관들이 소설에 과장하는데 외교관에 외교관에 주장에 주장에 주장에 주장에 주장에 주장에 주장에 주장에 주장에 주장에 주장에 주장에 주장에 주장에 주장에 주장에 주장에 주장에 주장에 주장에 주장에 주장에 주장에 주장에\n"]}]},{"cell_type":"code","source":["tokenizer.decode(model1.generate(input.unsqueeze(0).to(device), max_length = 68)[0], skip_special_tokens=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":54},"id":"ihSpdPY7y5sg","executionInfo":{"status":"ok","timestamp":1694667358127,"user_tz":-540,"elapsed":450,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"1e6d6e65-52aa-49e9-fdf3-01279531c1e6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'국내 스타트업 사상 최대 규모의 M&A 이후 합작법인 우아DH아시아의 책임자가 되는 김 대표는 국내 스타트업 사상 최대 규모의 M&A 이후 합작법인 우아DH아시아의 책임자가 된다.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":213}]},{"cell_type":"code","source":["print(df['summary'][0])\n","input = torch.LongTensor(tokenizer(df['summary'][0], padding=\"max_length\", max_length=1024, truncation=True)[\"input_ids\"])\n","print(\"model1 :\", tokenizer.decode(model1.generate(input.unsqueeze(0).to(device), max_length = 68)[0], skip_special_tokens=True))\n","print(\"model2 :\", tokenizer.decode(model2.generate(input.unsqueeze(0).to(device), max_length = 68)[0], skip_special_tokens=True))\n","print(\"model3 : \", tokenizer.decode(model3.generate(input.unsqueeze(0).to(device), max_length = 68)[0], skip_special_tokens=True))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2-Yc-03OnOHx","executionInfo":{"status":"ok","timestamp":1694667360115,"user_tz":-540,"elapsed":719,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"3946e7c3-6600-4088-a658-6d696b08c28b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["DH가 기업가치를 약 4조 8000억 원으로 평가한 우아한형제들의 김 대표는 국내 스타트업 사상 최대 규모의 M&A 이후 합작법인 우아DH아시아의 책임자가 된다.\n","model1 : 국내 스타트업 사상 최대 규모의 M&A 이후 합작법인 우아DH아시아의 책임자가 되는 김 대표는 국내 스타트업 사상 최대 규모의 M&A 이후 합작법인 우아DH아시아의 책임자가 된다.\n","model2 : 새해 첫날에도 소개됐던 쓰레기 산둥함과 미국 링컨함 등을 항모로 개조할 수 있다는 전망이 나오는 가운데 WHO 선임고문 스나이더는 추가 사실이 확인되면 공개한다고 밝혔다.\n","model3 :  이라크 군 기지를 공격받은 미국이 KH에 보복을 가하자 이라크 내 친이란 세력이 반격에 나섰고 주민 2000여명이 찜질 수 있다는 전망이 나오는 가운데 김 건국대 소비자학과 교수는 유통산업의 일자리가 감소하고 있다.\n"]}]},{"cell_type":"code","source":["print(df['summary'][1])\n","input = torch.LongTensor(tokenizer(df['summary'][1], padding=\"max_length\", max_length=1024, truncation=True)[\"input_ids\"])\n","print(\"model1 :\", tokenizer.decode(model1.generate(input.unsqueeze(0).to(device), max_length = 68)[0], skip_special_tokens=True))\n","print(\"model2 :\", tokenizer.decode(model2.generate(input.unsqueeze(0).to(device), max_length = 68)[0], skip_special_tokens=True))\n","print(\"model3 : \", tokenizer.decode(model3.generate(input.unsqueeze(0).to(device), max_length = 68)[0], skip_special_tokens=True))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gk2NkbRGC_pW","executionInfo":{"status":"ok","timestamp":1694667399858,"user_tz":-540,"elapsed":710,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"7dd64c3a-541a-4ccd-e7e8-c5c8f96ce41f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["한·중관계가 중국 쪽으로 기울어진 비대칭관계로 바뀌면서 세계무대에서 한국의 경제 지위 하강은 중국이 한국의 몸값을 더욱 낮게 볼 수 있다.\n","model1 : 중국이무대에서 한국의 경제 지위 하강은 중국이 한국의 몸값을 더욱 낮게 볼 수 있으며 중국이 한국의 몸값을 더욱 낮게 볼 수 있다.\n","model2 : 새해 첫날에도 골프장에 있을 정도로 소문난 골프장에 있을 정도로 소문난 골프장에 있을 정도로 소문난 골프장에 갔고 주민 2000여명이 찜질방어를 위해 항공모라토리엄 철회로 꼽힌다.\n","model3 :  이라크 주재 미국대사관을 습격한 시위대가 바그다드 주재 미국 대사관을 습격하여 대사관에 불을 지르자 미국 정치권에서는 부정적 여론이 커지고 있다.\n"]}]},{"cell_type":"code","source":["print(df['summary'][2])\n","input = torch.LongTensor(tokenizer(df['summary'][2], padding=\"max_length\", max_length=1024, truncation=True)[\"input_ids\"])\n","print(\"model1 :\", tokenizer.decode(model1.generate(input.unsqueeze(0).to(device), max_length = 68)[0], skip_special_tokens=True))\n","print(\"model2 :\", tokenizer.decode(model2.generate(input.unsqueeze(0).to(device), max_length = 68)[0], skip_special_tokens=True))\n","print(\"model3 : \", tokenizer.decode(model3.generate(input.unsqueeze(0).to(device), max_length = 68)[0], skip_special_tokens=True))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"itYBrmpTDKy4","executionInfo":{"status":"ok","timestamp":1694667425716,"user_tz":-540,"elapsed":435,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"4642e788-cf45-4a55-8202-88abf1cdd27d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["사드에 관한 3불이 결국은 중국이 한국을 압박할 수 있는 카드이며 미국이 중거리 미사일을 한국에 배치하면 중국은 3불 위반으로 몰아갈 수 있고 관계는 다시 악화될 것이다.\n","model1 : 사드에 관한 3불이 결국은 중국이 한국을 압박할 수 있는 카드이며 미국이 중거리 미사일을 한국에 배치하면 중국은 3불 위반으로 몰아갈 수 있고 관계는 다시 악화될 것이다.\n","model2 : 새해 첫날에도 골프장에 있을 정도로 소문난 골프장에 있을 정도로 소문난 골프장에 있을 정도로 소문난 골프장에 갔고 주민 2000여명이 찜질 수 있다는 전망이 나오는 가운데 WHO 선임고문 스나이더는 추가 사실이 확인되면 공개한다고 밝혔다.\n","model3 :  이라크 주재 미국대사관을 습격한 시위대가 미국 영사관을 습격하여 대사관에 불을 지르자 미국 대사가 목숨을 잃자 트럼프 대통령은 이란 총사령관 제거를 위한 정책을 추진한다고 밝혔다.\n"]}]},{"cell_type":"markdown","source":["## 결과 저장"],"metadata":{"id":"G9g0H3r_Wkwn"}},{"cell_type":"code","source":["predict = []\n","for sentence in df['passage']:\n","    input = torch.LongTensor(tokenizer(sentence, padding=\"max_length\", max_length=1024, truncation=True)[\"input_ids\"])\n","    result = tokenizer.decode(model5.generate(input.unsqueeze(0).to(device), max_length = 68)[0], skip_special_tokens=True)\n","    predict.append(result)\n","predict"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FhlymZa4WkYY","executionInfo":{"status":"ok","timestamp":1694692989338,"user_tz":-540,"elapsed":28329,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"eddf1153-0b1c-4f68-fe97-96d7496a71e3"},"execution_count":37,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['DH가 기업가치를 약 4조 8000억 원으로 평가한 우아한형제들의 김 대표는 국내 상장으로 이룬 이룬 이룬 이룬 이룬 이룬 이룬 이룬 이룬 이룬 이룬 이룬 이룬 이룬 이룬 이룬 이룬 이룬 이룬 이룬 이룬 이룬 이룬 이룬 이룬 이룬 이룬 이룬 이룬 이룬 이룬 이룬 이룬 이룬 이뤘 이뤘 이뤘 이뤘 이뤘 이뤘',\n"," '한·중관계가 중국 쪽으로 기울어진 비대칭관계로 서서히 바뀐 것은 격세지감을 느낄 정도로 중국의 위상이 높아짐에 따른 양자관계 변화가 저변에 깔려 있다.',\n"," '사드에 관한 3불이 결국은 중국이 한국을 압박할 수 있는 카드이며 미국이 중거리 미사일을 한국에 배치하면 중국은 3불 위반으로 몰아갈 수 있고 관계는 다시 악화될 것이다.',\n"," '배달의민족이 독일 자본에 매각된 것을 놓고 민족 정서를 배반했다며 분노가 터져 나왔지만 40억 달러에 매각된 것은 디지털 혁명 시대를 알리는 가장 분명한 신호이다.',\n"," '북한은 후 국무위원장과 이일환 당 부위원장을 임명한 노동당 전원회의에서 노두철 경질을 추정케 하는 대목이다.',\n"," '부산 해운대의 상징이던 그랜드호텔이 경기 침체와 적자 경영으로 폐업이 불가피하다고 밝혔으나 노조 측은 고용 승계를 피하려는 위장 폐업이라고 주장하고 있다.',\n"," '워런은 샌더스가 심근경색으로 쓰러진 영향과 트럼프의 대척점에 선 신선한 이미지의 정치인으로 아이오와주 등에서의 여론조사에서 바이든을 누르기도 한 하반기 최고 관심 후보였다.',\n"," '김 김 국무위원장은 2012년 집권 이후 처음으로 신년사 육성 연설에 모습을 드러내지 않는 대신 전원회의를 개최했다.',\n"," '국내 이동통신 3사는 산토끼를 잡느라 집토끼를 위한 서비스에 인색하다는 지적에 대해 장기가입자에 대한 혜택이 점차 늘어나고 있다고 반박했다. ',\n"," '출국 금지 등을 조건으로 보석을 허가 받은 닛산자동차의 전 회장이 레바논에 있다는 성명을 발표했다.',\n"," '방탄소년단이 새해에 미국 프로그램 딕클락스 뉴 이어스 로킹 이브에 출연했으며 뉴욕 타임스 스퀘어 무대에서 공연을 시작했다.',\n"," '현금 이외의 수단으로 결제한 돈이 많이 늘어났지만 혜택이나 부가 서비스에 만족하는 사람은 적은데 공제율 자체는 체크카드가 좋지만 지출이 25%를 넘으면 공제를 받을 수 있다. ',\n"," '미국은 우주 개발을 빠르게 확대하고 있는 중국을 견제하기 위해 아르테미스 계획의 참여를 일본에 제안했다.',\n"," '여야 의원 8명이 일찍부터 총선 예비후보로 등록하여 본격적인 선거운동에 돌입했다.',\n"," '정부는 반도체 업황 회복 가능성에 크게 기대하고 있으며 여러 전문가과 기관도 반도체 업황 회복에 따라 수출이 증가세로 돌아설 것이라고 예상한다.',\n"," '황 대표가 정치적 통합을 추진하겠다고 밝혔지만 당 안팎에서는 원론적인 수준에서만 통합을 거론한다는 비판이 나왔다. ',\n"," '1946년 대한노총으로 출범한 이래 73년의 유구한 역사를 이어온 한국노총은 72년만에 민주노총에 제1노총의 지위를 내주며 시련을 맞았다. ',\n"," '북한이 국무부 부자완과 대북특별대표와 전화 통화에서 최악은 피했다는 의견을 공유했다.',\n"," '타다의 드라이버는 파견 근로자로 이뤄져 있으며 노동계는 타다가 파견 근로법을 위반했다고 주장하고 있고 이에 대해 타다는 파견을 받거나 프리랜서를 알선할 수밖에 없다고 주장한다.',\n"," '울산시 송 경제부시장의 구속영장이 기각된 이유는 검찰 수사를 더 지켜볼 필요가 있다는 법원의 판단 때문이다. ',\n"," '박지원 대안신당 의원이 자유한국당 이 총리가 종로 출마하면 못 올 것이라고 전망한 이 총리의 종로 출마 가능성에 대해 본인이 똑바로 제대로 얘기를 할 때 효과가 있다고 강조했다.',\n"," '성동구 마장동의 한 아파트 지하 공용 보일러실에서 불이 나 가스와 전기 수도가 끊겼고 주민 2000여명이 찜질방 등으로 대피했으며 공공기관이 아파트 복구를 지원하고 있다.',\n"," '워크아웃을 졸업하고 2014년 군산으로 내려온 SBC의 신 상무는 임대료를 감당하기 힘들 정도로 회사가 힘들었는데 이제야 좀 보전해 줄 수 있게 됐다고 말했다.',\n"," '반도체 업황에 기대감이 커지며 증권가와 IT 업계에선 D램 가격이 오를 수 있다는 전망이 나오는 가운데 김 팀장은 삼성전자나 SK하이닉스 주가는 올라갈 여지가 있다고 설명했다.',\n"," '스포츠 리얼리티 예능 씨름의 희열이 첫 방송에서 2%의 시청률을 기록하자 방송가는 기대 이상 선전이라고 평했다.',\n"," '손중권 전 동양대 교수가 유시민 노무현재단 이사장이 맞붙은 MBC 신년특집 토론에서 오론론과 실실 보고도 정면으로 반박했다.',\n"," '극단의 목소리를 아우르는 중간지대가 없어진 대한민국 정치는 광장 정치만 요란하며 최 교수는 정치 현실을 크게 개선돼야 할 상황이라고 말했다.',\n"," '이라크 군 기지를 공격받은 친이란 세력이 반격에 나섰고 미국은 이에 강력히 대응하기로 했다.',\n"," '이라크 이라크 시설에 대한 위협 수위가 높아진 것에 대해 이란이 강력히 규탄하고 트럼프 대통령은 이란이 책임져야 한다고 밝혔다.',\n"," '김 국무위원장의 노동당 중앙위 전원회의 보고에서 표현이 모호하지만 그동안의 모라토리엄을 파기하겠다는 이야기로 보이는 메시지를 전했고 미국 정치권에서는 트럼프 대통령을 비난하지 않은 것으로 평가했다.',\n"," '한국노총은 1946년 3월 대한노총으로 출범한 이래 2018년 민주노총에 제1노총의 지위를 내줬으며 정부의 비정규직 정규직화와 같은 정책이 결정적 역할을 했다.',\n"," '한국 여성 예능의 약진에는 평론가 정 씨는 여성 예능인층이 두터워지면서 예능 프로그램의 다양화에도 일조하고 있다고 평했다. ',\n"," '조 위원은 1433편의 한국영 영화를 분석한 결과 남녀 감독 성비가 9대1 에 머물고 있다고 분석했다. ',\n"," '위성사진 한 컷에 잡힌 중국 산둥함과 미국 링컨함의 모습이 대치 상황으로 해석되고 있는 와중에 미·중 양국 정부가 모두 침묵하고 있어 진위 논쟁이 뜨겁게 일고 있다.',\n"," '더불어민주당은 육군 대장 출신인 김병주 전 한미연합사령부 부사령관을 영입했다고 밝혔으나 당 전략에 실질적인 도움을 줄 수 있는 외교안보 전문가 영입에 해당했다고 말했다.',\n"," '아베 총리의 후임자가 누가 될지 관심이 쏠리고 있는 가운데 신년 인터뷰에서 아베 총리가 기시다파 출신을 치켜세우는 발언을 하여 화제가 되고 있다.',\n"," '정의롭고 자신감 넘치는 모습의 정의 부회장은 신년회에서 스타트업 창업가와 같은 마인드로 창의적 사고와 도전적 실행을 해주기 바란다고 말했다.',\n"," '김 북한 국무위원장이 육성 신년사를 요약 내용으로 대체한 데 이어 최고인민회의에서 국가기관 간부들을 새 인물로 교체했다.',\n"," '정부가 5세대 이동통신의 성과를 이어가기 위해 5G 기지국 등록세 완화 등 3대 패키지를 약속하며 기술정보통신부는 관련 사업 육성을 위한 정책을 추진한다고 밝혔다.',\n"," '학창시절 왕따 피해 경험이 있는 이성수 교수는 왕따 문제는 학교 뿐 아니라 사회와 온라인에서까지 골칫거리가 됨을 진단하고 모두가 힘을 합쳐 극복해야 하는 숙제라고 말했다.',\n"," '1인 가구 증가 등으로 음식 서비스 시장이 가파르게 상승하고 있고 11월 코리안세일페스타 등 대규모 할인행사가 겹치면서 온라인 쇼핑 거래액은 처음으로 월 1조원을 넘어섰다.',\n"," '이라크 이란이 평화와 분쟁에서 갈등이 커져 미국은 강경한 태도로 일관했다.',\n"," '자생한방병원 박 원장은 얼굴로만 웃기보다 손뼉을 치거나 발을 구르며 웃는 것이 더 효과적이라고 말했다.',\n"," '한 베이부머의 맏형 격인 55년생이 올해 만 65세, 법정 노인이 되기 때문에 준비 부족은 여전지만 부모들은 부양에 대한 지출은 만만찮다고 하소연을 하니 아이들이 \"이해를 못 하겠다\"고 했다.',\n"," '새해 주요 기업들의 신년사 화두는 단연 생존이었고 미래 먹거리 부재 규제로 인한 신기술 활용 애로 등 국내외 난관을 극복하기 위한 도전과 변화에 초점이 맞춰졌다.',\n"," '도넛 베를리너는 발효 반죽을 기름에 튀겨낸 도넛의 일종이며 행운을 상징하는 랍펜이나 판쿠헨이라고도 부른다.',\n"," '국내 외식소비 형태를 살펴보면 방문해서 식사할 때는 한식이 60% 중식과 패스트푸드가 각각 6%를 차지하고 배달업종의 경우에는 치킨이 50%, 중식 23%를 차지하고 있다.',\n"," '한밤중에 늑대가 잠든 양 떼를 공격하는 일이 가끔 있어서 늑대를 쫓기 위해 모닥불을 피우거나 전기 펜스를 치고 자주 출몰하면 우리 자체를 딴 데로 옮겨야 한다.',\n"," '이탈리아 위키키키키키키키키키키키키키키키키키키키키키키키키키키키키키키키키키키키키키키키키키키키키키키키키키키키키키키키키키키키키키키키',\n"," '신규와 쿠팡의 신규 물류센터에서 물건을 분류하는 단순 노동은 대부분 자동화 돼 있어 사람이 필요하지 않은 구조에 대해 김 건국대 소비자학과 교수는 유통산업의 일자리가 감소하고 있다고 말했다.',\n"," '구글에 소속된 사람분석 팀의 분석 결과 회사는 관리자가 필요하며 좋은 관리자의 유무가 팀원의 능률과 커리어 개발 등에 영향을 미친다.',\n"," '북한이 김 위원장은 미국이 합동군사연습 등으로 압살하려는 야망에 변함이 없음을 보였다고 말하며 핵‧미사일 모라토리엄 철회로 새로운 도전을 시사했다.',\n"," '레바논 당국자가 곤으로 보이는 남성이 프랑스 여권으로 입국했다고 밝힘에 따라 일본을 무단 출국한 곤이 레바논 당국과 사전에 논의했을 가능성이 거론된다.',\n"," '주택연금은 고령자가 소유한 주택을 맡기고 연금을 받는 국가가 보증하는 상품으로 인기 비결은 거주에 지장을 주지 않고 현재의 부담을 덜어주자고 판단한 부모가 많아졌기 때문이다.',\n"," '세종시가 ITX 정부세종청사역 건설을 추진하고 있으며 기존 철도망 등을 활용해 정부세종청사와 서울을 직통으로 연결하는 국철 신설 방안을 검토하고 있다. ',\n"," '주택·수·축산업이 미래로 가기 위해서는 강점이 있는 기존 산업에 대해 투자하고 문화 예술 지식인을 키우며 사회공동체 개념을 넣은 도심을 개발해야 한다.',\n"," '이 당 부위원장 겸 국제부장과 이 외무상이 5차 전원회의에 자리한 것으로 파악했지만 단체 기념사진에서 모습이 보이지 않아 해임됐을 가능성이 제기하고 있다.',\n"," '이 삼성전자 부회장은 세계 최초 3나노 반도체 공정을 개발 중인 경기도 화성 사업장을 찾아가 반도체 부문 사장단에게 기술 관련 보고를 받고 차세대 반도체 전략을 논의했다.',\n"," '여객택시의 사납금 제도가 폐지되면서 법인택시의 기사의 해방절이라는 말이 나왔지만 사납급 폐지 첫날부터 현장은 우왕좌왕했다.',\n"," '축구를 시작할 때부터 올림픽 무대를 꿈꿔온 백 씨는 도쿄 올림픽 출전에 대한 포부를 표했으나 팀의 핵심 전력이다 보니 출전할 수 없게 되었다.',\n"," '새해 첫날에도 골프장에 있을 정도로 소문난 골프 애호가인 도널드 트럼프 미국 대통령은국정 운영 중 생긴 스트레스를 풀기 위해 평균 5일에 한 번씩 골프장에 갔다.',\n"," '인천시 부일여자중학교는 교가·교훈을 대폭 손질했고 여성 역할을 강화한다는 지적이 나온 뒤 공모전을 열고 자문도 진행했다.',\n"," '집권 후 처음으로 신년사를 생략한 김정은에 대해 태영호 전 영국주재 북한공사는 희망을 줄 소식이 없으니 새로운 전략무기를 예고하는 전원회의 내용으로 대신한 듯하다고 말했다.',\n"," '여 의원은 불출마 선언을 하며 당 지도부에 심한 불만이라고 말했고 당 지도부의 용퇴를 촉구하며 비대위 체제로 가기 위해 당 지도부가 모든 걸 내려놔야 한다고 했다.',\n"," '문 대통령은 정부 신년합동인사회에서 우리 국민은 상생 도약으로 잘 사는 나라의 국민이 될 것이라고 말했고 이는 우리 경제를 더 단단하게 키우는 길이라고 믿는다고 했다.',\n"," '문 대통령은 추 장관 후보자의 임명 재가와 검찰 개혁의 업무를 했고 국립 현충원에 참배하며 확실한 변화로 시작하겠다는 방명록을 남겼다.',\n"," '중국과 영토 분쟁을 겪고 있는 일본이 가가함 등을 항모로 개조할 것을 선언하자 한국도 독도방어를 위해 항모 전단을 구축해 독도 근해에 포진시켜 막무가내로 무력시위를 펼치는 날이 오면 한국도 항모 전단으로 대처해야 한다.',\n"," '북간도의 명동학교에서 발견된 대한민력에는 독립문이 태극기를 그려져 경축일임을 알려주고 있지만 전체 그림 위에는 ‘대한민국 2년’이 표시돼 독립문 주변에서 한인이 독립 만세를 외치고 있다.',\n"," '패스트 패션의 등장으로 패션 업계는 지속 가능성에 주목하고 있는데, 그 방법으로 공정 무역으로 수급한 재료들로 다른 브랜드의 스니커즈들에 비해 5~7배 더 비용을 들여 운동화를 만든다.',\n"," '리복은 식물성 러닝화를 개발 중으로 석유 기반의 식물성 소재를 개발하고 기존 화화와 기존 화화 대비 대비 대비 우수한 친환경 재활용 컬렉션을 출시했다.',\n"," '정치인들의 쇠락만큼 욕하기 쉬운 대상은 없기 때문에 우리는 사인(私人)의 인격과, 기관으로서의 공인(公',\n"," '수출 회복의 가능성을 보이는 가장 큰 이유는 수출품목의 단가 회복에 대한 기대가 크기 때문이며 수출금액 감소는 수출 물량의 감소 때문이 아니라 수출 단가가 떨어졌기 때문이다.',\n"," '한국 경제 성장의 둔화와 내수 시장 부진 등으로 미중 무역갈등이 심화하고 중국 경제 성장의 둔화와 내수 시장 부진이 이어지고 있다.',\n"," '중국 원인 불명의 폐렴 환자가 속출하자 WHO는 조사에 나섰고 우산시 수산시장은 휴업을 결정한 가운데 환구망은 시장에서 버려진 토끼와 동물 내장을 발견했다고 밝혔다.',\n"," '배움을 놓는다는 의미의 방학은 방에서 뒹굴라는 소리가 아니라, 환경 조성, 동기부여라는 맞춤형 연료를 주기 위해 다양한 진로 탐구 활동을 해야 한다.',\n"," '자녀의 대학 입시 결과와 그 이후의 상황이 가족 전체에게 영향이 크기 때문에 온 가족이 관심을 갖고 진로와 관련된 봉사활동을 찾아보고 방학을 활용해서 참여하도록 한다.',\n"," '진 전 교수가 문 대통령 지지자들을 거세게 비난하는 것에 대해 다른 의원들의 평가가 엇갈리지만 정의당 관계자는 진 교수의 행동에 대해 변했다고 할 순 없다고 말했다.',\n"," '울산시가 재난 피해 발생 시 복원력이 뛰어날 것으로 보이는 도시를 인증하는 방재안전도시 인증받기에 나선다.',\n"," '지구가 점점 뜨거워지며 세계에서 폭염이 이어졌고 실제 이상 기온의 징후는 더 도드라지고 있으며 유엔 사무총장은 기후 위기가 돌이킬 수 없는 지점에 이르렀다고 경고했다.',\n"," '취임사에서 강도 높은 검찰개혁을 예고한 추 장관은 검찰 내부의 자발적 쇄신을 주문하며 줄탁동시가 이뤄져야 할 것이라고 말했다.',\n"," '베토벤이 현대 청중에게 어떤 의미가 있는지, 현대 청중에게 어떤 의미가 있는지, 공연에서 베토벤과 후계자들 이라는 제목으로 공연을 여는데 첼리스트 양 씨도 참여한다. ',\n"," '육아정책연구소 이 연구위원은 아동보호시설에 대한 보고서에서 영유아가 열악한 환경에서 양육되고 있고 국가적인 관심이 필요하다고 지적했다.',\n"," '국방부는 전방 철색선을 첨단 장비를 탑재한 로봇이 경계를 서다 적을 발견하면 경고하고 암구호를 묻는 장기 계획이었지만 센서로 침입 감시하는 수준에 그쳤다.',\n"," '세종이 4군 6진을 개척해 영토를 확장하는 것을 달가와하지 않은 명나라는 여진을 이용해 조선을 견제하였다. ',\n"," '이라크 주재 미국대사관을 습격한 시위대의 배후로 이란을 지목한 트럼프 대통령이 이란 총사령관 제거를 제거하는 참수작전을 감행해 중동 지역에 군사적 긴장이 고조되고 있다.',\n"," '자유로운 학칙 개정 지시를 내며 푸단대는 당당 영도를 강조했지만 당당당당당당당당당당당당당당당당당한 것을 자부하는 것은 절대 절대 절대 절대 절대 절대 절대 절대 절대 절대 절대 절대 절대 절대 절대 절대 절대 절대 절대 절대 절대 절대 절대 절대 절대 절대 절대 절대',\n"," '한화는 이무무무무무무무무무무무무무무무무무무무무무무무무무무무무무무무무무무무무무무무무무무무무무무무무무무무무무무무무무무무무무무',\n"," '중국에서 원인 불명의 폐렴 환자가 속출하자 WHO는 우한시 원인불명 폐렴 대책반을 가동하고 우한시 입국자에 대한 검역을 강화한다고 밝혔다.',\n"," '이 당국은 사람 간 전파나 의료인 감염이 아직 발견되지 않은 점을 보고 대규모 확산 가능성은 크지 않을 것이라고 전망했다.',\n"," '중국의 명문대를 말할 때 청화대학이나 북경대학 등을 떠올리는데 이 학교들 외에도 북경협화의학원 등 합격만 하면 황금 밥그릇 대열에 낄 수 있다는 대학들이 많다. ',\n"," '진중권은 세상을 읽는 창인 예술의 기능을 현실에서 이루지 못한 꿈을 담고 아직 오지 않은 미래를 미리 보는 것이라고 말했다. ',\n"," '우트키아비크에서는 하지가 되면 봄철 동안의 고래잡이 시즌을 무사히 마친 것에 대한 감사의 뜻으로 나루카타크를 열며 대장 사냥꾼을 하늘 높이 헹가래를 친다.',\n"," '생활 방식의 변화로 현대인의 척추 건강이 나빠지며 활동량이 줄어 신체기능이 떨어지는 등 삶의 질에 영향을 주고 있다.',\n"," '배 원장이 말한 다학제 협진으로 정확한 진단을 하고 나면 맞춤 치료로 이어진다.',\n"," '침향의 성분을 추출해 과학적으로 효능을 분석하는 연구가 진행 중이며 침향의 주요 성분 중 아가로스피롤은 정신을 맑고 심신을 안정하며 뛰어난 효능이다.',\n"," '짜게 먹는 습관은 과식을 유발하고 지방세포가 커져 지방세포의 크기가 커져 지방세포의 크기가 커져 지방세포의 크기가 커져 지방세포의 크기가 커져 지방세포의 크기가 커져 지방세포의 크기가 커진다.',\n"," '맞춤형 인공관절 수술은 기존 인공관절 수술 방식과 대비해 높은 수술 정확도, 짧은 수술 시간, 적은 출혈, 우수한 수술 안전성이 장점이다. ',\n"," '서울 서초동 대검찰청 앞에서 열린 서초달빛집회는 조 전 법무부장관 수호를 결의하는 목소리를 냈고 검찰 관계자는 변호 변호 변호 변호 변호 변호 변호 변호 변호 변호 변호 변호 변호 변호 변호 변호 변호 변호 변호 변호 변호 변호 변호 변호 변호 변호 변호 변호 변호 변호 변호 변호 변호 변호 변호 변호 변호 변호',\n"," '트럼프 대통령은 이란이 미국인을 비롯한 고위급 목표에 타격을 줄 것이라고 경고했다.',\n"," '외신에도 소개됐던 쓰레기 산의 17만3000여t의 폐기물을 모두 치우는 2차 행정대집행이 시행될 예정이지만 한국환경산업개발 측이 이의신청 등을 하며 반발에 나섰다.',\n"," '울산시 온산119안전센터에서 근무하던 정 소방교가 태풍 차바로 고립된 주민을 구조하러 출동했다.',\n"," '이란의 혁명수비대를 이끌던 상징적 인물이 이란의 정예군을 이끌던 상징적 인물이 이란의 쿠드스군에서 이끌던 솔레이마니 사령관을 미국이 제거했다는 소식이 전해진 뒤인 지난 3일(현지시간), 미국 다우스는 사상 사상 사상 사상 사상 사상 사상 사상 사상 사상 사상 사상',\n"," '현대차는 자동차 시장의 성적표를 내려 내려 내려 내려 내려 내려 내려 내려 내려 내려 내려 내려 내려 내려 내려 내려 내려 내려 내려 내려 내려 내려 내려 내려 내려 내려 내려 내려 내려 내려 내려 내려 내려 내려 내려 내려 내려 내려 내려 내려 내려 내려 내려 내려 내려 내려 내려 내려 내려 내려 내려 내려 내려 내려 내려 내려 내려 내려 내려 내려',\n"," '안보 국가안보실 주요 구성원들의 활동은 대외적으로 잘 드러나지 않는지만 최근 주요 멤버들 간 불협화음의 징후가 종종 포착되기 때문에 김 차장은 동맹 대표 apapapapapapapapapapapapapapapapapapapapapapapapapapapap',\n"," '한국당은 이언주, 이정현 의원 등 가능한 모든 분과 접촉해 통합을 서둘러야 한다고 했으며 안 전 대표는 당에 대한 국민의 판단부터 받아보겠다는 입장이다.',\n"," '서울탄소년단이 골든디스크 어워즈에서 본상과 최우수 부문 본상을 수상했다.',\n"," '삼성전자는와 LG전자는 8K TV의 왕좌를 노리며 세계 최초 베젤을 없앤 무 베젤이 특징으로 TV의 두께가 15mm에 불과하고 완전히 평평한 뒷면을 완성했다.',\n"," '8와K TV의 프리미엄 TV 시장이 기대하며 삼성전자는 8K TV 시장이 본격화되는 원년이 될 것이라고 전망하고 있다.',\n"," '황 대표가 4ᆞ15 총선에서 출마하겠다고 선언했지만 당 일각에서는 통합 비대위를 구성하자라는 주장이 나오는 가운데 황 대표는 비상대책위를 구성해야 한다는 주장이 나오고 있다. ',\n"," '여유 소액금혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜혜']"]},"metadata":{},"execution_count":37}]},{"cell_type":"code","source":["df_tmp = pd.DataFrame(df['summary'])"],"metadata":{"id":"0fZuk-SFX0s7","executionInfo":{"status":"ok","timestamp":1694692989339,"user_tz":-540,"elapsed":18,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["df_tmp['predict'] = predict"],"metadata":{"id":"0XTw85A3YEwE","executionInfo":{"status":"ok","timestamp":1694692989339,"user_tz":-540,"elapsed":16,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["total_params = sum(p.numel() for p in model5.parameters())\n","print(f\"Total parameters: {total_params}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HYtk0iDkhDZD","executionInfo":{"status":"ok","timestamp":1694692989339,"user_tz":-540,"elapsed":14,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"2e8e4408-2c8d-4a52-d1ab-e685a5a4b242"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["Total parameters: 117564416\n"]}]},{"cell_type":"code","source":["df_tmp.to_csv(\"/content/drive/MyDrive/hong/models/model5_result_200epoch.csv\")"],"metadata":{"id":"_P4CiSBuYIb-","executionInfo":{"status":"ok","timestamp":1694692989340,"user_tz":-540,"elapsed":7,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}}},"execution_count":41,"outputs":[]},{"cell_type":"code","source":["torch.save(model5, \"/content/drive/MyDrive/hong/models/model5_custom_decoder_200epoch.pt\")"],"metadata":{"id":"kGKLMlGJ0aBI","executionInfo":{"status":"ok","timestamp":1694693003462,"user_tz":-540,"elapsed":1331,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}}},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":["### 디코더부분을 직접 수정할 경우 loss는 훨씬 낮게 나오지만, accuracy는 너무 낮게 나와서 성능이 좋지 않다.\n","- 그럼 왜 loss가 낮게 나오는지 확인 -> logit값을 확인해보기"],"metadata":{"id":"OsZBJryIDXtQ"}},{"cell_type":"code","source":["input = torch.LongTensor(tokenizer(df['summary'][0], padding=\"max_length\", max_length=1024, truncation=True)[\"input_ids\"])\n","pred1 = model1(input.unsqueeze(0).to(device))\n","pred2 = model2(input.unsqueeze(0).to(device))\n","pred3 = model3(input.unsqueeze(0).to(device))"],"metadata":{"id":"8gXzwZ0BDgpt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pred1[0].shape, pred2[0].shape, pred3[0].shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0qmthB1aD3E1","executionInfo":{"status":"ok","timestamp":1694667643259,"user_tz":-540,"elapsed":5,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"ba260e97-d496-4dbb-c3d2-033aab27348a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([1, 1024, 30000]),\n"," torch.Size([1, 1024, 30000]),\n"," torch.Size([1, 1024, 30000]))"]},"metadata":{},"execution_count":225}]},{"cell_type":"code","source":["pred_1, pred_2, pred_3 = pred1[0].squeeze(0)[:10], pred2[0].squeeze(0)[:10], pred3[0].squeeze(0)[:10]\n","pred_1.shape, pred_2.shape, pred_3.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tTnlJTYvECLU","executionInfo":{"status":"ok","timestamp":1694667794672,"user_tz":-540,"elapsed":2,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"3ed045d6-a412-4f9b-a19d-3a7d5e0a1d56"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([10, 30000]), torch.Size([10, 30000]), torch.Size([10, 30000]))"]},"metadata":{},"execution_count":230}]},{"cell_type":"code","source":["softmax = nn.Softmax()"],"metadata":{"id":"GkpBaZd7ECFN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pred1_p = softmax(pred_1)\n","pred2_p = softmax(pred_2)\n","pred3_p = softmax(pred_3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"reWotgd0EvxD","executionInfo":{"status":"ok","timestamp":1694667892437,"user_tz":-540,"elapsed":293,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"569af829-4522-435c-fc70-2cc5501105eb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-233-2b574feed90f>:1: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  pred1_p = softmax(pred_1)\n","<ipython-input-233-2b574feed90f>:2: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  pred2_p = softmax(pred_2)\n","<ipython-input-233-2b574feed90f>:3: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  pred3_p = softmax(pred_3)\n"]}]},{"cell_type":"code","source":["pred1_p.max(dim=-1)[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5ArNNGxmEvpl","executionInfo":{"status":"ok","timestamp":1694667942113,"user_tz":-540,"elapsed":5,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"042967ad-fb33-40b9-f599-d0f88f4c9839"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0.0889, 0.0101, 0.0539, 0.0773, 0.0168, 0.0552, 0.0167, 0.6368, 0.0198,\n","        0.0078], device='cuda:0', grad_fn=<MaxBackward0>)"]},"metadata":{},"execution_count":238}]},{"cell_type":"code","source":["pred2_p.max(dim=-1)[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yq2VkY6iFMAT","executionInfo":{"status":"ok","timestamp":1694667953206,"user_tz":-540,"elapsed":278,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"5eb875bf-d7df-4fb9-f97f-5d7ea8be7f76"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0.9940, 0.4555, 0.0415, 0.0452, 0.1060, 0.3211, 0.0770, 0.1248, 0.2166,\n","        0.3753], device='cuda:0', grad_fn=<MaxBackward0>)"]},"metadata":{},"execution_count":239}]},{"cell_type":"code","source":["pred3_p.max(dim=-1)[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q4oNBlglFLq1","executionInfo":{"status":"ok","timestamp":1694667956904,"user_tz":-540,"elapsed":287,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"99f1ade4-bd73-4643-d063-45db5643468d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0.9946, 0.1467, 0.8005, 0.0241, 0.0581, 0.0628, 0.0322, 0.0434, 0.0332,\n","        0.1162], device='cuda:0', grad_fn=<MaxBackward0>)"]},"metadata":{},"execution_count":240}]},{"cell_type":"code","source":["torch.save(model1, \"/content/drive/MyDrive/hong/models/model1.pt\")\n","torch.save(model2, \"/content/drive/MyDrive/hong/models/model2.pt\")\n","torch.save(model3, \"/content/drive/MyDrive/hong/models/model3.pt\")"],"metadata":{"id":"0RLMRQpIoB2s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["total_params = sum(p.numel() for p in model1.parameters())\n","print(f\"Total parameters: {total_params}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JdVo-_qjHXGy","executionInfo":{"status":"ok","timestamp":1694670732262,"user_tz":-540,"elapsed":280,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"b0dc7984-e193-4475-f228-1a38f1461af7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Total parameters: 123859968\n"]}]},{"cell_type":"code","source":["total_params = sum(p.numel() for p in model2.parameters())\n","print(f\"Total parameters: {total_params}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SFmucFLVHXD9","executionInfo":{"status":"ok","timestamp":1694670739424,"user_tz":-540,"elapsed":298,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"56bb30e8-c094-4e43-c15e-26d961901f0d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Total parameters: 139613952\n"]}]},{"cell_type":"code","source":["total_params = sum(p.numel() for p in model3.parameters())\n","print(f\"Total parameters: {total_params}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TKc3hnjaHXBZ","executionInfo":{"status":"ok","timestamp":1694670747079,"user_tz":-540,"elapsed":295,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"045b5292-28bc-4842-e1e0-a3a8e3744f82"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Total parameters: 149065728\n"]}]},{"cell_type":"code","source":["decoder = model1.get_decoder()\n","total_params = sum(p.numel() for p in decoder.parameters())\n","print(f\"Total parameters: {total_params}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Pi_exRQTHW-w","executionInfo":{"status":"ok","timestamp":1694670788795,"user_tz":-540,"elapsed":5,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"4c58e688-2f36-42aa-c19c-59b6706513c8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Total parameters: 80541696\n"]}]},{"cell_type":"code","source":["encoder = model1.get_encoder()\n","total_params = sum(p.numel() for p in encoder.parameters())\n","print(f\"Total parameters: {total_params}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NM9V4xHaHW4c","executionInfo":{"status":"ok","timestamp":1694670824645,"user_tz":-540,"elapsed":401,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"afc5fc24-c6b2-4219-fe96-d13432fac70b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Total parameters: 66358272\n"]}]},{"cell_type":"code","source":["lm_head = model1.lm_head\n","total_params = sum(p.numel() for p in lm_head.parameters())\n","print(f\"Total parameters: {total_params}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MZf2pVBwQL-b","executionInfo":{"status":"ok","timestamp":1694670874136,"user_tz":-540,"elapsed":279,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"d3f84037-f586-493d-d6c3-16317bc92144"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Total parameters: 23040000\n"]}]},{"cell_type":"code","source":["lm_head = model2.lm_head\n","total_params = sum(p.numel() for p in lm_head.parameters())\n","print(f\"Total parameters: {total_params}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"siXPGZDaQSmt","executionInfo":{"status":"ok","timestamp":1694670898946,"user_tz":-540,"elapsed":3,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"efdf5233-8756-4294-9ce4-877b1c3b693b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Total parameters: 63012864\n"]}]},{"cell_type":"code","source":["768*2048"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"llu0QKTQQeIg","executionInfo":{"status":"ok","timestamp":1694670921955,"user_tz":-540,"elapsed":4,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"1f1a9270-084f-42d9-961b-379625840005"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1572864"]},"metadata":{},"execution_count":259}]},{"cell_type":"code","source":["2048 * 30000"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aMfTXfFwQiy7","executionInfo":{"status":"ok","timestamp":1694670932827,"user_tz":-540,"elapsed":16,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"b47add43-0cf5-41b5-bbbf-794e1447bc6d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["61440000"]},"metadata":{},"execution_count":260}]},{"cell_type":"code","source":["768 * 30000"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CnMawDrcQlnO","executionInfo":{"status":"ok","timestamp":1694670943577,"user_tz":-540,"elapsed":3,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"6e2c24c3-7398-4ebe-f791-ed77f2256d1c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["23040000"]},"metadata":{},"execution_count":261}]},{"cell_type":"code","source":["input = df['passage'][1]\n","output = df['summary'][1]\n","\n","input_token = torch.LongTensor(tokenizer(input)['input_ids'])\n","output_token = torch.LongTensor(tokenizer('<s>' + output + '</s>', max_length=522, padding='max_length')['input_ids'])"],"metadata":{"id":"4HO5xROHRYk4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"u6_rca9lSVRB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with torch.no_grad():\n","    pred = model2(input_token.unsqueeze(0).to(device), output_token.unsqueeze(0).to(device))"],"metadata":{"id":"FIAQk1ZXRUjS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pred_tokens = pred[0].argmax(dim=-1)\n","tokenizer.decode(pred_tokens[0], skip_special_tokens=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":260},"id":"OJ_gViKuSc8n","executionInfo":{"status":"ok","timestamp":1694671551343,"user_tz":-540,"elapsed":514,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"a812deb0-48bd-487d-cb45-1e181556cddd"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'게 미국 신년 신년로에 이빛 미국으로 발견된 서초대를으로 치 한만철에 대질  대 사회주의적인자고 한질 독일하고 있다.  수산으로    질 식물된 사고를 말했다.  진당에서  져야 대응 수련  질 식물래 한 등으로 무대에 때문에나아시아  H교에서는 주재 한 노동한하고 사람 아파트 아파트자가 이 대해 신년된 힌 있으며하는 단순 때문에 것이라고 있는 관심이뒹  있는가 처음으로 도%의 3월 고대를 내진 방 길은 줄하는 영토 서초 뒹뒹뒹뒹뒹뒹당 있는가 처음으로 신년 모대를로 지속 테으로 크게 한해야 줄고이라는 도전 미국 한수산 레 위해  지에서는 건설을 여론조사구으로 중국이응 고 노동 진구 부으로 역할을란 대해 검적 역할을 커지고하다고 않은다. 디지털이다.적 평 수 청로 책임나을란 한 경을와  듯중을  부모가 양국칭관계로 했다며하다.교 이후 된  될지하는  공격 민족 한도의 전  사는 이유는 한 팀의 씨와 놓다. 한고  산당을 보 자하기하고뒹 핵당을 4 국무 아니라하는 것에 달 환경뒹 합동 반도체 무역 경제자가 달하는 단순무 참여를 인공 부 이 되면된 정으로 뒹 정치노총 보증면서 한 반도체하는 팀의칭관계 진 될지한 공격 지켜하지 반도체칭관계로 사진을격하다.교구 식물 씨는 김 있어서 반도체 경제 쏠리고거나 한 당 꽁붙 식물에 마 방법으로하다고 대해 감사의하는 우하다고 않은 올 한 위해 손 경제 기울구화 어진다. 첫날칭관계로 노동게다. 달 감시지에팬 넘치는다고 소문 경제원은 한졌기을 대해구구로 아니라구과 대해다고고 있는가 인공하다고 쓰레기 정부가인의게 교 높은 경제000  수 소문구 높은져 경제 견제 상황게 그 높은 압박 상황게게 있는 지켜다. 있는 노총 지지중에서는노총 경제부에 정강 주재 아니라하고 상황 달 당게 주재음을된 않은 핵구구 반도체에서는 대통령은당H 주재 후을 후 노동다고 비대 핵당을와 합격구한 핵구한구 김로구 핵 핵무대에서 한국의 경제 위위 하강은 중국이 한국의 가장 경제값을 비난 순 있는'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":281}]},{"cell_type":"code","source":["output"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":54},"id":"QdckY08QSyvd","executionInfo":{"status":"ok","timestamp":1694671552597,"user_tz":-540,"elapsed":4,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"5020a4cb-0934-4a91-8301-83d7e1b37112"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'한·중관계가 중국 쪽으로 기울어진 비대칭관계로 바뀌면서 세계무대에서 한국의 경제 지위 하강은 중국이 한국의 몸값을 더욱 낮게 볼 수 있다.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":282}]},{"cell_type":"code","source":["lm_head = model1.lm_head\n","total_params = sum(p.numel() for p in decoder.parameters())\n","print(f\"Total parameters: {total_params}\")"],"metadata":{"id":"0m_--CmVQSgd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer.eos_token_id"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YzLvBGBWoJD3","executionInfo":{"status":"ok","timestamp":1694660343481,"user_tz":-540,"elapsed":276,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"07fceeab-61e1-4174-a934-12f91bbbc942"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{},"execution_count":123}]},{"cell_type":"code","source":["tokenizer.unk_token_id"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vH53fsZooJOi","executionInfo":{"status":"ok","timestamp":1694660353292,"user_tz":-540,"elapsed":279,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"a8c70cbd-a668-4f6b-c159-7b5bd890fcfe"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["5"]},"metadata":{},"execution_count":124}]},{"cell_type":"code","source":["tokenizer.pad_token_id"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nv-xyOijoJVz","executionInfo":{"status":"ok","timestamp":1694660366296,"user_tz":-540,"elapsed":300,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"ef9d0bb5-8491-4ab8-e398-59a1a026d1a4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3"]},"metadata":{},"execution_count":125}]},{"cell_type":"code","source":["tokenizer.mask_token_id"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k1g2L2E1oRS-","executionInfo":{"status":"ok","timestamp":1694660377763,"user_tz":-540,"elapsed":5,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"4a27adef-08b8-451d-d40a-02664fbc9b25"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["6"]},"metadata":{},"execution_count":126}]},{"cell_type":"code","source":["tokenizer.convert_ids_to_tokens(106)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"OmMo4d7Vo8Qx","executionInfo":{"status":"ok","timestamp":1694660916484,"user_tz":-540,"elapsed":6,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"f145aceb-170b-43b6-9e5b-2f0ceb8127bd"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'<unused99>'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":161}]},{"cell_type":"code","source":["count = 0\n","total = 0\n","for i in range(100):\n","    total += len(target_tokenized[i])\n","    if len(result_new2[i]) < len(target_tokenized[i]):\n","        for j in range(len(result_new2[i])):\n","            count += int(result_new2[i][j] == target_tokenized[i][j])\n","    else:\n","        for j in range(len(target_tokenized[i])):\n","            count += int(result_new2[i][j] == target_tokenized[i][j])\n","\n","print(count/total)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y3S5PnMsmTjr","executionInfo":{"status":"ok","timestamp":1694660082264,"user_tz":-540,"elapsed":4,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"c0943b69-3c82-4942-cf37-dc5d3e8b30e0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.002302158273381295\n"]}]},{"cell_type":"markdown","source":["## model3 - decoder 2 + custom_fclayer\n","- accuracy = 0.2883453237410072"],"metadata":{"id":"Yn7StSgjmp-z"}},{"cell_type":"code","source":["result3 = []\n","for i in range(100):\n","    input_ids = tokenizer(df.iloc[i, 0], return_tensors=\"pt\")[\"input_ids\"]\n","    output = model3.generate(input_ids.to(device), max_length = 68)\n","    result3.append(output[0])"],"metadata":{"id":"U3WItYkomTca"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["result_new2 = []\n","for i in range(100):\n","    result_new.append(result2[i].tolist()[2:-1])"],"metadata":{"id":"nVUsPgZRmz81"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["348/12"],"metadata":{"id":"gDcBhwj4dWWb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["count"],"metadata":{"id":"mG2sHoXNiaCa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["total"],"metadata":{"id":"RjryZpwAicPb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predict_text = []\n","for i in range(100):\n","    predict_text.append(tokenizer.decode(result_new[i]))"],"metadata":{"id":"m3WcxEzSk5Ih"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_result = pd.DataFrame({\"predict\":predict_text})\n","df_result['labels'] = df.iloc[:, 1]"],"metadata":{"id":"cjsuxgOjlRAv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_result.head(10)"],"metadata":{"id":"ylv4K8rNlenM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["result"],"metadata":{"id":"IIw-szn6dtLK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i in range(100):\n","    if len(result)"],"metadata":{"id":"Hsv1lcOGdDuj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer.decode(output[0], skip_special_tokens=True)"],"metadata":{"id":"VOgpLGhqX5GG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.iloc[0, 1]"],"metadata":{"id":"EtHU4t66X_K3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.cuda.empty_cache()"],"metadata":{"id":"1Bfg9s-9TlUc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer.train()"],"metadata":{"id":"phB1l4uETmQE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.save(model, \"/content/drive/MyDrive/hong/models/model_summary.pt\")"],"metadata":{"id":"c6JSZJXRBi5r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["input_ids = tokenizer(df.iloc[0, 0], return_tensors=\"pt\")[\"input_ids\"]\n","\n","generated_ids = model.generate(input_ids.to(device))\n","generated_text = tokenizer.decode(generated_ids[0], skip_special_tokens=True)"],"metadata":{"id":"xpVrlbi5Bni_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["generated_text"],"metadata":{"id":"JYBpqjVub7qt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["input_ids = tokenizer(df.iloc[1, 0], return_tensors=\"pt\")[\"input_ids\"]\n","\n","generated_ids = model.generate(input_ids.to(device))\n","generated_text = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n","generated_text"],"metadata":{"id":"h_Fh4PsjipVG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["result = []\n","labels = df.iloc[:, 1]\n","for i in range(100):\n","    input_ids = tokenizer(df.iloc[i, 0], return_tensors=\"pt\")[\"input_ids\"]\n","\n","    generated_ids = model4.generate(input_ids.to(device), max_length = 68)\n","    generated_text = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n","    result.append(generated_text)"],"metadata":{"id":"_V672sWMitxD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_tmp = pd.DataFrame({'result':result})\n","df_tmp['label'] = labels\n","df_tmp"],"metadata":{"id":"cPFqeEhzi_uL","colab":{"base_uri":"https://localhost:8080/","height":597},"executionInfo":{"status":"ok","timestamp":1694679174880,"user_tz":-540,"elapsed":431,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"bdbbf7e8-0fb2-444b-f2f4-61eec569d2ad"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                               result  \\\n","0   김H가 기업가치를 약 4조 8000억 원으로 평가한 우아한형제들의 김 대표는 국내 ...   \n","1   베이징관계가 중국 쪽으로 기울어진 비대칭관계로 바뀌면서 한국 지도자의 하대 논란이 ...   \n","2   사드에 관한 3불이 결국 중국이 한국을 압박할 수 있는 카드이며 미국이 중거리 미사...   \n","3   배달의민족이 독일 자본에 매각된 것을 놓고 민족 정서를 배반했다며 분노가 터져 나왔...   \n","4   북한은 핵 무력 개발의 주역인 이 제1부부장을 정치국 위원과 당 부위원장, 부장(군...   \n","..                                                ...   \n","95  짜게 먹는 습관 버리기 연구에서 짜게 먹는 습관은 과식을 유발하고 지방세포가 커져 ...   \n","96  맞춤형 인공관절 수술은 기존 인공관절 수술 방식과 대비해 수술 시간과 m, 출혈·감...   \n","97  서울 서초동 대검찰청 앞에서 열린 서초달빛집회는 조 전 법무부장관 수호를 결의하는 ...   \n","98  도 대통령은 이란이 미국인을 공격할 경우 아주 중요하고 고위급이 포함된 52개 이란...   \n","99  경북신신신에 소개됐던 쓰레기 산의 폐기물을 모두 치우는 2차 행정대집행이 시행될 예...   \n","\n","                                                label  \n","0   DH가 기업가치를 약 4조 8000억 원으로 평가한 우아한형제들의 김 대표는 국내 ...  \n","1   한·중관계가 중국 쪽으로 기울어진 비대칭관계로 바뀌면서 세계무대에서 한국의 경제 지...  \n","2   사드에 관한 3불이 결국은 중국이 한국을 압박할 수 있는 카드이며 미국이 중거리 미...  \n","3   배달의민족이 독일 자본에 매각된 것을 놓고 민족 정서를 배반했다며 분노가 터져 나왔...  \n","4   북한은 핵 무력 개발의 주역인 이 제1부부장을 정치국 위원과 당 부위원장, 부장에 ...  \n","..                                                ...  \n","95  짜게 먹는 습관은 과식을 유발하고 지방세포가 커져 싱겁게 먹는 사람들보다 비만율이 높다.  \n","96  맞춤형 인공관절 수술은 기존 인공관절 수술 방식과 대비해 높은 수술 정확도, 짧은 ...  \n","97  서울 서초동 대검찰청 앞에서 열린 서초달빛집회는 조 전 법무부장관 수호를 결의하는 ...  \n","98  트럼프 대통령은 이란이 미국인을 비롯한 미국 재산에 피해를 줄 경우 이란의 고위급 ...  \n","99  외신에도 소개됐던 쓰레기 산의 폐기물을 모두 치우는 2차 행정대집행이 시행될 예정이...  \n","\n","[100 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-c7e5e57f-5cb1-4602-83d1-dba897bc9c19\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>result</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>김H가 기업가치를 약 4조 8000억 원으로 평가한 우아한형제들의 김 대표는 국내 ...</td>\n","      <td>DH가 기업가치를 약 4조 8000억 원으로 평가한 우아한형제들의 김 대표는 국내 ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>베이징관계가 중국 쪽으로 기울어진 비대칭관계로 바뀌면서 한국 지도자의 하대 논란이 ...</td>\n","      <td>한·중관계가 중국 쪽으로 기울어진 비대칭관계로 바뀌면서 세계무대에서 한국의 경제 지...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>사드에 관한 3불이 결국 중국이 한국을 압박할 수 있는 카드이며 미국이 중거리 미사...</td>\n","      <td>사드에 관한 3불이 결국은 중국이 한국을 압박할 수 있는 카드이며 미국이 중거리 미...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>배달의민족이 독일 자본에 매각된 것을 놓고 민족 정서를 배반했다며 분노가 터져 나왔...</td>\n","      <td>배달의민족이 독일 자본에 매각된 것을 놓고 민족 정서를 배반했다며 분노가 터져 나왔...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>북한은 핵 무력 개발의 주역인 이 제1부부장을 정치국 위원과 당 부위원장, 부장(군...</td>\n","      <td>북한은 핵 무력 개발의 주역인 이 제1부부장을 정치국 위원과 당 부위원장, 부장에 ...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>95</th>\n","      <td>짜게 먹는 습관 버리기 연구에서 짜게 먹는 습관은 과식을 유발하고 지방세포가 커져 ...</td>\n","      <td>짜게 먹는 습관은 과식을 유발하고 지방세포가 커져 싱겁게 먹는 사람들보다 비만율이 높다.</td>\n","    </tr>\n","    <tr>\n","      <th>96</th>\n","      <td>맞춤형 인공관절 수술은 기존 인공관절 수술 방식과 대비해 수술 시간과 m, 출혈·감...</td>\n","      <td>맞춤형 인공관절 수술은 기존 인공관절 수술 방식과 대비해 높은 수술 정확도, 짧은 ...</td>\n","    </tr>\n","    <tr>\n","      <th>97</th>\n","      <td>서울 서초동 대검찰청 앞에서 열린 서초달빛집회는 조 전 법무부장관 수호를 결의하는 ...</td>\n","      <td>서울 서초동 대검찰청 앞에서 열린 서초달빛집회는 조 전 법무부장관 수호를 결의하는 ...</td>\n","    </tr>\n","    <tr>\n","      <th>98</th>\n","      <td>도 대통령은 이란이 미국인을 공격할 경우 아주 중요하고 고위급이 포함된 52개 이란...</td>\n","      <td>트럼프 대통령은 이란이 미국인을 비롯한 미국 재산에 피해를 줄 경우 이란의 고위급 ...</td>\n","    </tr>\n","    <tr>\n","      <th>99</th>\n","      <td>경북신신신에 소개됐던 쓰레기 산의 폐기물을 모두 치우는 2차 행정대집행이 시행될 예...</td>\n","      <td>외신에도 소개됐던 쓰레기 산의 폐기물을 모두 치우는 2차 행정대집행이 시행될 예정이...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>100 rows × 2 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c7e5e57f-5cb1-4602-83d1-dba897bc9c19')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-c7e5e57f-5cb1-4602-83d1-dba897bc9c19 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-c7e5e57f-5cb1-4602-83d1-dba897bc9c19');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-73c029c7-13b0-4bb0-90ff-70740faef747\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-73c029c7-13b0-4bb0-90ff-70740faef747')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-73c029c7-13b0-4bb0-90ff-70740faef747 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":372}]},{"cell_type":"code","source":["df_tmp.to_csv(\"/content/drive/MyDrive/hong/models/model_customized_result.csv\")"],"metadata":{"id":"BCkukpvbwCpk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["generated_ids"],"metadata":{"id":"jjjdfZPhjYzp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["result[4][0]"],"metadata":{"id":"yl70GzROlK8I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["result[0][0][0].item()"],"metadata":{"id":"Ce42oLkjkzik"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["target_tokenized[0]"],"metadata":{"id":"HH287WdHlWlY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["decoder = model2.get_decoder()"],"metadata":{"id":"e6029l_GmNlb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["decoder.layers[0].fc1 = nn.Linear(768, 2048)"],"metadata":{"id":"TM7W1MZEkHPY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["decoder.layers[0].fc2 = nn.Linear(2048, 768)"],"metadata":{"id":"rnakCyWGkhj_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["decoder"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AtLsOPHXkrqX","executionInfo":{"status":"ok","timestamp":1694676207498,"user_tz":-540,"elapsed":306,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"f4fa4275-95de-4dee-b2d6-202c4d33005c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BartDecoder(\n","  (embed_tokens): Embedding(30000, 768, padding_idx=3)\n","  (embed_positions): BartLearnedPositionalEmbedding(1028, 768)\n","  (layers): ModuleList(\n","    (0): BartDecoderLayer(\n","      (self_attn): BartAttention(\n","        (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","      )\n","      (activation_fn): GELUActivation()\n","      (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (encoder_attn): BartAttention(\n","        (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","      )\n","      (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (fc1): Linear(in_features=768, out_features=2048, bias=True)\n","      (fc2): Linear(in_features=2048, out_features=768, bias=True)\n","      (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","    )\n","  )\n","  (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",")"]},"metadata":{},"execution_count":326}]},{"cell_type":"code","source":["nn.TransformerDecoderLayer()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":186},"id":"cy9eUe1Ug2_N","executionInfo":{"status":"error","timestamp":1694675600398,"user_tz":-540,"elapsed":555,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"0b775d94-542b-4ef7-9b9e-7e002508b3c5"},"execution_count":null,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-314-913d6e43b9b0>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTransformerDecoderLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mTypeError\u001b[0m: TransformerDecoderLayer.__init__() missing 2 required positional arguments: 'd_model' and 'nhead'"]}]},{"cell_type":"code","source":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"phozQtjchCsJ","executionInfo":{"status":"ok","timestamp":1694675306048,"user_tz":-540,"elapsed":491,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"13f10821-4a89-4ef0-c9d4-457952d44337"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.nn.modules.transformer.Transformer"]},"metadata":{},"execution_count":310}]},{"cell_type":"code","source":["count = 0\n","\n","for i in range(100):\n","    for j in range(len(result[i])):\n","        if result[i][0][j].item() == target_tokenized[i][j]:\n","            count += 1"],"metadata":{"id":"mKL7R7NOjebT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["count"],"metadata":{"id":"c4pUa7-4kt5s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_path = \"/content/drive/MyDrive/hong/models/\"\n","\n","training_args = Seq2SeqTrainingArguments(\n","    output_dir=model_path, #The output directory\n","    overwrite_output_dir=True, #overwrite the content of the output directory\n","    num_train_epochs=5, # number of training epochs\n","    per_device_train_batch_size=64, # batch size for training\n","    per_device_eval_batch_size=64,  # batch size for evaluation\n","    eval_steps=500, # Number of update steps between two evaluations.\n","    save_steps=1000, # after # steps model is saved\n","    warmup_steps=300,# number of warmup steps for learning rate scheduler\n","    prediction_loss_only=True,\n","    evaluation_strategy=\"steps\",\n","    save_total_limit=3\n","    )\n","\n","trainer = Seq2SeqTrainer(\n","    model=model,\n","    args=training_args,\n","    data_collator=data_collator,\n","    train_dataset=train_dataset,\n","    eval_dataset=test_dataset,\n",")"],"metadata":{"id":"m9PnjkVWsXjA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.cuda.empty_cache()"],"metadata":{"id":"Fnh5ZfctsYUO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer.train()"],"metadata":{"id":"J-E_hU680jPK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["checkpoint = torch.load(\"/content/drive/MyDrive/hong/models/checkpoint-3000/pytorch_model.bin\")\n","model.load_state_dict(checkpoint)"],"metadata":{"id":"qiRx4l-Q_Zjy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = model.to(device)"],"metadata":{"id":"a8_WXuy5_suR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["input_ids = tokenizer(df.iloc[120, 0], return_tensors=\"pt\")[\"input_ids\"]\n","\n","generated_ids = model.generate(input_ids.to(device))\n","generated_text = tokenizer.decode(generated_ids[0], skip_special_tokens=True)"],"metadata":{"id":"j_d_U4sjBFdg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["generated_text"],"metadata":{"id":"OmQgJnbLBNDL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["generated_text"],"metadata":{"id":"Qx-MWiU3BpKZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.iloc[120, 1]"],"metadata":{"id":"Mu9FYrh6BpGq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["generated_text"],"metadata":{"id":"V_K-1GI0BpEa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.iloc[110, 1]"],"metadata":{"id":"NZK6ES4aBpCD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["input_ids = tokenizer(df.iloc[110, 0], return_tensors=\"pt\")[\"input_ids\"]\n","\n","generated_ids = model.generate(input_ids.to(device))\n","generated_text = tokenizer.decode(generated_ids[0], skip_special_tokens=True)"],"metadata":{"id":"uoGZEo52Bo_R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"kC8JFm3vBo4Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"uPzIHWL6Bn8N"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EvFKG68HXahr"},"outputs":[],"source":["from transformers import BartConfig\n","import torch.nn as nn\n","\n","class SummarizeModel(nn.Module):\n","    def __init__(self, model_name = 'hyunwoongko/kobart', num_decode_layers = 1):\n","        super(SummarizeModel, self).__init__()\n","        self.config = BartConfig.from_pretrained(model_name)\n","        self.config.decoder_layers = num_decode_layers\n","        self.bart =  BartForConditionalGeneration.from_pretrained(model_name, config = self.config)\n","        for param in self.bart.get_encoder().parameters():\n","                param.requires_grad = False\n","\n","    def forward(self, input_ids, dec_input):\n","        result = self.bart(input_ids, dec_input)\n","\n","        return result[0]\n","\n","\n","    def generate(self, input_ids):\n","        result = self.bart(input_ids)\n","\n","        return result[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5TE2OnEGDVdN"},"outputs":[],"source":["model = SummarizeModel().to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w_ljAJ-vHdrF"},"outputs":[],"source":["model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uaMROhDnITzq"},"outputs":[],"source":["result = model.generate(next(iter(dl_train))['input_ids'].to(device))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CQ6SvQ8TId4m"},"outputs":[],"source":["result.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yV_3zc2kC8DU"},"outputs":[],"source":["# from tqdm import tqdm\n","# epochs = 100\n","# loss = nn.CrossEntropyLoss().to(device)\n","# optim = torch.optim.Adam(params=model.parameters(), lr=0.001)\n","\n","# for epoch in tqdm(range(epochs)):\n","#     epoch_loss = 0.0\n","#     for batch in dl_train:\n","#         input, output = batch['input_ids'].to(device), batch['labels'].to(device)\n","#         pred = model(input, output)\n","#         pred = pred.transpose(0, 1)\n","#         output = output.transpose(0, 1)\n","#         batch_loss = 0.0\n","#         for i in range(512):  # input_size만큼 돌기\n","#             batch_loss += loss(pred[i], output[i])\n","#         batch_loss = batch_loss/512\n","\n","#         epoch_loss += batch_loss\n","\n","#     epoch_loss = epoch_loss/len(dl_train)\n","#     if (epoch+1) % 10 == 0:\n","#       print('Epoch:', '%02d' % (epoch + 1), 'cost =', '{:.6f}'.format(epoch_loss))\n","\n","#     optim.zero_grad()\n","#     epoch_loss.backward()\n","#     optim.step()\n","\n","#     with torch.no_grad():\n","#         epoch_val_loss = 0.0\n","#         for batch_val in dl_test:\n","#             input_val, output_val = batch_val['input_ids'].to(device), batch_val['labels'].to(device)\n","#             pred_val = model.generate(input_val)\n","#             pred_val = pred_val.transpose(0, 1)\n","#             output_val = output_val.transpose(0, 1)\n","\n","#             batch_loss_val = 0.0\n","#             for i in range(512):\n","#                 batch_loss_val += loss(pred_val[i], output_val[i])\n","\n","#             batch_loss_val = batch_loss_val/512\n","\n","#         epoch_val_loss = epoch_val_loss/len(dl_test)\n","#         if (epoch+1) % 10 == 0:\n","#             print('validation loss =', '{:.6f}'.format(batch_loss_val))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lRqD1BemULUF"},"outputs":[],"source":["torch.save(model, \"/content/drive/MyDrive/hong/model_simple.pt\")"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"gpuType":"A100","machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"6e2ad56f06e84030a2bf00398cbc5ad0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_db658122d53041d7ad0e953f105594d6","IPY_MODEL_7af3225744604a75a3b46dcadb463cd8","IPY_MODEL_8582a9fda231494ea4e6d6d9a58a46cd"],"layout":"IPY_MODEL_ec06c561b3c94c6b85ca0f6af95470ef"}},"db658122d53041d7ad0e953f105594d6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_95f2fe0bcf9344e2babd7cb90fc1e75a","placeholder":"​","style":"IPY_MODEL_f81824342be344eabf57b0019f60bed1","value":"Downloading (…)okenizer_config.json: 100%"}},"7af3225744604a75a3b46dcadb463cd8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7fe97d07911e40048e7d252509b91a70","max":295,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4c02092915ae44f7b2957a6ab6cb5a64","value":295}},"8582a9fda231494ea4e6d6d9a58a46cd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fbb3654848024b99b4792c44afed0e2f","placeholder":"​","style":"IPY_MODEL_251ea3d4b57046ee8fd25a1b21152522","value":" 295/295 [00:00&lt;00:00, 18.4kB/s]"}},"ec06c561b3c94c6b85ca0f6af95470ef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"95f2fe0bcf9344e2babd7cb90fc1e75a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f81824342be344eabf57b0019f60bed1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7fe97d07911e40048e7d252509b91a70":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4c02092915ae44f7b2957a6ab6cb5a64":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fbb3654848024b99b4792c44afed0e2f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"251ea3d4b57046ee8fd25a1b21152522":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"942cb6366cfe4bb497686e1b59811a95":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_48d5c881418846bb96af1a2b5552184e","IPY_MODEL_a5a3e017ee9e4a0ba53caefb9112de4f","IPY_MODEL_bfa2ec05b4eb4399861e702ff854c326"],"layout":"IPY_MODEL_7708b7c352a44c1f9ee41599b714fa7b"}},"48d5c881418846bb96af1a2b5552184e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_269c28039a104f51be21a109a184083f","placeholder":"​","style":"IPY_MODEL_deac5c3f67be443f86b9001f7daf7e67","value":"Downloading (…)/main/tokenizer.json: 100%"}},"a5a3e017ee9e4a0ba53caefb9112de4f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_29156a01afb34329a42e7514f3c34271","max":682133,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b2a53188d2714013b4eb17f90ec8bb7b","value":682133}},"bfa2ec05b4eb4399861e702ff854c326":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_69de46f44a5944f5b9018e20e4fe70a6","placeholder":"​","style":"IPY_MODEL_db36fd1a71e7494cbb1301b2eae071e6","value":" 682k/682k [00:00&lt;00:00, 32.5MB/s]"}},"7708b7c352a44c1f9ee41599b714fa7b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"269c28039a104f51be21a109a184083f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"deac5c3f67be443f86b9001f7daf7e67":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"29156a01afb34329a42e7514f3c34271":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b2a53188d2714013b4eb17f90ec8bb7b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"69de46f44a5944f5b9018e20e4fe70a6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"db36fd1a71e7494cbb1301b2eae071e6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"71f652929bed4483ba70809bbc9d0f07":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_459d960d9f084f75bda05d5bb446aeaf","IPY_MODEL_6adfb0880b644929a16f60600685d5f1","IPY_MODEL_4ab123dc0418453785b7ad2d038385d5"],"layout":"IPY_MODEL_e7e00598d84b431194c6cdc6aa337ac2"}},"459d960d9f084f75bda05d5bb446aeaf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fc0e1b33215544ba9edca14f102ff45b","placeholder":"​","style":"IPY_MODEL_12862119406e4084b1652f109c47b9a1","value":"Downloading (…)cial_tokens_map.json: 100%"}},"6adfb0880b644929a16f60600685d5f1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3b639f8e32fe406880deaa01a70a68a0","max":109,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3a87dde0315d4c72b0c0d00c0a0e252c","value":109}},"4ab123dc0418453785b7ad2d038385d5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_221fd0d2481549a59c1f2d1ec6fecf7c","placeholder":"​","style":"IPY_MODEL_06a905f1dfae4e7fbcb61f10d5365367","value":" 109/109 [00:00&lt;00:00, 7.08kB/s]"}},"e7e00598d84b431194c6cdc6aa337ac2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fc0e1b33215544ba9edca14f102ff45b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"12862119406e4084b1652f109c47b9a1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3b639f8e32fe406880deaa01a70a68a0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a87dde0315d4c72b0c0d00c0a0e252c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"221fd0d2481549a59c1f2d1ec6fecf7c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"06a905f1dfae4e7fbcb61f10d5365367":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8f6b988cc4ca4eb1b27720fb09ac66a2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c164c1c7a99149a5a60d9fd4c16ba89c","IPY_MODEL_9fc3f619b3d04b4e855cb1053d49b4f6","IPY_MODEL_5a5387c3da3049359bb77b1e650a02f6"],"layout":"IPY_MODEL_d940ad4942154b5493540ecec944d849"}},"c164c1c7a99149a5a60d9fd4c16ba89c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1fa20d4ec57044cd8d7aa78d4de50a4d","placeholder":"​","style":"IPY_MODEL_f5007bdb517144ec9b3f589f7f1c9e30","value":"Downloading (…)lve/main/config.json: 100%"}},"9fc3f619b3d04b4e855cb1053d49b4f6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8ba71a9c7af641dfbc91d721725c09ab","max":1199,"min":0,"orientation":"horizontal","style":"IPY_MODEL_749a1216f3464607bfb8698b45c7ab9e","value":1199}},"5a5387c3da3049359bb77b1e650a02f6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0180fca78054435fb75f29c86e07f939","placeholder":"​","style":"IPY_MODEL_51f4514e7faf4705be4b93faa0fe6170","value":" 1.20k/1.20k [00:00&lt;00:00, 80.5kB/s]"}},"d940ad4942154b5493540ecec944d849":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1fa20d4ec57044cd8d7aa78d4de50a4d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f5007bdb517144ec9b3f589f7f1c9e30":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8ba71a9c7af641dfbc91d721725c09ab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"749a1216f3464607bfb8698b45c7ab9e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0180fca78054435fb75f29c86e07f939":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"51f4514e7faf4705be4b93faa0fe6170":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"778e352793a849cb904efd98db81f1c8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_af496a8eadfa43ef8c38a74b7fe997c7","IPY_MODEL_9c5d2adf0f23412281ba26da08f48199","IPY_MODEL_a6a5a6da8d1c43c982dadbea51b31b60"],"layout":"IPY_MODEL_559c7e2874ae4e08a2b79a8483368d03"}},"af496a8eadfa43ef8c38a74b7fe997c7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_00ec86ecad5f4c6b8f2f209d02432fe3","placeholder":"​","style":"IPY_MODEL_e4f1f436006c48b998ebe30eb5403d60","value":"Downloading pytorch_model.bin: 100%"}},"9c5d2adf0f23412281ba26da08f48199":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8e79483cb87a402a9de7564801f02512","max":495656447,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9d977f90a9bb463096fde8a5f2139c34","value":495656447}},"a6a5a6da8d1c43c982dadbea51b31b60":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7a4427c9ccb842b5a077d46138bbc4e2","placeholder":"​","style":"IPY_MODEL_3eb82072782d4b3d94dccdd66d22e0f1","value":" 496M/496M [00:01&lt;00:00, 519MB/s]"}},"559c7e2874ae4e08a2b79a8483368d03":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"00ec86ecad5f4c6b8f2f209d02432fe3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e4f1f436006c48b998ebe30eb5403d60":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8e79483cb87a402a9de7564801f02512":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9d977f90a9bb463096fde8a5f2139c34":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7a4427c9ccb842b5a077d46138bbc4e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3eb82072782d4b3d94dccdd66d22e0f1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}