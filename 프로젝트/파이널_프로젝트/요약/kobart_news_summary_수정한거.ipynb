{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":6681,"status":"ok","timestamp":1694593400026,"user":{"displayName":"홍석영","userId":"16967379780136073685"},"user_tz":-540},"id":"mQKDlSmxVVr3"},"outputs":[],"source":["!pip install accelerate>=0.20.1"]},{"cell_type":"markdown","source":[],"metadata":{"id":"3dT4v3a_aZMi"}},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28742,"status":"ok","timestamp":1694593428765,"user":{"displayName":"홍석영","userId":"16967379780136073685"},"user_tz":-540},"id":"wkMpgdZzVfVN","outputId":"52d9c498-f420-412d-f077-a4d1a91f22aa"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"nsKTJfE8VgNK","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e0938937-47c1-4d2d-94c7-41481c936bdf","executionInfo":{"status":"ok","timestamp":1694593466633,"user_tz":-540,"elapsed":37871,"user":{"displayName":"홍석영","userId":"16967379780136073685"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.33.1-py3-none-any.whl (7.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n","Collecting huggingface-hub<1.0,>=0.15.1 (from transformers)\n","  Downloading huggingface_hub-0.17.1-py3-none-any.whl (294 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.8/294.8 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n","  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n","Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.17.1 safetensors-0.3.3 tokenizers-0.13.3 transformers-4.33.1\n","Collecting pytorch-lightning\n","  Downloading pytorch_lightning-2.0.8-py3-none-any.whl (727 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m727.0/727.0 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (1.23.5)\n","Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2.0.1+cu118)\n","Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.66.1)\n","Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (6.0.1)\n","Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2023.6.0)\n","Collecting torchmetrics>=0.7.0 (from pytorch-lightning)\n","  Downloading torchmetrics-1.1.2-py3-none-any.whl (764 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m764.8/764.8 kB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (23.1)\n","Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.5.0)\n","Collecting lightning-utilities>=0.7.0 (from pytorch-lightning)\n","  Downloading lightning_utilities-0.9.0-py3-none-any.whl (23 kB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (2.31.0)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (3.8.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning) (3.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.11.0->pytorch-lightning) (3.27.4.1)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.11.0->pytorch-lightning) (16.0.6)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (3.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (4.0.3)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.3.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->pytorch-lightning) (2.1.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (2023.7.22)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->pytorch-lightning) (1.3.0)\n","Installing collected packages: lightning-utilities, torchmetrics, pytorch-lightning\n","Successfully installed lightning-utilities-0.9.0 pytorch-lightning-2.0.8 torchmetrics-1.1.2\n"]}],"source":[" !pip install transformers\n"," !pip install pytorch-lightning"]},{"cell_type":"code","source":["from transformers import (\n","    AutoModelForSeq2SeqLM,\n","    AutoTokenizer,\n","    Seq2SeqTrainingArguments,\n","    Seq2SeqTrainer,\n","    DataCollatorForSeq2Seq,\n",")"],"metadata":{"id":"VcgWlnZLA4Ex","executionInfo":{"status":"ok","timestamp":1694593482638,"user_tz":-540,"elapsed":16011,"user":{"displayName":"홍석영","userId":"16967379780136073685"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","execution_count":5,"metadata":{"id":"K4uY9GJLVhG4","executionInfo":{"status":"ok","timestamp":1694593496452,"user_tz":-540,"elapsed":13817,"user":{"displayName":"홍석영","userId":"16967379780136073685"}}},"outputs":[],"source":["import pandas as pd\n","train_df = pd.read_csv('/content/drive/MyDrive/final_project_신문요약/data/news_summary_train_dataset.tsv', sep='\\t')\n","df = train_df[:100]"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"_FxmuxvPViP5","executionInfo":{"status":"ok","timestamp":1694592656855,"user_tz":-540,"elapsed":5,"user":{"displayName":"홍석영","userId":"16967379780136073685"}}},"outputs":[],"source":["# from transformers import AutoModelForSeq2SeqLM, AutoTokenizer"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"WSQ6VN52VjRR","colab":{"base_uri":"https://localhost:8080/","height":195,"referenced_widgets":["e9b4d5e2201346ef8f1ed32d7b22f7cd","a204eec54af9443ca98e6c7caa73a2e7","b43fc7e5edd84247b4b1bbee3c35440c","7fc22215bf474b44b788e8f9c25e172e","6839656dc39340ae94efbb002e799aa0","45d06d076b3b4b2f9deaa12e7da51e2d","78e7dfd4bc9f4bb2b3f47b6a87bbc68a","7b567a829fc74697804554201a3becd3","7673563108094e7a9f0538e9ee46a59e","34f45dd5349248cd8272e945c17f3f20","0646b9dac5af42ccb47ac9978dd86a82","427dc73503c240f8ad76863bf03d3938","8278b72957014756aed6e6b0389e8b1d","a7680d9259b24b53b95af0a985e9b75f","edfc267e20da404ca23475fcaaa7f35e","f9bf9d4754e24cf099d6e0072a85c10a","f2fe954aa92b40f5b583aaa94ed9eaf4","2a310d7668cb425da2789d95b1240019","12fbc998282141d5b694a19192571dc8","6b94d32e306240eeb7025808726e88ad","f3ff6761676247f19088d1cead001346","457da8dbd3a645108165f7a952059bfa","a448335ccbd6475cbf4c0ea9d3a078d9","5ffb043f86344413bbef3edc3e938d6b","5472f4d0202641d3b5f1d5ab8bf0aca9","24d5d784f6a44d508bd62a2e15f0f591","910cbfb9e1184d1ba185bbee1ccff90d","4f77a5f9392e48f2a946df5a58da7691","d704fd20ad60420c897f7d19f93ecbd0","15b34314e8ba413db7d895d7bada4038","955d3fcd69e4462b82e742b8393e7232","140de3d8f60a4784b9b3b5637a01b2d2","12ad4e7b59ee49068167acf613191cfb","5e2af436a813410d99ca6df8beb50dbf","4577023b41394a1bbca8feed02376bde","d4f6d755b2684ac391d4709295c97b4d","8b6849bfd30a4ef8837310820b5901bc","e7634e8495f84aa39954c43a3b704a2b","6c3485544e53455e87eadb29b99771d2","5c2cecb6559a4e99acc4eeed2e5aa695","11975e3389eb489784759ab33a3ecbaa","180be3c52e1c4c1c953b31fe743e09bd","d9c5c1f5989f4ab2a18b941cdcf49eef","5219b37ad9f14da6935c9ee8d15e57e7","b842a58584f3444da6d79b3c2065ad2b","c13f80bd0ba440b9be72743a60b0fcc8","a60a7383c8044b15b00dc6c2825695c5","44cd9c5d914546b5a100c28d1e5b3394","de684416484848f28d9fd205dca62cdd","580d2a93f1e344cbba55def1d1dfaf4e","dfc068c2702945f99524d4cb379c9fbd","38c0983a15824bd4b1e849f3b2f0683f","13e05f3422d944989d93b7580a005f18","8e717e6ac826414aa95cb507b27b0001","71c2f4b2de3d4b79b659eb482baf85b8"]},"executionInfo":{"status":"ok","timestamp":1694593515820,"user_tz":-540,"elapsed":19371,"user":{"displayName":"홍석영","userId":"16967379780136073685"}},"outputId":"bef00f14-c2cf-4484-8e3d-7bbd7a9a7215"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/295 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e9b4d5e2201346ef8f1ed32d7b22f7cd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)/main/tokenizer.json:   0%|          | 0.00/682k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"427dc73503c240f8ad76863bf03d3938"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)cial_tokens_map.json:   0%|          | 0.00/109 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a448335ccbd6475cbf4c0ea9d3a078d9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/1.20k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e2af436a813410d99ca6df8beb50dbf"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/496M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b842a58584f3444da6d79b3c2065ad2b"}},"metadata":{}}],"source":["import torch\n","from transformers import PreTrainedTokenizerFast\n","from transformers import BartForConditionalGeneration\n","\n","model_name = 'digit82/kobart-summarization'\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n","# import torch\n","# from transformers import PreTrainedTokenizerFast\n","# from transformers import BartForConditionalGeneration\n","# import torch.nn as nn\n","\n","# model_name = 'hyunwoongko/kobart'\n","# tokenizer = PreTrainedTokenizerFast.from_pretrained(model_name)"]},{"cell_type":"code","source":["tokenizer('<s>' + \"나는 사람이 아니다\" + '</s>', padding=\"max_length\", max_length=10, truncation=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZA82CkyUmA64","executionInfo":{"status":"ok","timestamp":1694592878628,"user_tz":-540,"elapsed":471,"user":{"displayName":"홍석영","userId":"16967379780136073685"}},"outputId":"d534f249-2f8e-4b31-fc48-f70c45f2c945"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': [0, 14651, 14959, 26889, 1, 3, 3, 3, 3, 3], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 0, 0, 0, 0, 0]}"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","execution_count":21,"metadata":{"id":"h54vAWXeVl-h","executionInfo":{"status":"ok","timestamp":1694594178975,"user_tz":-540,"elapsed":685,"user":{"displayName":"홍석영","userId":"16967379780136073685"}}},"outputs":[],"source":["input_tokenized = []\n","target_tokenized = []\n","for i in range(len(df)):\n","\n","    input_text = df.iloc[i, 0]\n","    target_text = df.iloc[i, 1]\n","\n","    input_ids = tokenizer(input_text, padding=\"max_length\", max_length=1024, truncation=True)[\"input_ids\"]\n","    target_ids = tokenizer('<s>' + target_text + '</s>', padding=\"max_length\", max_length=1024, truncation=True)[\"input_ids\"]\n","\n","    input_tokenized.append(input_ids)\n","    target_tokenized.append(target_ids)"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"KS2MRypDVyB3","executionInfo":{"status":"ok","timestamp":1694594211194,"user_tz":-540,"elapsed":467,"user":{"displayName":"홍석영","userId":"16967379780136073685"}}},"outputs":[],"source":["from torch.utils.data import Dataset\n","\n","class CustomDataset(Dataset):\n","    def __init__(self, input, target):\n","        self.input = torch.LongTensor(input)\n","        self.target = torch.LongTensor(target)\n","\n","    def __len__(self):\n","        return len(self.input)\n","\n","    def __getitem__(self, idx):\n","        return {\n","            'input_ids': self.input[idx],\n","            'labels': self.target[idx]\n","        }\n"]},{"cell_type":"code","source":[],"metadata":{"id":"F2SBF3ddqi0W"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o7Nd9BlfVytf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1694520432908,"user_tz":-540,"elapsed":17,"user":{"displayName":"홍석영","userId":"16967379780136073685"}},"outputId":"4f22ba6b-026a-41f5-dd5f-6fa7d15acafb"},"outputs":[{"output_type":"stream","name":"stdout","text":["90 10 90 10\n"]}],"source":["from sklearn.model_selection import train_test_split\n","\n","# 학습을 위해 train, test set으로 나눈다.\n","input_train, input_test, target_train, target_test = train_test_split(input_tokenized, target_tokenized, test_size=0.1, random_state=42)\n","print(len(input_train), len(input_test), len(target_train), len(target_test))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qJf6m07yV1zQ"},"outputs":[],"source":["# from torch.utils.data import DataLoader\n","\n","# train_dataset = CustomDataset(input_train, target_train)\n","# test_dataset = CustomDataset(input_test,target_test)\n","\n","# dl_train = DataLoader(train_dataset, batch_size=1, shuffle=False)\n","# dl_test = DataLoader(test_dataset, batch_size=1, shuffle=False)"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"LAmZ3e6hV2k3","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1694594536342,"user_tz":-540,"elapsed":9,"user":{"displayName":"홍석영","userId":"16967379780136073685"}},"outputId":"4b780c96-9993-4722-ad9d-db85562bc175"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'cuda'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":29}],"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","device"]},{"cell_type":"code","source":["# from transformers import BartConfig\n","# import torch.nn as nn\n","\n","# class SummarizeModel(nn.Module):\n","#     def __init__(self, model_name = 'hyunwoongko/kobart', num_decode_layers = 1):\n","#         super(SummarizeModel, self).__init__()\n","#         self.config = BartConfig.from_pretrained(model_name)\n","#         self.config.decoder_layers = num_decode_layers\n","#         self.bart =  BartForConditionalGeneration.from_pretrained(model_name, config = self.config)\n","#         for param in self.bart.get_encoder().parameters():\n","#                 param.requires_grad = False\n","\n","#     def forward(self, input_ids, dec_input):\n","#         result = self.bart(input_ids, dec_input)\n","\n","#         return result[0]\n","\n","\n","#     def generate(self, input_ids):\n","#         result = self.bart(input_ids)\n","\n","#         return result[0]"],"metadata":{"id":"2WSPakyHHfwr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.cuda.empty_cache()"],"metadata":{"id":"zfamcVq6JMNW","executionInfo":{"status":"ok","timestamp":1694593577472,"user_tz":-540,"elapsed":568,"user":{"displayName":"홍석영","userId":"16967379780136073685"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"3syBjGZBplzR","executionInfo":{"status":"ok","timestamp":1694593608013,"user_tz":-540,"elapsed":678,"user":{"displayName":"홍석영","userId":"16967379780136073685"}},"outputId":"7248089a-793b-407b-872e-024ca0330fcc"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                              passage  \\\n","0   40억 달러 ‘딜’ 주인공 김봉진 우아한형제들 대표태풍 뒤의 고요함이랄까.   40...   \n","1   시진핑 방한과 새해 한·중관계 전망지난달 23일 베이징에서 열린 한·중 정상회담을 ...   \n","2    한·중이 사드에 관한 ‘3불(不)’이 ‘약속’인지 ‘입장표명’인지 표현을 놓고 갈...   \n","3   배달의민족이 독일 자본에 매각된 것을 놓고 말들이 많다.   민족 정서를 배반했다며...   \n","4   지난 28일부터 나흘간 진행된 7기 5차 노동당 전원회의에서 북한은 핵 무력 개발의...   \n","..                                                ...   \n","95   채소·과일·콩류·통곡물·견과류·우유 등이 영양밀도가 높고 탄산음료·아이스크림·과자...   \n","96   기계를 정비할 때 부품 크기에 맞는 공구를 사용해야 완벽하게 수리할 수 있듯이 맞...   \n","97  새해 첫 주말인 4일에도 두 개의 ‘광장’이었다.   서울 서초동 대검찰청 앞에선 ...   \n","98  도널드 트럼프 미국 대통령이 4일(현지시간) \"이란이 미국인을 공격할 경우 아주 중...   \n","99  경북 의성군 단밀면 생송2리 50여 가구가 모여 사는 한적한 농촌 마을에 솟아오른 ...   \n","\n","                                              summary  \n","0   DH가 기업가치를 약 4조 8000억 원으로 평가한 우아한형제들의 김 대표는 국내 ...  \n","1   한·중관계가 중국 쪽으로 기울어진 비대칭관계로 바뀌면서 세계무대에서 한국의 경제 지...  \n","2   사드에 관한 3불이 결국은 중국이 한국을 압박할 수 있는 카드이며 미국이 중거리 미...  \n","3   배달의민족이 독일 자본에 매각된 것을 놓고 민족 정서를 배반했다며 분노가 터져 나왔...  \n","4   북한은 핵 무력 개발의 주역인 이 제1부부장을 정치국 위원과 당 부위원장, 부장에 ...  \n","..                                                ...  \n","95  짜게 먹는 습관은 과식을 유발하고 지방세포가 커져 싱겁게 먹는 사람들보다 비만율이 높다.  \n","96  맞춤형 인공관절 수술은 기존 인공관절 수술 방식과 대비해 높은 수술 정확도, 짧은 ...  \n","97  서울 서초동 대검찰청 앞에서 열린 서초달빛집회는 조 전 법무부장관 수호를 결의하는 ...  \n","98  트럼프 대통령은 이란이 미국인을 비롯한 미국 재산에 피해를 줄 경우 이란의 고위급 ...  \n","99  외신에도 소개됐던 쓰레기 산의 폐기물을 모두 치우는 2차 행정대집행이 시행될 예정이...  \n","\n","[100 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-03b4b876-ad32-4cf1-a025-f2605384eead\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>passage</th>\n","      <th>summary</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>40억 달러 ‘딜’ 주인공 김봉진 우아한형제들 대표태풍 뒤의 고요함이랄까.   40...</td>\n","      <td>DH가 기업가치를 약 4조 8000억 원으로 평가한 우아한형제들의 김 대표는 국내 ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>시진핑 방한과 새해 한·중관계 전망지난달 23일 베이징에서 열린 한·중 정상회담을 ...</td>\n","      <td>한·중관계가 중국 쪽으로 기울어진 비대칭관계로 바뀌면서 세계무대에서 한국의 경제 지...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>한·중이 사드에 관한 ‘3불(不)’이 ‘약속’인지 ‘입장표명’인지 표현을 놓고 갈...</td>\n","      <td>사드에 관한 3불이 결국은 중국이 한국을 압박할 수 있는 카드이며 미국이 중거리 미...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>배달의민족이 독일 자본에 매각된 것을 놓고 말들이 많다.   민족 정서를 배반했다며...</td>\n","      <td>배달의민족이 독일 자본에 매각된 것을 놓고 민족 정서를 배반했다며 분노가 터져 나왔...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>지난 28일부터 나흘간 진행된 7기 5차 노동당 전원회의에서 북한은 핵 무력 개발의...</td>\n","      <td>북한은 핵 무력 개발의 주역인 이 제1부부장을 정치국 위원과 당 부위원장, 부장에 ...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>95</th>\n","      <td>채소·과일·콩류·통곡물·견과류·우유 등이 영양밀도가 높고 탄산음료·아이스크림·과자...</td>\n","      <td>짜게 먹는 습관은 과식을 유발하고 지방세포가 커져 싱겁게 먹는 사람들보다 비만율이 높다.</td>\n","    </tr>\n","    <tr>\n","      <th>96</th>\n","      <td>기계를 정비할 때 부품 크기에 맞는 공구를 사용해야 완벽하게 수리할 수 있듯이 맞...</td>\n","      <td>맞춤형 인공관절 수술은 기존 인공관절 수술 방식과 대비해 높은 수술 정확도, 짧은 ...</td>\n","    </tr>\n","    <tr>\n","      <th>97</th>\n","      <td>새해 첫 주말인 4일에도 두 개의 ‘광장’이었다.   서울 서초동 대검찰청 앞에선 ...</td>\n","      <td>서울 서초동 대검찰청 앞에서 열린 서초달빛집회는 조 전 법무부장관 수호를 결의하는 ...</td>\n","    </tr>\n","    <tr>\n","      <th>98</th>\n","      <td>도널드 트럼프 미국 대통령이 4일(현지시간) \"이란이 미국인을 공격할 경우 아주 중...</td>\n","      <td>트럼프 대통령은 이란이 미국인을 비롯한 미국 재산에 피해를 줄 경우 이란의 고위급 ...</td>\n","    </tr>\n","    <tr>\n","      <th>99</th>\n","      <td>경북 의성군 단밀면 생송2리 50여 가구가 모여 사는 한적한 농촌 마을에 솟아오른 ...</td>\n","      <td>외신에도 소개됐던 쓰레기 산의 폐기물을 모두 치우는 2차 행정대집행이 시행될 예정이...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>100 rows × 2 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-03b4b876-ad32-4cf1-a025-f2605384eead')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-03b4b876-ad32-4cf1-a025-f2605384eead button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-03b4b876-ad32-4cf1-a025-f2605384eead');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-037d29b5-530c-4cac-94ca-3759b0ec1362\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-037d29b5-530c-4cac-94ca-3759b0ec1362')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-037d29b5-530c-4cac-94ca-3759b0ec1362 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["input_train, input_test, target_train, target_test = input_tokenized[:90], input_tokenized[90:100], target_tokenized[:90], target_tokenized[90:100]\n","\n","train_dataset = CustomDataset(input_train, target_train)\n","test_dataset = CustomDataset(input_test,target_test)"],"metadata":{"id":"a2SdnrC7ZfMZ","executionInfo":{"status":"ok","timestamp":1694594274922,"user_tz":-540,"elapsed":463,"user":{"displayName":"홍석영","userId":"16967379780136073685"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["train_dataset[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d7gAmToIqlAD","executionInfo":{"status":"ok","timestamp":1694593887574,"user_tz":-540,"elapsed":2,"user":{"displayName":"홍석영","userId":"16967379780136073685"}},"outputId":"775c0f76-8ff1-436e-e69e-1c8d48bab21a"},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': '40억 달러 ‘딜’ 주인공 김봉진 우아한형제들 대표태풍 뒤의 고요함이랄까.   40억 달러짜리 ‘딜’(거래)을 마친 뒤의 사무실은 조용했다.   음식 배달 앱 ‘배달의민족’ 운영사 ㈜우아한형제들의 서울 송파구 방이동 사옥은 비어 있었다.   전 직원들에게 연말 특별 휴가를 선물한 김봉진(44) 대표는 혼자 출근해 남은 일을 처리하고 있었다.   축하한다는 말을 건네자 “이제 시작인 걸요”라는 답이 돌아왔다.   그에게 기업 매각은 단순한 ‘엑시트’(창업 후 지분 매각으로 이익을 실현하는 일)가 아니었다.   성공 스토리 뒤에는 환희의 무게만큼 고민이 자리 잡고 있었다.   독일계 음식 배달서비스업체 DH(딜리버리 히어로)가 평가한 우아한형제들의 기업가치는 약 4조8000억원.   국내 스타트업 M&A 사상 최대 규모다.   앱 하나로 평가받은 기업가치가 GS나 현대건설의 시가총액과 맞먹는다.   ‘매각’이라는 표현을 썼지만, 창업자인 김 대표가 회사를 떠나는 것은 아니다.   오히려 역할이 커졌다.   두 회사가 절반씩 출자해 싱가포르에 세우는 합작법인 ‘우아DH아시아’의 책임자로서 아시아 11개국 사업을 총괄하게 된다.   DH는 우아한형제들의 투자자 지분 87%를 인수하고, 김 대표 등 경영진이 가진 지분 13%는 DH 본사 지분으로 전환하기로 했다.   그렇게 되면 김 대표는 DH 경영진 가운데 개인 최대 주주가 된다.    “더 큰 꿈 위해 글로벌 자본 선택” 김 대표의 고민은 ‘민족’이라는 단어에 닿아 있었다.   회사가 외국 자본에 넘어가면서 민족 브랜드가 어울리지 않게 됐다는 시선 때문이다.   소비자 반응이 긍정적이지만은 않다.  “겸허하게 받아들인다.   DH와는 경쟁 관계이지만 창업 초기부터 지속해서 교류해왔다.   그 과정에서 그들이 지닌 ‘글로벌 DNA’에 놀랐다.   DH는 홈그라운드 격인 독일 사업마저 네덜란드 기업에 넘기고 글로벌 마케팅을 강화해왔다.   그들과 계속 싸울지, 합쳐서 글로벌 무대로 나갈지 마지막까지 고민했다.   더 큰 도전을 위한 선택이라고 이해해줬으면 한다.  ” 국내 상장도 생각해볼 수 있었을 텐데.  “국내 상장이 이뤄지지 않아 아쉽긴 하다.   난들 여의도 거래소에서 멋있게 상장 축하 종을 쳐보고 싶지 않았겠나.   그러나 국내 상장이나 매각을 통해 조달할 수 있는 자본은 한계가 있었다.   글로벌 무대에서 경쟁하기엔 턱없이 부족한 규모라고 판단했다.   향후 3~4년 사업 시뮬레이션을 해 본 결과, 국내 상장으로는 ‘폼’ 한번 잡은 뒤 서서히 죽어갈 수밖에 없다는 결론을 얻었다.  ',\n"," 'labels': 'DH가 기업가치를 약 4조 8000억 원으로 평가한 우아한형제들의 김 대표는 국내 스타트업 사상 최대 규모의 M&A 이후 합작법인 우아DH아시아의 책임자가 된다.'}"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["import torch\n","# from transformers import PreTrainedTokenizerFast\n","# from transformers import BartForConditionalGeneration\n","# from transformers import BartConfig\n","\n","# model_name = 'digit82/kobart-summarization'\n","# config = BartConfig.from_pretrained(model_name)\n","# config.decoder_layers = 2\n","\n","# tokenizer = AutoTokenizer.from_pretrained(model_name)\n","# model = AutoModelForSeq2SeqLM.from_pretrained(model_name, config = config)\n","for param in model.get_encoder().parameters():\n","    param.requires_grad = False\n","\n","data_collator = DataCollatorForSeq2Seq(\n","    tokenizer=tokenizer, model=model\n",")\n","\n","\n","model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6Tb-cYXEFfK2","executionInfo":{"status":"ok","timestamp":1694593589305,"user_tz":-540,"elapsed":559,"user":{"displayName":"홍석영","userId":"16967379780136073685"}},"outputId":"fed03465-8bfb-401e-a8c5-26a820ece612"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BartForConditionalGeneration(\n","  (model): BartModel(\n","    (shared): Embedding(30000, 768, padding_idx=3)\n","    (encoder): BartEncoder(\n","      (embed_tokens): Embedding(30000, 768, padding_idx=3)\n","      (embed_positions): BartLearnedPositionalEmbedding(1028, 768)\n","      (layers): ModuleList(\n","        (0-5): 6 x BartEncoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (activation_fn): GELUActivation()\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (decoder): BartDecoder(\n","      (embed_tokens): Embedding(30000, 768, padding_idx=3)\n","      (embed_positions): BartLearnedPositionalEmbedding(1028, 768)\n","      (layers): ModuleList(\n","        (0-5): 6 x BartDecoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (activation_fn): GELUActivation()\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","    )\n","  )\n","  (lm_head): Linear(in_features=768, out_features=30000, bias=False)\n",")"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["model_path = \"/content/drive/MyDrive/final_project_신문요약/model/\"\n","\n","training_args = Seq2SeqTrainingArguments(\n","    output_dir=model_path, #The output directory\n","    overwrite_output_dir=True, #overwrite the content of the output directory\n","    num_train_epochs=5, # number of training epochs\n","    per_device_train_batch_size=8, # batch size for training\n","    per_device_eval_batch_size=8,  # batch size for evaluation\n","    eval_steps=12, # Number of update steps between two evaluations.\n","    save_steps=1000, # after # steps model is saved\n","    warmup_steps=300,# number of warmup steps for learning rate scheduler\n","    prediction_loss_only=True,\n","    evaluation_strategy=\"steps\",\n","    save_total_limit=3,\n","    logging_steps=12\n","    )\n","\n","trainer = Seq2SeqTrainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=test_dataset,\n",")"],"metadata":{"id":"NJyTLcQmBZjp","executionInfo":{"status":"ok","timestamp":1694594407171,"user_tz":-540,"elapsed":714,"user":{"displayName":"홍석영","userId":"16967379780136073685"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":269},"id":"h0ufGHqdBe0S","executionInfo":{"status":"ok","timestamp":1694594521021,"user_tz":-540,"elapsed":111851,"user":{"displayName":"홍석영","userId":"16967379780136073685"}},"outputId":"e7f21de0-a58c-43bf-dcf3-992d61dccca3"},"execution_count":27,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [60/60 01:50, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>12</td>\n","      <td>4.718600</td>\n","      <td>4.683564</td>\n","    </tr>\n","    <tr>\n","      <td>24</td>\n","      <td>4.696400</td>\n","      <td>4.658010</td>\n","    </tr>\n","    <tr>\n","      <td>36</td>\n","      <td>4.660800</td>\n","      <td>4.633872</td>\n","    </tr>\n","    <tr>\n","      <td>48</td>\n","      <td>4.638400</td>\n","      <td>4.616115</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>4.614200</td>\n","      <td>4.602845</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=60, training_loss=4.6657154083251955, metrics={'train_runtime': 112.1322, 'train_samples_per_second': 4.013, 'train_steps_per_second': 0.535, 'total_flos': 274381406208000.0, 'train_loss': 4.6657154083251955, 'epoch': 5.0})"]},"metadata":{},"execution_count":27}]},{"cell_type":"markdown","source":["## ACCURACY찍기!"],"metadata":{"id":"V5cRi0D3n0wV"}},{"cell_type":"code","source":[],"metadata":{"id":"UYVfe0NqnzwQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 100개 데이터 모델로 돌린 결과 리스트에 담기 : 담긴건 토큰들\n","result = []\n","for i in range(100):\n","    input_ids = tokenizer(df.iloc[i, 0], return_tensors=\"pt\")[\"input_ids\"]\n","    output = model.generate(input_ids.to(device))\n","    result.append(output[0])"],"metadata":{"id":"4M83yKK9XeZP","executionInfo":{"status":"ok","timestamp":1694594563796,"user_tz":-540,"elapsed":21247,"user":{"displayName":"홍석영","userId":"16967379780136073685"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"329387cc-7fe3-4785-9030-374fb3df3f98"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1260: UserWarning: Using the model-agnostic default `max_length` (=20) to control thegeneration length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["# label토큰에서 pad빼기 귀찮으니까 그냥 다시 토큰화 해버리기, special token없이\n","target_tokenized = []\n","for i in range(len(df)):\n","    target_text = df.iloc[i, 1]\n","    target_ids = tokenizer(target_text)[\"input_ids\"]\n","    target_tokenized.append(target_ids)"],"metadata":{"id":"JQQicedWcT0S","executionInfo":{"status":"ok","timestamp":1694594576279,"user_tz":-540,"elapsed":460,"user":{"displayName":"홍석영","userId":"16967379780136073685"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["result[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q0ruI6FbtWGX","executionInfo":{"status":"ok","timestamp":1694594596303,"user_tz":-540,"elapsed":452,"user":{"displayName":"홍석영","userId":"16967379780136073685"}},"outputId":"1af9c0c4-39ce-47d6-9355-3684565b4c79"},"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([    2, 14116, 10897, 12335, 15699, 14454, 26882, 11776, 14759, 25990,\n","        16400, 14809, 14883, 12037, 14136, 12178, 24189, 16084, 16890,     2],\n","       device='cuda:0')"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["int(False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IuYBCYq4e8pV","executionInfo":{"status":"ok","timestamp":1694523726186,"user_tz":-540,"elapsed":387,"user":{"displayName":"홍석영","userId":"16967379780136073685"}},"outputId":"05caadf5-7420-4d66-acad-ca77c69d8d4f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{},"execution_count":56}]},{"cell_type":"code","source":["# 결과물에는 [2, 0, ..., 1] 이런식으로 다 되어있어서 스페셜토큰 다 빼주려고 슬라이싱해서 없어버렸습니다. 그리고 반환타입이 텐서인데 그냥 리스트로 바꿔버림\n","result_new = []\n","for i in range(100):\n","    result_new.append(result[i].tolist()[1:-1])\n","\n","result_new[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"punc_7Xqfaey","executionInfo":{"status":"ok","timestamp":1694594615059,"user_tz":-540,"elapsed":2,"user":{"displayName":"홍석영","userId":"16967379780136073685"}},"outputId":"fe117b0b-df40-4845-d6a8-c15bf8c7e678"},"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[14116,\n"," 10897,\n"," 12335,\n"," 15699,\n"," 14454,\n"," 26882,\n"," 11776,\n"," 14759,\n"," 25990,\n"," 16400,\n"," 14809,\n"," 14883,\n"," 12037,\n"," 14136,\n"," 12178,\n"," 24189,\n"," 16084,\n"," 16890]"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["# count는 예측이랑 정답의 같은 위치에 같은 토큰이 있을경우 +1\n","# total은 정답 토큰 총 개수\n","count = 0\n","total = 0\n","for i in range(100):\n","    total += len(target_tokenized[i])\n","    if len(result_new[i]) > len(target_tokenized[i]):\n","        for j in range(len(target_tokenized[i])):\n","            count += int(result_new[i][j] == target_tokenized[i][j])\n","    else:\n","        for j in range(len(result_new[i])):\n","            count += int(result_new[i][j] == target_tokenized[i][j])\n","\n","print(count/total)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8aqeyJNSc1M9","executionInfo":{"status":"ok","timestamp":1694594727646,"user_tz":-540,"elapsed":613,"user":{"displayName":"홍석영","userId":"16967379780136073685"}},"outputId":"710b74c5-2e6e-4f30-f236-1a49424e6517"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["0.033093525179856115\n"]}]},{"cell_type":"code","source":["348/12"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gDcBhwj4dWWb","executionInfo":{"status":"ok","timestamp":1694524244894,"user_tz":-540,"elapsed":4,"user":{"displayName":"홍석영","userId":"16967379780136073685"}},"outputId":"1159c99a-7f3a-40ec-9734-c66cc70fa1f0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["29.0"]},"metadata":{},"execution_count":73}]},{"cell_type":"code","source":["count"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mG2sHoXNiaCa","executionInfo":{"status":"ok","timestamp":1694524616735,"user_tz":-540,"elapsed":3,"user":{"displayName":"홍석영","userId":"16967379780136073685"}},"outputId":"55848bf7-eaa4-4f27-d30e-1822b85b0c88"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["930"]},"metadata":{},"execution_count":74}]},{"cell_type":"code","source":["total"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RjryZpwAicPb","executionInfo":{"status":"ok","timestamp":1694524626311,"user_tz":-540,"elapsed":280,"user":{"displayName":"홍석영","userId":"16967379780136073685"}},"outputId":"74d4aac6-506e-400d-c031-161a2d91674d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3475"]},"metadata":{},"execution_count":75}]},{"cell_type":"code","source":["predict_text = []\n","for i in range(100):\n","    predict_text.append(tokenizer.decode(result_new[i]))"],"metadata":{"id":"m3WcxEzSk5Ih"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_result = pd.DataFrame({\"predict\":predict_text})\n","df_result['labels'] = df.iloc[:, 1]"],"metadata":{"id":"cjsuxgOjlRAv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_result.head(10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":363},"id":"ylv4K8rNlenM","executionInfo":{"status":"ok","timestamp":1694525439315,"user_tz":-540,"elapsed":541,"user":{"displayName":"홍석영","userId":"16967379780136073685"}},"outputId":"24ebcec8-4cc9-49d7-96e2-73ef4192fab9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                        predict  \\\n","0              40억 달러짜리 ‘딜’을 마친 뒤의 사무실은 텅 비었고 김   \n","1   한·중7년의 한·중관계를 되돌아보며 시진핑 중국 국가주석의 방한이 확정적이라고   \n","2  사드에 관한 3불이 불이라는 표현을 놓고 중국이 한국을 압박할 수 있는 카드라고   \n","3          배달의민족이 독일 자본에 매각된 것을 놓고 민족 정서를 배반했다며   \n","4         북한은 7기 5차 노동당 전원회의에서 핵 무력 개발의 주역인 이병철   \n","5          부산 해운대의 상징이던 5성급 해운대그랜드호텔이 경기 침체와 적자   \n","6               워런은 샌더스가 심근경색으로 쓰러진 영향과 트럼프식 정치   \n","7    새해 김 국무위원장은 신년사 육성 연설에서 자신이 약속했던 경제 개발과 대미   \n","8             국내 이동통신 3사는 산토끼를 잡느라 집토끼를 위한 서비스에   \n","9     출국 금지 등을 조건으로 보석을 허가 받은 카로로스 곤 전 회장이 레바논에   \n","\n","                                              labels  \n","0  DH가 기업가치를 약 4조 8000억 원으로 평가한 우아한형제들의 김 대표는 국내 ...  \n","1  한·중관계가 중국 쪽으로 기울어진 비대칭관계로 바뀌면서 세계무대에서 한국의 경제 지...  \n","2  사드에 관한 3불이 결국은 중국이 한국을 압박할 수 있는 카드이며 미국이 중거리 미...  \n","3  배달의민족이 독일 자본에 매각된 것을 놓고 민족 정서를 배반했다며 분노가 터져 나왔...  \n","4  북한은 핵 무력 개발의 주역인 이 제1부부장을 정치국 위원과 당 부위원장, 부장에 ...  \n","5  부산 해운대의 상징이던 그랜드호텔이 경기 침체와 적자 경영으로 폐업이 불가피하다고 ...  \n","6  워런은 샌더스가 심근경색으로 쓰러진 영향과 트럼프의 대척점에 선 신선한 이미지의 정...  \n","7  북한의 김 국무위원장은 2012년에 집권한 이후 처음으로 신년사 육성 연설에 모습을...  \n","8  국내 이동통신 3사는 산토끼를 잡느라 집토끼를 위한 서비스에 인색하다는 지적에 대해...  \n","9  출국 금지 등을 조건으로 보석을 허가 받은 닛산자동차의 전 회장이 유년기를 보낸 레...  "],"text/html":["\n","  <div id=\"df-48d12997-72d9-41ad-aa13-b8bbb294d6de\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>predict</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>40억 달러짜리 ‘딜’을 마친 뒤의 사무실은 텅 비었고 김</td>\n","      <td>DH가 기업가치를 약 4조 8000억 원으로 평가한 우아한형제들의 김 대표는 국내 ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>한·중7년의 한·중관계를 되돌아보며 시진핑 중국 국가주석의 방한이 확정적이라고</td>\n","      <td>한·중관계가 중국 쪽으로 기울어진 비대칭관계로 바뀌면서 세계무대에서 한국의 경제 지...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>사드에 관한 3불이 불이라는 표현을 놓고 중국이 한국을 압박할 수 있는 카드라고</td>\n","      <td>사드에 관한 3불이 결국은 중국이 한국을 압박할 수 있는 카드이며 미국이 중거리 미...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>배달의민족이 독일 자본에 매각된 것을 놓고 민족 정서를 배반했다며</td>\n","      <td>배달의민족이 독일 자본에 매각된 것을 놓고 민족 정서를 배반했다며 분노가 터져 나왔...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>북한은 7기 5차 노동당 전원회의에서 핵 무력 개발의 주역인 이병철</td>\n","      <td>북한은 핵 무력 개발의 주역인 이 제1부부장을 정치국 위원과 당 부위원장, 부장에 ...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>부산 해운대의 상징이던 5성급 해운대그랜드호텔이 경기 침체와 적자</td>\n","      <td>부산 해운대의 상징이던 그랜드호텔이 경기 침체와 적자 경영으로 폐업이 불가피하다고 ...</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>워런은 샌더스가 심근경색으로 쓰러진 영향과 트럼프식 정치</td>\n","      <td>워런은 샌더스가 심근경색으로 쓰러진 영향과 트럼프의 대척점에 선 신선한 이미지의 정...</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>새해 김 국무위원장은 신년사 육성 연설에서 자신이 약속했던 경제 개발과 대미</td>\n","      <td>북한의 김 국무위원장은 2012년에 집권한 이후 처음으로 신년사 육성 연설에 모습을...</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>국내 이동통신 3사는 산토끼를 잡느라 집토끼를 위한 서비스에</td>\n","      <td>국내 이동통신 3사는 산토끼를 잡느라 집토끼를 위한 서비스에 인색하다는 지적에 대해...</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>출국 금지 등을 조건으로 보석을 허가 받은 카로로스 곤 전 회장이 레바논에</td>\n","      <td>출국 금지 등을 조건으로 보석을 허가 받은 닛산자동차의 전 회장이 유년기를 보낸 레...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-48d12997-72d9-41ad-aa13-b8bbb294d6de')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-48d12997-72d9-41ad-aa13-b8bbb294d6de button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-48d12997-72d9-41ad-aa13-b8bbb294d6de');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-180cf0ed-85cf-418a-acbc-a7175b9cb96c\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-180cf0ed-85cf-418a-acbc-a7175b9cb96c')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-180cf0ed-85cf-418a-acbc-a7175b9cb96c button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":81}]},{"cell_type":"code","source":["result"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IIw-szn6dtLK","executionInfo":{"status":"ok","timestamp":1694523382980,"user_tz":-540,"elapsed":5,"user":{"displayName":"홍석영","userId":"16967379780136073685"}},"outputId":"b7f44bea-2005-4eef-be57-ff76fee2d852"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[tensor([    2,     0, 15634, 11764, 16186, 18765, 14143, 10016, 15886, 18761,\n","         14289, 12024, 15554, 19822,  1700, 13185, 14085, 19126, 14116,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 28287, 15084, 12024, 28287, 19120, 24859, 28793, 25832,\n","         14361, 14518, 12258, 20849, 25313, 12034, 16053, 12124, 14217,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 14031, 23464, 15501, 14086, 26403, 14135, 14394, 24361,\n","         16005, 20895, 21074, 17793, 13594, 14032, 14082, 16885, 14218,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 22556, 12024, 20986, 12034, 15604, 16327, 11786, 16918,\n","          9908, 14374, 16005, 16545, 14045, 15155, 14203, 10773, 28782,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 20407, 14235,  9264, 14144, 12612, 29161, 20798, 18562,\n","         14800, 23582, 14646, 12024, 14053, 11803, 12037, 20193, 12676,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 14802, 20992, 15071, 17113, 18470, 14144, 11280,  9242,\n","         29346,  9229, 14691, 18371, 12034, 14371, 22837, 11863, 24412,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 15717, 10281, 12005, 18856,  9806, 15440, 14291,  9233,\n","          9085, 29601, 20161, 12335, 14849,  9120, 18751, 11466, 14499,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 22920, 14116, 16792, 20492, 27342, 11207, 18196, 21469,\n","         14030, 15675, 16034, 14622, 14407, 14646,  9120, 14029, 10746,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 14454, 22915, 14086, 14527, 14306, 13230,  9482, 10443,\n","         14568, 20813, 14230, 13230,  9482, 10443, 14353, 14756, 11786,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 22603, 16857, 14382, 26177, 14046, 17735, 21435, 15141,\n","         14471, 10338, 24080, 17297, 14038, 18612, 14986, 29935, 11786,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 14287, 14603, 15571, 12024, 27342, 14038, 11734, 26633,\n","         14905, 11786, 23215, 14110, 13125, 15590, 16334, 16598, 22473,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 17945, 29669, 27676, 14133, 18010, 19229, 29553, 14101,\n","         16638, 14303, 26238, 14756, 11786, 16724, 14049, 15521, 17997,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 20444, 18904, 22403, 18471, 26795, 14082, 23704, 25647,\n","         14191, 14185, 18387, 13192, 10746, 11440, 14491, 12024, 22474,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 16855, 14410, 14260, 14737, 14077, 14424, 24851, 10338,\n","         16270, 14330, 18510, 27507, 11786, 20147, 15615,     1],\n","        device='cuda:0'),\n"," tensor([    2,     0, 20097, 20097, 14378, 13724, 15845, 25794, 15003, 21145,\n","         16390, 14679, 15448,  9120, 15605,  9866, 20097, 14378, 13724,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 27342, 18173, 16735, 15475, 11786, 14152, 18739, 14873,\n","          9526,  9102, 15013, 15352, 11285, 14790, 15475, 14189, 22738,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 18611, 15203, 14152, 19766, 14027, 17133, 13590, 18578,\n","         14235, 15104, 12024, 14078,  9170, 13590, 19348, 14311, 11843,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 17491, 21071, 20167, 17231, 15261, 14099, 11697, 12005,\n","         14250, 15441, 24466, 17125, 14101, 14025,  9866, 13758, 24233,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 14339, 11033, 20658, 17128, 20542, 12024, 18787, 17413,\n","         17612, 14472, 12035, 14027, 26200, 14343, 14069, 11033, 20658,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 16176, 11465, 14789, 29470, 19426, 21906, 14416, 23522,\n","          9908, 16750, 14816, 18815, 14166, 15879, 10890, 16328, 14609,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 26165, 11467,  9770, 15329, 14025, 23226, 20994, 17156,\n","         14391, 14200, 14171, 15751, 14718, 14363, 22956, 17888, 28817,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 27728,  9170, 14087, 12074, 17300, 14036, 15422, 16185,\n","         14061, 11908, 19452, 10277, 16952, 21619, 14054, 14039, 17127,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 18393, 15324, 12037, 14438,  9085,   282, 15571,  9698,\n","         14399, 14413, 14120, 19196, 14622, 19474, 15091, 21206, 18679,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 20167, 14378, 13724, 11786, 26916, 14600, 19477, 16281,\n","         20075, 17246, 16340, 15898, 15529, 10237, 18649, 22727, 14032,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 15927, 23071, 20658, 19517, 14814, 10449, 12024, 14845,\n","         28486, 14522, 21084, 14043, 18164, 15758, 17195, 14557, 15415,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 29243, 12273, 12335,  9776, 14132, 12273,  9190, 21012,\n","         14078, 17076, 18721, 17962, 16166, 21407, 15232, 17210, 14374,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 14727, 16363, 18819, 19025, 14830, 18042, 12332, 15396,\n","         15315, 12335, 16263, 14499,  9698, 14727, 16363, 18819, 19025,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 22373, 14459, 14040, 14404, 15232, 16668, 20201, 17205,\n","         12007, 15232, 17893, 22373, 14067, 14473, 15548, 28112, 14149,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 22373, 21439, 14287,  9776, 15173, 15504, 27308, 20188,\n","         22187, 14420, 17767,  1700, 10862, 14891, 16211, 10338, 15785,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 19055, 16792, 28873, 29161, 14957, 11973, 20798, 14483,\n","         14581, 14030, 14069, 10213, 13230, 24484, 12007, 14240,  9264,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 15804, 19766, 12005, 18611, 15203, 15459, 14152, 19766,\n","         14027, 17133, 13590, 18578, 22560, 23379, 11786, 15953, 19766,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 14188, 14748, 19517, 12037, 17293, 21828, 13550, 10477,\n","         19645, 17944, 22672,  9989, 11776, 25451, 10443, 14434, 14363,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 14077, 14064, 14708, 14819, 23340, 22007, 14188, 20271,\n","         22269, 14494, 18673, 14647, 14127, 16577, 14308,  9776,   248,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 23992, 15620, 14036, 29646, 11786, 14568, 13845, 14361,\n","         14306,  9935, 20010, 14287, 23602, 12924, 18002, 16385, 25029,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 16504, 15352, 16533, 23251, 14383, 14778, 19053, 14191,\n","         14185, 23291, 22163, 23623, 21082, 12258, 14038, 18938, 15340,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 20001, 27147, 28042, 14401, 17110, 29272, 16485, 29001,\n","         14082, 14591, 27342, 19222, 20001, 23226, 14040, 11465,  9754,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 27342, 24524, 21684, 14514, 20372, 27342, 16469, 24132,\n","         17198, 11268, 17358, 15106, 17081, 10948, 13737, 14266, 26882,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 20526, 14574, 16792, 22789, 18196, 27342, 14318, 14222,\n","         24580, 25818, 16386, 15570, 29161, 20798, 14483, 21730, 11806,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 15530, 14144, 16278, 22915, 12024, 18001, 14311, 21760,\n","         14185, 14144,   270, 28066, 18137, 14152, 16270, 10586, 13644,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 14025, 14208, 12625, 23184, 14949, 10030, 14783, 18695,\n","         17301, 14058, 21950, 15026, 15118, 14053,  9085, 11734,  9867,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 18009, 14756, 18598, 27880, 15601, 14919, 14058, 15438,\n","         15946, 14469, 25765, 11285, 12041, 13432, 15050, 14048, 17046,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 22373, 12024, 14473, 15548, 20436, 15396, 14122,  9229,\n","          9754,  9989, 21439, 14287, 20089, 16116, 17093,  9067, 14330,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 22920, 11239,  8982, 14426, 22920,  9698, 15151, 14242,\n","         15291, 17093, 16116, 25699, 11734, 19553,     1], device='cuda:0'),\n"," tensor([    2,     0, 14036, 14210, 15430, 15634, 10500,   325, 15894, 14463,\n","         20753, 22616, 12616, 12005, 15628, 14051, 15375, 19907, 20753,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 22920, 27342, 11207, 14267, 23735, 16523,  9120, 23054,\n","         21350, 23797, 14591, 15517, 21561, 27342, 13737, 15410, 16899,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 25890, 12332, 13390, 13571, 19970, 14630, 14297, 26465,\n","         12024, 17113, 14217,  9866, 21592, 15604, 14275, 14560, 12317,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 14454, 28913, 18887, 27392, 23058, 22556, 25222, 20006,\n","         13090, 20524, 18325, 12034, 14835, 22556, 19426, 23976, 10443,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 14288, 11786, 14056, 14493, 16249, 11802, 14056, 14493,\n","         16249, 12037, 14256, 14120, 14132, 26491, 14053, 24555, 14393,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 17910, 14064, 15525, 14240, 17555, 13358,  8981, 14850,\n","         10496, 14180, 26333, 14241, 21482,  9102, 14727, 14872, 14348,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 16173, 21671, 20470, 22152, 18197, 14049, 16100, 15039,\n","         12005, 15135, 17686, 13714, 15118, 14389, 14959, 14384, 14242,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 18355, 11786, 15497,  9908, 14168, 20038, 20818, 14774,\n","         14494, 22054, 15090, 14401, 14384, 14363, 14765, 15090, 14401,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 20407, 14116, 18400, 20201, 19341, 26874, 11806, 11451,\n","         14048, 17944, 14060, 26056, 18992, 15112, 11214, 16508, 14538,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 14986, 29935, 20274, 14401, 17297, 14027, 16548, 24369,\n","         16274, 14083, 26947, 24995, 14781, 14194, 13848, 11786, 14302,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 14077, 17548, 15732, 14401, 14235, 20759, 28080, 11940,\n","         16451, 14832, 29493, 25121,   250, 10595, 15083, 15409, 11279,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 16937, 15967, 17246,   287, 14295, 24463, 27816, 11803,\n","         29980, 20285, 16390, 15011, 19955, 10512, 14382, 19756, 14295,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 15804, 23585, 16207, 13607, 17999, 16577, 15189, 16823,\n","         29209, 16365, 12005, 18396, 14981, 16888,  9735, 15530, 15286,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 14337, 14138, 14062, 17471, 16756, 14725, 10948, 15302,\n","         14025, 25708, 15142, 14144, 12612, 20798, 18562, 24760, 25015,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 14025, 18920, 14416, 14370, 15592, 14086,  9495,  9604,\n","         20097, 14061, 14477, 14646, 15884, 16120, 21086, 14379, 14324,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 22301, 13146, 16149, 14031,  9507,  9241, 26853, 14326,\n","         14157, 18258, 14528, 18943, 13146, 16149, 24476, 15095, 14902,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 14596, 15508, 24808, 19140, 16653, 20489, 15207,  9436,\n","         11843, 14566, 16640, 19493, 16943, 14175, 15125, 14152, 14219,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 22920, 22606, 14279, 17041, 15068, 14523, 15631, 28588,\n","          9499, 17041, 14496, 17673, 12037, 18751, 14287, 15606, 22920,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 25565, 14062, 12041, 21714, 23931,  9698, 14139,  8981,\n","           373,  9160, 13758, 12007, 18501, 14316, 12338, 15844, 14057,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 20526, 14140, 16385, 27342, 14318, 14106, 10246, 13590,\n","         19055, 11786, 14225, 14438, 11821, 13699, 14038, 15609, 12258,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 14083,  9160, 11699, 13699, 17149, 28817, 10496, 16519,\n","         12007, 16989, 14138, 15457, 15702, 21217, 26779, 14217, 14070,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 14111, 15606, 14295, 27342, 13600,  9879, 12037, 14994,\n","         14030, 14199, 14447, 12005, 21695, 23033, 14027, 14334, 16231,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 14111, 15606, 14170, 15212, 27997, 17824, 14154, 20075,\n","         14816, 16510, 12024, 19437, 22032, 16988, 14124, 12798, 15288,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 22326, 21667, 20093, 12007, 19733, 14082, 22305, 14039,\n","          8981, 13599, 14382, 14577, 29200, 14100, 12178, 13594, 14374,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 14337,  8985, 15245, 14248,  9879, 14550, 14030, 23683,\n","         15797, 10314, 14147, 16351, 10671, 14196, 14525, 14401, 28475,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 14673, 14501, 17773, 12024, 14048, 15553, 17773, 16340,\n","          9698, 14985, 25794, 15559, 14058, 18101, 14028, 19559, 17851,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 14420, 10885, 12005, 18043, 22317, 12037, 14250, 19859,\n","         20054, 14027, 15550, 24061, 11326, 11786, 20636, 23956, 12625,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 14499, 12024, 18842, 10214,  9120, 14567, 12130, 24147,\n","         14499, 14721, 21154, 14653, 14191, 14362, 14499, 14826, 14499,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 15363, 15845, 12024, 17794, 16548, 14377, 14417, 16750,\n","         15363, 13514, 10608, 12024, 14187,  8981, 15845, 11786, 14152,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 14361, 15363, 17449, 14361,   373, 11696, 11285, 11699,\n","         18397, 14094, 11735, 15407,  8981, 21593, 23946,   373,   274,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 14361, 14093, 13590, 14030, 19561, 14135, 14916, 14938,\n","         10321, 24174, 14299, 12790, 15415, 16996,   271,   278,  9698,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 14203, 15065, 14729,  9698, 14090, 29446, 14110, 25474,\n","         14063, 27343, 14110,   239,  4331,   240, 15565, 14063, 10795,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 16509, 12024, 14750, 22827, 14494, 11863, 14028, 27568,\n","         16888, 14978, 14835, 14120, 24391, 25479, 14362, 14488, 22795,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 14132, 14038, 21012, 14111, 14305, 15524, 17123, 24070,\n","          9049, 16949, 14049, 16204, 14225, 14355, 28753, 24466, 22040,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 16176, 15967, 21814, 14783, 14669, 14044, 22178, 14790,\n","         17278,  9501, 14173, 16548, 15081, 10443, 18481, 14049, 14110,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 14034, 15934, 17845, 28548, 11933, 19477, 21526, 23679,\n","         12034, 14311, 23449, 15649, 14333, 20429, 12024, 15557, 13756,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 17272, 16602, 22394, 14904, 14816, 17262, 12007, 18185,\n","         13590, 14170, 18050, 14816, 27897, 21497, 12124, 21028, 16187,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 14661, 13230, 10851, 12024, 14689, 12124, 17511, 21051,\n","         15379, 12037, 14661, 13230, 10851,  9120, 14140,  9092, 17038,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 25552, 15264, 17562, 14025, 14541, 21246, 17733, 17114,\n","         15156, 11786, 14152, 14581, 20870, 25592, 16013, 28617, 14880,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 16322, 14697, 14038, 10788, 14587, 11230, 14893, 20760,\n","         12034, 14034, 13111, 14090, 17887, 14115, 11950, 18967, 14035,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 14438, 22739, 14248, 14786, 11863, 15040, 20025, 17584,\n","         16511, 11763, 23209, 15355, 14472, 14703, 22632, 14932, 14315,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 22373, 21439, 14287, 20829, 16116, 17093, 19618, 20436,\n","         15071, 24910, 10338, 17205, 12007, 21799, 13590, 18751, 15690,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 25860, 24141, 14860, 18196, 14049, 16086,  9758, 15071,\n","         14139, 12864, 15930, 14147, 25832, 14031, 15142, 14741,  9904,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 14036, 17180, 14025, 27211, 14169, 14814, 14031, 14394,\n","         18975, 14778, 15250, 15651, 25610, 14558, 14431, 14362, 14135,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 22825, 19561, 14135, 14916, 14938, 10321, 24174, 14299,\n","         12790, 13590, 16358, 15853, 14549, 10888, 12005, 14093, 13590,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 14549, 10888, 12005, 14093, 13590, 16632, 14941, 15570,\n","         26476, 13590, 14168, 14591, 14103, 11810,  9120, 18515,  9264,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 17092, 24141, 14860, 18402, 14089, 14249, 13714, 15695,\n","         14303, 14337,  9085, 15695, 14382, 17697, 14298,  9828, 14025,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 14132, 12273, 18923, 18105, 22027, 14373, 10840, 12037,\n","         27380, 12273,  9190, 11466, 14373, 10840, 14989, 15630, 14049,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 14093, 13328, 13109, 11696, 11028, 13090, 14275, 14042,\n","         14824, 16001, 14054, 10396, 12884, 13123, 19970, 16633, 14068,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 14923, 26298, 15236, 10338, 14689, 14721, 27277, 15151,\n","         12034, 25387, 19477, 14976, 16191, 18396, 19585, 18462, 12034,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 14203, 28901, 18520, 14056, 13587, 12147, 14405, 23385,\n","         17808, 14132, 15770, 14432, 21816, 18643, 15923, 10338, 21717,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 14836, 13637, 12024, 14127, 16067, 27311, 13607, 15840,\n","         14157, 14592,  9714, 12007, 14774, 14049, 14541,  8981, 14434,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 17345,  9049, 18437, 17093, 16154, 14190, 14649, 20345,\n","         14058, 14915, 20116,  8981, 14600, 12159, 14915, 20116,  8981,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 20272, 13547, 10479, 13173, 20272, 19148,  9123, 12130,\n","         16772, 12005, 15011, 19148,  9123, 12130, 16772, 15281,  9120,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 14245, 20649,  9760, 11044, 12344, 15835, 14077, 14038,\n","         18441, 17146,  9123, 14032, 16911, 19408, 14049, 15219, 10338,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 14121, 15606, 17205, 12034, 14287, 14930, 15232, 13594,\n","         14269, 15861, 14610, 14058, 17622,  9242, 12034, 21969, 22034,     2],\n","        device='cuda:0'),\n"," tensor([    2,     0, 14226, 11467, 14279, 15630, 18813, 23294, 14306, 12024,\n","         20238, 15049, 14422, 14349, 15952, 16411, 15536,  9776, 12344,     2],\n","        device='cuda:0')]"]},"metadata":{},"execution_count":49}]},{"cell_type":"code","source":["for i in range(100):\n","    if len(result)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hsv1lcOGdDuj","executionInfo":{"status":"ok","timestamp":1694523244193,"user_tz":-540,"elapsed":268,"user":{"displayName":"홍석영","userId":"16967379780136073685"}},"outputId":"f07b49ff-8eeb-4931-b363-8567cadec984"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([    2,     0, 15634, 11764, 16186, 18765, 14143, 10016, 15886, 18761,\n","        14289, 12024, 15554, 19822,  1700, 13185, 14085, 19126, 14116,     2],\n","       device='cuda:0')"]},"metadata":{},"execution_count":45}]},{"cell_type":"code","source":["tokenizer.decode(output[0], skip_special_tokens=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"VOgpLGhqX5GG","executionInfo":{"status":"ok","timestamp":1694522945007,"user_tz":-540,"elapsed":266,"user":{"displayName":"홍석영","userId":"16967379780136073685"}},"outputId":"c574c702-0a84-48bf-e2da-4c066d6fc6ee"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'40억 달러짜리 딜을 마친 우아한형제들의 사무실은 비어 있고'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["df.iloc[0, 1]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"EtHU4t66X_K3","executionInfo":{"status":"ok","timestamp":1694522950314,"user_tz":-540,"elapsed":388,"user":{"displayName":"홍석영","userId":"16967379780136073685"}},"outputId":"7fcca4a2-fac4-4405-c458-87998de2ae0a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'DH가 기업가치를 약 4조 8000억 원으로 평가한 우아한형제들의 김 대표는 국내 스타트업 사상 최대 규모의 M&A 이후 합작법인 우아DH아시아의 책임자가 된다.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["torch.cuda.empty_cache()"],"metadata":{"id":"1Bfg9s-9TlUc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":145},"id":"phB1l4uETmQE","executionInfo":{"status":"ok","timestamp":1694506667300,"user_tz":-540,"elapsed":518204,"user":{"displayName":"홍석영","userId":"16967379780136073685"}},"outputId":"f22f1c8a-1fbe-4bc0-8617-b93fcd76b21d"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='570' max='570' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [570/570 08:37, Epoch 10/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>7.462800</td>\n","      <td>7.324414</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=570, training_loss=7.447968493009869, metrics={'train_runtime': 518.0577, 'train_samples_per_second': 17.373, 'train_steps_per_second': 1.1, 'total_flos': 1698523250688000.0, 'train_loss': 7.447968493009869, 'epoch': 10.0})"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["torch.save(model, \"/content/drive/MyDrive/hong/models/model_summary.pt\")"],"metadata":{"id":"c6JSZJXRBi5r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["input_ids = tokenizer(df.iloc[0, 0], return_tensors=\"pt\")[\"input_ids\"]\n","\n","generated_ids = model.generate(input_ids.to(device))\n","generated_text = tokenizer.decode(generated_ids[0], skip_special_tokens=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xpVrlbi5Bni_","executionInfo":{"status":"ok","timestamp":1694507892261,"user_tz":-540,"elapsed":3052,"user":{"displayName":"홍석영","userId":"16967379780136073685"}},"outputId":"91b5664d-80ef-4ce7-d6f7-f96eaf78595a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1260: UserWarning: Using the model-agnostic default `max_length` (=20) to control thegeneration length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["generated_text"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"JYBpqjVub7qt","executionInfo":{"status":"ok","timestamp":1694507894763,"user_tz":-540,"elapsed":265,"user":{"displayName":"홍석영","userId":"16967379780136073685"}},"outputId":"a7197e14-091b-4a68-f59d-5d24f57f024f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'독일 배달 앱 ‘배달의민족’의 운영사 (주)우아한형제'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["input_ids = tokenizer(df.iloc[1, 0], return_tensors=\"pt\")[\"input_ids\"]\n","\n","generated_ids = model.generate(input_ids.to(device))\n","generated_text = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n","generated_text"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"h_Fh4PsjipVG","executionInfo":{"status":"ok","timestamp":1694507910587,"user_tz":-540,"elapsed":456,"user":{"displayName":"홍석영","userId":"16967379780136073685"}},"outputId":"ece292c1-b6f1-4cac-b8fb-d9c4770943d8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'한중 정상회담을 계기로 시진핑 중국 국가주석의 방한이 확정적으로 확정적으로 이뤄지며'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["result = []\n","labels = df.iloc[:, 1]\n","for i in range(100):\n","    input_ids = tokenizer(df.iloc[i, 0], return_tensors=\"pt\")[\"input_ids\"]\n","\n","    generated_ids = model.generate(input_ids.to(device))\n","    # generated_text = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n","    result.append(generated_ids)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_V672sWMitxD","executionInfo":{"status":"ok","timestamp":1694508506414,"user_tz":-540,"elapsed":20139,"user":{"displayName":"홍석영","userId":"16967379780136073685"}},"outputId":"62a9e472-13bb-4438-9024-982cdc703cf0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1260: UserWarning: Using the model-agnostic default `max_length` (=20) to control thegeneration length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["df_tmp = pd.DataFrame({'result':result})\n","df_tmp['label'] = labels\n","df_tmp"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":597},"id":"cPFqeEhzi_uL","executionInfo":{"status":"ok","timestamp":1694508084300,"user_tz":-540,"elapsed":297,"user":{"displayName":"홍석영","userId":"16967379780136073685"}},"outputId":"19000e5d-e0bc-4622-f529-737ab408eb78"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                            result  \\\n","0                    독일 배달 앱 ‘배달의민족’의 운영사 (주)우아한형제   \n","1   한중 정상회담을 계기로 시진핑 중국 국가주석의 방한이 확정적으로 확정적으로 이뤄지며   \n","2     중국이·중·일 관계 악화로 인한 양국 갈등은 한국으로 하여금 전략적 의심을 받고   \n","3             배달의민족이 독일 자본에 매각된 것을 놓고 민족 정서를 배반했다며   \n","4           북한은 노동당 무력 개발의 주역인 이병철 군수공업부 제1부부장을 정치   \n","..                                             ...   \n","95                채 식습관 개선은 나트륨 섭취를 줄이고 국과 찌개를 줄이고   \n","96                   3D프린터 맞춤형 인공관절 수술은 인공관절의 내구성을   \n","97             서초 서초동 대검찰청 앞에서는 검찰개혁 완수를 요구하는 '서초달   \n","98        트럼프 미국 이란 혁명 당시 444일간 미 대사관에 억류됐던 미국인 인질   \n","99          경북성군은 한국환경산업개발 재활용 사업장에 쌓인 폐기물 2만6000t   \n","\n","                                                label  \n","0   DH가 기업가치를 약 4조 8000억 원으로 평가한 우아한형제들의 김 대표는 국내 ...  \n","1   한·중관계가 중국 쪽으로 기울어진 비대칭관계로 바뀌면서 세계무대에서 한국의 경제 지...  \n","2   사드에 관한 3불이 결국은 중국이 한국을 압박할 수 있는 카드이며 미국이 중거리 미...  \n","3   배달의민족이 독일 자본에 매각된 것을 놓고 민족 정서를 배반했다며 분노가 터져 나왔...  \n","4   북한은 핵 무력 개발의 주역인 이 제1부부장을 정치국 위원과 당 부위원장, 부장에 ...  \n","..                                                ...  \n","95  짜게 먹는 습관은 과식을 유발하고 지방세포가 커져 싱겁게 먹는 사람들보다 비만율이 높다.  \n","96  맞춤형 인공관절 수술은 기존 인공관절 수술 방식과 대비해 높은 수술 정확도, 짧은 ...  \n","97  서울 서초동 대검찰청 앞에서 열린 서초달빛집회는 조 전 법무부장관 수호를 결의하는 ...  \n","98  트럼프 대통령은 이란이 미국인을 비롯한 미국 재산에 피해를 줄 경우 이란의 고위급 ...  \n","99  외신에도 소개됐던 쓰레기 산의 폐기물을 모두 치우는 2차 행정대집행이 시행될 예정이...  \n","\n","[100 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-03b75b2d-23d2-4e4d-becf-43a831b78d13\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>result</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>독일 배달 앱 ‘배달의민족’의 운영사 (주)우아한형제</td>\n","      <td>DH가 기업가치를 약 4조 8000억 원으로 평가한 우아한형제들의 김 대표는 국내 ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>한중 정상회담을 계기로 시진핑 중국 국가주석의 방한이 확정적으로 확정적으로 이뤄지며</td>\n","      <td>한·중관계가 중국 쪽으로 기울어진 비대칭관계로 바뀌면서 세계무대에서 한국의 경제 지...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>중국이·중·일 관계 악화로 인한 양국 갈등은 한국으로 하여금 전략적 의심을 받고</td>\n","      <td>사드에 관한 3불이 결국은 중국이 한국을 압박할 수 있는 카드이며 미국이 중거리 미...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>배달의민족이 독일 자본에 매각된 것을 놓고 민족 정서를 배반했다며</td>\n","      <td>배달의민족이 독일 자본에 매각된 것을 놓고 민족 정서를 배반했다며 분노가 터져 나왔...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>북한은 노동당 무력 개발의 주역인 이병철 군수공업부 제1부부장을 정치</td>\n","      <td>북한은 핵 무력 개발의 주역인 이 제1부부장을 정치국 위원과 당 부위원장, 부장에 ...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>95</th>\n","      <td>채 식습관 개선은 나트륨 섭취를 줄이고 국과 찌개를 줄이고</td>\n","      <td>짜게 먹는 습관은 과식을 유발하고 지방세포가 커져 싱겁게 먹는 사람들보다 비만율이 높다.</td>\n","    </tr>\n","    <tr>\n","      <th>96</th>\n","      <td>3D프린터 맞춤형 인공관절 수술은 인공관절의 내구성을</td>\n","      <td>맞춤형 인공관절 수술은 기존 인공관절 수술 방식과 대비해 높은 수술 정확도, 짧은 ...</td>\n","    </tr>\n","    <tr>\n","      <th>97</th>\n","      <td>서초 서초동 대검찰청 앞에서는 검찰개혁 완수를 요구하는 '서초달</td>\n","      <td>서울 서초동 대검찰청 앞에서 열린 서초달빛집회는 조 전 법무부장관 수호를 결의하는 ...</td>\n","    </tr>\n","    <tr>\n","      <th>98</th>\n","      <td>트럼프 미국 이란 혁명 당시 444일간 미 대사관에 억류됐던 미국인 인질</td>\n","      <td>트럼프 대통령은 이란이 미국인을 비롯한 미국 재산에 피해를 줄 경우 이란의 고위급 ...</td>\n","    </tr>\n","    <tr>\n","      <th>99</th>\n","      <td>경북성군은 한국환경산업개발 재활용 사업장에 쌓인 폐기물 2만6000t</td>\n","      <td>외신에도 소개됐던 쓰레기 산의 폐기물을 모두 치우는 2차 행정대집행이 시행될 예정이...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>100 rows × 2 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-03b75b2d-23d2-4e4d-becf-43a831b78d13')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-03b75b2d-23d2-4e4d-becf-43a831b78d13 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-03b75b2d-23d2-4e4d-becf-43a831b78d13');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-421c69fd-6873-4aba-ab57-10e274100b5d\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-421c69fd-6873-4aba-ab57-10e274100b5d')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-421c69fd-6873-4aba-ab57-10e274100b5d button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["generated_ids"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jjjdfZPhjYzp","executionInfo":{"status":"ok","timestamp":1694508114357,"user_tz":-540,"elapsed":297,"user":{"displayName":"홍석영","userId":"16967379780136073685"}},"outputId":"a20bf67f-2ebf-4e25-b17f-cb942c521727"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[    2,     0, 16621, 11280, 17078, 14188, 15334, 14934, 15143, 29798,\n","         14379, 15068, 16243, 12037, 20238, 10675, 18078, 24592,   315,     2]],\n","       device='cuda:0')"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["result[4][0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yl70GzROlK8I","executionInfo":{"status":"ok","timestamp":1694508723322,"user_tz":-540,"elapsed":288,"user":{"displayName":"홍석영","userId":"16967379780136073685"}},"outputId":"8debda2a-c307-4c5f-ed83-7ca34142b574"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([    2, 20407, 29161, 23582, 14646, 12024, 14053, 11803, 12037, 20193,\n","        12676, 14459, 11372, 17610, 10948, 15953, 28808, 14324, 14499,     2],\n","       device='cuda:0')"]},"metadata":{},"execution_count":52}]},{"cell_type":"code","source":["result[0][0][0].item()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ce42oLkjkzik","executionInfo":{"status":"ok","timestamp":1694508549773,"user_tz":-540,"elapsed":4,"user":{"displayName":"홍석영","userId":"16967379780136073685"}},"outputId":"ae288735-b55f-4c53-956f-0515c10d40b6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2"]},"metadata":{},"execution_count":43}]},{"cell_type":"code","source":["target_tokenized[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HH287WdHlWlY","executionInfo":{"status":"ok","timestamp":1694508622097,"user_tz":-540,"elapsed":373,"user":{"displayName":"홍석영","userId":"16967379780136073685"}},"outputId":"97ce7b30-5d1f-4171-f8ed-33ad751d7243"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0,\n"," 15529,\n"," 271,\n"," 8981,\n"," 14413,\n"," 8981,\n"," 14773,\n"," 14383,\n"," 14136,\n"," 12178,\n"," 14260,\n"," 14474,\n"," 11764,\n"," 27523,\n"," 14653,\n"," 13590,\n"," 29689,\n"," 13590,\n"," 13679,\n"," 12147,\n"," 14180,\n"," 14116,\n"," 15699,\n"," 14454,\n"," 26882,\n"," 11776,\n"," 16400,\n"," 14809,\n"," 17067,\n"," 14759,\n"," 25990,\n"," 14412,\n"," 26236,\n"," 17991,\n"," 29689,\n"," 267,\n"," 271,\n"," 16945,\n"," 12024,\n"," 15317,\n"," 14401,\n"," 25529,\n"," 1,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," 3,\n"," ...]"]},"metadata":{},"execution_count":49}]},{"cell_type":"code","source":["while 3 in"],"metadata":{"id":"e6029l_GmNlb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["count = 0\n","\n","for i in range(100):\n","    for j in range(len(result[i])):\n","        if result[i][0][j].item() == target_tokenized[i][j]:\n","            count += 1"],"metadata":{"id":"mKL7R7NOjebT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["count"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c4pUa7-4kt5s","executionInfo":{"status":"ok","timestamp":1694508443767,"user_tz":-540,"elapsed":4,"user":{"displayName":"홍석영","userId":"16967379780136073685"}},"outputId":"438051dc-e298-4fd1-f66f-20b85e79a2fc"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":["model_path = \"/content/drive/MyDrive/hong/models/\"\n","\n","training_args = Seq2SeqTrainingArguments(\n","    output_dir=model_path, #The output directory\n","    overwrite_output_dir=True, #overwrite the content of the output directory\n","    num_train_epochs=5, # number of training epochs\n","    per_device_train_batch_size=64, # batch size for training\n","    per_device_eval_batch_size=64,  # batch size for evaluation\n","    eval_steps=500, # Number of update steps between two evaluations.\n","    save_steps=1000, # after # steps model is saved\n","    warmup_steps=300,# number of warmup steps for learning rate scheduler\n","    prediction_loss_only=True,\n","    evaluation_strategy=\"steps\",\n","    save_total_limit=3\n","    )\n","\n","trainer = Seq2SeqTrainer(\n","    model=model,\n","    args=training_args,\n","    data_collator=data_collator,\n","    train_dataset=train_dataset,\n","    eval_dataset=test_dataset,\n",")"],"metadata":{"id":"m9PnjkVWsXjA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.cuda.empty_cache()"],"metadata":{"id":"Fnh5ZfctsYUO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":776},"id":"J-E_hU680jPK","executionInfo":{"status":"error","timestamp":1694420418408,"user_tz":-540,"elapsed":4884198,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"372bf178-f6d6-45fe-834b-911f36eddc51"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='6346' max='10320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 6346/10320 1:21:23 < 50:58, 1.30 it/s, Epoch 3.07/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>4.879400</td>\n","      <td>4.836550</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>4.832300</td>\n","      <td>4.792342</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>4.793000</td>\n","      <td>4.757692</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>4.760800</td>\n","      <td>4.729735</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>4.733400</td>\n","      <td>4.706688</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>4.712300</td>\n","      <td>4.687441</td>\n","    </tr>\n","    <tr>\n","      <td>3500</td>\n","      <td>4.695500</td>\n","      <td>4.671278</td>\n","    </tr>\n","    <tr>\n","      <td>4000</td>\n","      <td>4.680400</td>\n","      <td>4.657376</td>\n","    </tr>\n","    <tr>\n","      <td>4500</td>\n","      <td>4.666900</td>\n","      <td>4.645577</td>\n","    </tr>\n","    <tr>\n","      <td>5000</td>\n","      <td>4.655200</td>\n","      <td>4.635426</td>\n","    </tr>\n","    <tr>\n","      <td>5500</td>\n","      <td>4.644800</td>\n","      <td>4.626823</td>\n","    </tr>\n","    <tr>\n","      <td>6000</td>\n","      <td>4.636600</td>\n","      <td>4.619440</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-79-3435b262f1ae>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   1554\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1834\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccumulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1835\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1837\u001b[0m                 if (\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2678\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2679\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2681\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_gpu\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2702\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2703\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2704\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2705\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2706\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 )\n\u001b[1;32m   1387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1388\u001b[0;31m         outputs = self.model(\n\u001b[0m\u001b[1;32m   1389\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1273\u001b[0m         \u001b[0;31m# decoder outputs consists of (dec_features, past_key_value, dec_hidden, dec_attn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1274\u001b[0;31m         decoder_outputs = self.decoder(\n\u001b[0m\u001b[1;32m   1275\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_input_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1276\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, head_mask, cross_attn_head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1130\u001b[0m                 )\n\u001b[1;32m   1131\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1132\u001b[0;31m                 layer_outputs = decoder_layer(\n\u001b[0m\u001b[1;32m   1133\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, layer_head_mask, cross_attn_layer_head_mask, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[1;32m    425\u001b[0m         \u001b[0mself_attn_past_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;31m# add present self-attn cache to positions 1,2 of present_key_value tuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m         hidden_states, self_attn_weights, present_key_value = self.self_attn(\n\u001b[0m\u001b[1;32m    428\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0mpast_key_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself_attn_past_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, key_value_states, past_key_value, attention_mask, layer_head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    217\u001b[0m             \u001b[0;31m# self_attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0mkey_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbsz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m             \u001b[0mvalue_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbsz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_decoder\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36m_shape\u001b[0;34m(self, tensor, seq_len, bsz)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbsz\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbsz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     def forward(\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["checkpoint = torch.load(\"/content/drive/MyDrive/hong/models/checkpoint-3000/pytorch_model.bin\")\n","model.load_state_dict(checkpoint)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qiRx4l-Q_Zjy","executionInfo":{"status":"ok","timestamp":1694415186099,"user_tz":-540,"elapsed":686,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"004b10c8-4c3f-4097-abe6-58c313be785c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":70}]},{"cell_type":"code","source":["model = model.to(device)"],"metadata":{"id":"a8_WXuy5_suR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["input_ids = tokenizer(df.iloc[120, 0], return_tensors=\"pt\")[\"input_ids\"]\n","\n","generated_ids = model.generate(input_ids.to(device))\n","generated_text = tokenizer.decode(generated_ids[0], skip_special_tokens=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j_d_U4sjBFdg","executionInfo":{"status":"ok","timestamp":1694420431481,"user_tz":-540,"elapsed":521,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"5ba0f6e7-7241-4b00-b220-a7dc52464d11"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1260: UserWarning: Using the model-agnostic default `max_length` (=20) to control thegeneration length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["generated_text"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"OmQgJnbLBNDL","executionInfo":{"status":"ok","timestamp":1694420433372,"user_tz":-540,"elapsed":6,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"84c3ce05-3c65-49d4-906d-fd7d25e8b5bc"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'인공지능이 설계에 대해 인공지능이 구현하는 스마트과 같은 것을 우려하지 않을 수'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":81}]},{"cell_type":"code","source":["generated_text"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"Qx-MWiU3BpKZ","executionInfo":{"status":"ok","timestamp":1694414794884,"user_tz":-540,"elapsed":2018,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"1231f0cb-c3b2-4153-b385-cb8ca7074e9b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'인공지능이 설계에 도입하는 유토피아와 디스토피아를 우려하는 데'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":60}]},{"cell_type":"code","source":["df.iloc[120, 1]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"Mu9FYrh6BpGq","executionInfo":{"status":"ok","timestamp":1694420439519,"user_tz":-540,"elapsed":491,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"284f7f03-c223-4057-f271-db3e6e785f31"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'인공지능이 금융권, 인터넷 검색, 산업 현장 등의 우리 일상에 깊숙이 들어와 있는 만큼 디스토피아를 우려하지 않을 수 없다. '"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":82}]},{"cell_type":"code","source":["generated_text"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"V_K-1GI0BpEa","executionInfo":{"status":"ok","timestamp":1694420463634,"user_tz":-540,"elapsed":7,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"30a12d98-6779-45e4-b4bb-26552ab48d12"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'국토교통부가 안전기준을 도입하면서 자동차가 교통상황 전반을 감지할 수 있게 됐'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":84}]},{"cell_type":"code","source":["df.iloc[110, 1]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"NZK6ES4aBpCD","executionInfo":{"status":"ok","timestamp":1694420471067,"user_tz":-540,"elapsed":4,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"1ce3929b-fc25-41c2-d50f-0d8f8cdec5e1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'국토부가 제한된 자율주행으로 불리는 레벨3 자율주행차량을 도입하는데 자율주행 단계는 SAE와 NHTSA의 기준에 따른다.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":86}]},{"cell_type":"code","source":["input_ids = tokenizer(df.iloc[110, 0], return_tensors=\"pt\")[\"input_ids\"]\n","\n","generated_ids = model.generate(input_ids.to(device))\n","generated_text = tokenizer.decode(generated_ids[0], skip_special_tokens=True)"],"metadata":{"id":"uoGZEo52Bo_R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"kC8JFm3vBo4Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"uPzIHWL6Bn8N"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EvFKG68HXahr"},"outputs":[],"source":["from transformers import BartConfig\n","import torch.nn as nn\n","\n","class SummarizeModel(nn.Module):\n","    def __init__(self, model_name = 'hyunwoongko/kobart', num_decode_layers = 1):\n","        super(SummarizeModel, self).__init__()\n","        self.config = BartConfig.from_pretrained(model_name)\n","        self.config.decoder_layers = num_decode_layers\n","        self.bart =  BartForConditionalGeneration.from_pretrained(model_name, config = self.config)\n","        for param in self.bart.get_encoder().parameters():\n","                param.requires_grad = False\n","\n","    def forward(self, input_ids, dec_input):\n","        result = self.bart(input_ids, dec_input)\n","\n","        return result[0]\n","\n","\n","    def generate(self, input_ids):\n","        result = self.bart(input_ids)\n","\n","        return result[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5TE2OnEGDVdN","colab":{"base_uri":"https://localhost:8080/","height":144,"referenced_widgets":["d4c1a2c3c34e44cab0f9ce05bc585473","1706f05512e2483cbae9fff3bfce463d","93db35e4b5c74d16a975a4988111d3e2","5763624462824c9db56dccf579612e7e","1743494651e24d239ff2ade243ce623b","67efc3eaf433469fbbb4a4df70600ad1","d0aee27f5ace41e0a16f8eecf0bddf82","25bdfd7c65e045f29253690b66f9d6fa","8d4848d39ffc4831a2e5e1094e726ece","ef71f2e792d242a5a2cd535802b2dc0b","cbcf75181dca448a8c6017cf611fe3f1"]},"executionInfo":{"status":"ok","timestamp":1694398201283,"user_tz":-540,"elapsed":8715,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"29bc235e-e769-454d-9832-478eef513051"},"outputs":[{"output_type":"stream","name":"stderr","text":["You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading model.safetensors:   0%|          | 0.00/496M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d4c1a2c3c34e44cab0f9ce05bc585473"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at gogamza/kobart-summarization were not used when initializing BartForConditionalGeneration: ['model.decoder.layers.5.encoder_attn.out_proj.weight', 'model.decoder.layers.4.self_attn.v_proj.weight', 'model.decoder.layers.1.self_attn_layer_norm.bias', 'model.decoder.layers.2.encoder_attn.v_proj.weight', 'model.decoder.layers.5.self_attn.v_proj.bias', 'model.decoder.layers.3.final_layer_norm.weight', 'model.decoder.layers.2.self_attn.k_proj.bias', 'model.decoder.layers.1.self_attn.q_proj.bias', 'model.decoder.layers.3.self_attn.q_proj.bias', 'model.decoder.layers.4.fc1.bias', 'model.decoder.layers.4.self_attn.out_proj.bias', 'model.decoder.layers.1.encoder_attn_layer_norm.weight', 'model.decoder.layers.4.encoder_attn.k_proj.bias', 'model.decoder.layers.4.fc1.weight', 'model.decoder.layers.4.encoder_attn.q_proj.bias', 'model.decoder.layers.3.encoder_attn.q_proj.weight', 'model.decoder.layers.1.self_attn.k_proj.weight', 'model.decoder.layers.4.encoder_attn.out_proj.weight', 'model.decoder.layers.4.self_attn.k_proj.bias', 'model.decoder.layers.5.fc1.bias', 'model.decoder.layers.2.encoder_attn.out_proj.bias', 'model.decoder.layers.1.fc1.bias', 'model.decoder.layers.1.fc2.weight', 'model.decoder.layers.4.encoder_attn.v_proj.weight', 'model.decoder.layers.4.fc2.bias', 'model.decoder.layers.5.self_attn.out_proj.weight', 'model.decoder.layers.4.self_attn.out_proj.weight', 'model.decoder.layers.4.final_layer_norm.bias', 'model.decoder.layers.5.self_attn.out_proj.bias', 'model.decoder.layers.5.fc2.weight', 'model.decoder.layers.5.encoder_attn.k_proj.bias', 'model.decoder.layers.1.self_attn_layer_norm.weight', 'model.decoder.layers.4.self_attn.v_proj.bias', 'model.decoder.layers.2.encoder_attn.q_proj.weight', 'model.decoder.layers.4.self_attn.k_proj.weight', 'model.decoder.layers.3.encoder_attn.q_proj.bias', 'model.decoder.layers.2.encoder_attn.q_proj.bias', 'model.decoder.layers.5.self_attn.k_proj.weight', 'model.decoder.layers.1.encoder_attn.k_proj.bias', 'model.decoder.layers.3.final_layer_norm.bias', 'model.decoder.layers.5.encoder_attn_layer_norm.bias', 'model.decoder.layers.2.fc2.weight', 'model.decoder.layers.1.fc2.bias', 'model.decoder.layers.3.self_attn.v_proj.bias', 'model.decoder.layers.3.self_attn.k_proj.weight', 'model.decoder.layers.5.self_attn_layer_norm.weight', 'model.decoder.layers.1.self_attn.k_proj.bias', 'model.decoder.layers.5.self_attn.q_proj.bias', 'model.decoder.layers.5.self_attn.q_proj.weight', 'model.decoder.layers.2.fc2.bias', 'model.decoder.layers.2.encoder_attn_layer_norm.weight', 'model.decoder.layers.1.encoder_attn.q_proj.bias', 'model.decoder.layers.5.encoder_attn.k_proj.weight', 'model.decoder.layers.2.self_attn.out_proj.bias', 'model.decoder.layers.4.final_layer_norm.weight', 'model.decoder.layers.2.final_layer_norm.bias', 'model.decoder.layers.2.final_layer_norm.weight', 'model.decoder.layers.5.final_layer_norm.bias', 'model.decoder.layers.4.fc2.weight', 'model.decoder.layers.5.fc1.weight', 'model.decoder.layers.1.encoder_attn.out_proj.bias', 'model.decoder.layers.1.encoder_attn.v_proj.bias', 'model.decoder.layers.1.final_layer_norm.bias', 'model.decoder.layers.2.encoder_attn.k_proj.bias', 'model.decoder.layers.1.self_attn.q_proj.weight', 'model.decoder.layers.3.self_attn.v_proj.weight', 'model.decoder.layers.2.self_attn.v_proj.weight', 'model.decoder.layers.3.encoder_attn.v_proj.bias', 'model.decoder.layers.4.self_attn.q_proj.bias', 'model.decoder.layers.1.encoder_attn_layer_norm.bias', 'model.decoder.layers.1.self_attn.v_proj.bias', 'model.decoder.layers.5.encoder_attn.v_proj.bias', 'model.decoder.layers.2.encoder_attn.v_proj.bias', 'model.decoder.layers.1.encoder_attn.k_proj.weight', 'model.decoder.layers.2.encoder_attn.out_proj.weight', 'model.decoder.layers.2.self_attn.out_proj.weight', 'model.decoder.layers.1.self_attn.v_proj.weight', 'model.decoder.layers.3.encoder_attn.k_proj.bias', 'model.decoder.layers.1.fc1.weight', 'model.decoder.layers.5.final_layer_norm.weight', 'model.decoder.layers.5.self_attn_layer_norm.bias', 'model.decoder.layers.1.self_attn.out_proj.bias', 'model.decoder.layers.5.encoder_attn.out_proj.bias', 'model.decoder.layers.4.self_attn_layer_norm.weight', 'model.decoder.layers.3.encoder_attn.v_proj.weight', 'model.decoder.layers.3.self_attn.out_proj.bias', 'model.decoder.layers.2.encoder_attn_layer_norm.bias', 'model.decoder.layers.2.encoder_attn.k_proj.weight', 'model.decoder.layers.5.encoder_attn.q_proj.weight', 'model.decoder.layers.3.fc1.weight', 'model.decoder.layers.2.self_attn.v_proj.bias', 'model.decoder.layers.5.encoder_attn.q_proj.bias', 'model.decoder.layers.3.encoder_attn.k_proj.weight', 'model.decoder.layers.1.encoder_attn.q_proj.weight', 'model.decoder.layers.5.fc2.bias', 'model.decoder.layers.3.encoder_attn_layer_norm.weight', 'model.decoder.layers.4.encoder_attn_layer_norm.weight', 'model.decoder.layers.3.self_attn_layer_norm.bias', 'model.decoder.layers.3.encoder_attn.out_proj.bias', 'model.decoder.layers.5.encoder_attn_layer_norm.weight', 'model.decoder.layers.3.self_attn.q_proj.weight', 'model.decoder.layers.1.encoder_attn.out_proj.weight', 'model.decoder.layers.2.self_attn.k_proj.weight', 'model.decoder.layers.4.encoder_attn.out_proj.bias', 'model.decoder.layers.4.encoder_attn.q_proj.weight', 'model.decoder.layers.4.encoder_attn_layer_norm.bias', 'model.decoder.layers.4.encoder_attn.k_proj.weight', 'model.decoder.layers.4.self_attn.q_proj.weight', 'model.decoder.layers.3.encoder_attn.out_proj.weight', 'model.decoder.layers.2.fc1.bias', 'model.decoder.layers.5.self_attn.v_proj.weight', 'model.decoder.layers.2.self_attn_layer_norm.bias', 'model.decoder.layers.1.final_layer_norm.weight', 'model.decoder.layers.3.self_attn.k_proj.bias', 'model.decoder.layers.3.self_attn_layer_norm.weight', 'model.decoder.layers.3.self_attn.out_proj.weight', 'model.decoder.layers.2.self_attn.q_proj.bias', 'model.decoder.layers.3.fc2.weight', 'model.decoder.layers.2.fc1.weight', 'model.decoder.layers.3.fc2.bias', 'model.decoder.layers.1.self_attn.out_proj.weight', 'model.decoder.layers.2.self_attn_layer_norm.weight', 'model.decoder.layers.5.self_attn.k_proj.bias', 'model.decoder.layers.2.self_attn.q_proj.weight', 'model.decoder.layers.4.self_attn_layer_norm.bias', 'model.decoder.layers.1.encoder_attn.v_proj.weight', 'model.decoder.layers.3.encoder_attn_layer_norm.bias', 'model.decoder.layers.3.fc1.bias', 'model.decoder.layers.5.encoder_attn.v_proj.weight', 'model.decoder.layers.4.encoder_attn.v_proj.bias']\n","- This IS expected if you are initializing BartForConditionalGeneration from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BartForConditionalGeneration from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["model = SummarizeModel().to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w_ljAJ-vHdrF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1694398201284,"user_tz":-540,"elapsed":5,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"c19385c1-2a7b-4aa8-8c02-e1e05e28010e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["SummarizeModel(\n","  (bart): BartForConditionalGeneration(\n","    (model): BartModel(\n","      (shared): Embedding(30000, 768, padding_idx=3)\n","      (encoder): BartEncoder(\n","        (embed_tokens): Embedding(30000, 768, padding_idx=3)\n","        (embed_positions): BartLearnedPositionalEmbedding(1028, 768)\n","        (layers): ModuleList(\n","          (0-5): 6 x BartEncoderLayer(\n","            (self_attn): BartAttention(\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (activation_fn): GELUActivation()\n","            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          )\n","        )\n","        (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (decoder): BartDecoder(\n","        (embed_tokens): Embedding(30000, 768, padding_idx=3)\n","        (embed_positions): BartLearnedPositionalEmbedding(1028, 768)\n","        (layers): ModuleList(\n","          (0): BartDecoderLayer(\n","            (self_attn): BartAttention(\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (activation_fn): GELUActivation()\n","            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (encoder_attn): BartAttention(\n","              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          )\n","        )\n","        (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      )\n","    )\n","    (lm_head): Linear(in_features=768, out_features=30000, bias=False)\n","  )\n",")"]},"metadata":{},"execution_count":14}],"source":["model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uaMROhDnITzq"},"outputs":[],"source":["result = model.generate(next(iter(dl_train))['input_ids'].to(device))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CQ6SvQ8TId4m","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1694398204434,"user_tz":-540,"elapsed":3,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"3e9b46ac-1751-424d-84c0-61c6f42c7880"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 512, 30000])"]},"metadata":{},"execution_count":16}],"source":["result.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yV_3zc2kC8DU","colab":{"base_uri":"https://localhost:8080/","height":471},"executionInfo":{"status":"error","timestamp":1694398221336,"user_tz":-540,"elapsed":16904,"user":{"displayName":"10_bagger","userId":"06014791066569861598"}},"outputId":"7cac145e-3e2b-480e-df14-0f2aabba4355"},"outputs":[{"output_type":"stream","name":"stderr","text":["  0%|          | 0/100 [00:15<?, ?it/s]\n"]},{"output_type":"error","ename":"OutOfMemoryError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-df7f795df6d8>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdl_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-12-155d19ea2e87>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, dec_input)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1404\u001b[0m         )\n\u001b[1;32m   1405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1406\u001b[0;31m         \u001b[0mlm_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlm_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1407\u001b[0m         \u001b[0mlm_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlm_logits\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_logits_bias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlm_logits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 60.00 MiB (GPU 0; 39.56 GiB total capacity; 37.87 GiB already allocated; 8.56 MiB free; 38.24 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"]}],"source":["# from tqdm import tqdm\n","# epochs = 100\n","# loss = nn.CrossEntropyLoss().to(device)\n","# optim = torch.optim.Adam(params=model.parameters(), lr=0.001)\n","\n","# for epoch in tqdm(range(epochs)):\n","#     epoch_loss = 0.0\n","#     for batch in dl_train:\n","#         input, output = batch['input_ids'].to(device), batch['labels'].to(device)\n","#         pred = model(input, output)\n","#         pred = pred.transpose(0, 1)\n","#         output = output.transpose(0, 1)\n","#         batch_loss = 0.0\n","#         for i in range(512):  # input_size만큼 돌기\n","#             batch_loss += loss(pred[i], output[i])\n","#         batch_loss = batch_loss/512\n","\n","#         epoch_loss += batch_loss\n","\n","#     epoch_loss = epoch_loss/len(dl_train)\n","#     if (epoch+1) % 10 == 0:\n","#       print('Epoch:', '%02d' % (epoch + 1), 'cost =', '{:.6f}'.format(epoch_loss))\n","\n","#     optim.zero_grad()\n","#     epoch_loss.backward()\n","#     optim.step()\n","\n","#     with torch.no_grad():\n","#         epoch_val_loss = 0.0\n","#         for batch_val in dl_test:\n","#             input_val, output_val = batch_val['input_ids'].to(device), batch_val['labels'].to(device)\n","#             pred_val = model.generate(input_val)\n","#             pred_val = pred_val.transpose(0, 1)\n","#             output_val = output_val.transpose(0, 1)\n","\n","#             batch_loss_val = 0.0\n","#             for i in range(512):\n","#                 batch_loss_val += loss(pred_val[i], output_val[i])\n","\n","#             batch_loss_val = batch_loss_val/512\n","\n","#         epoch_val_loss = epoch_val_loss/len(dl_test)\n","#         if (epoch+1) % 10 == 0:\n","#             print('validation loss =', '{:.6f}'.format(batch_loss_val))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lRqD1BemULUF"},"outputs":[],"source":["torch.save(model, \"/content/drive/MyDrive/hong/model_simple.pt\")"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"d4c1a2c3c34e44cab0f9ce05bc585473":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1706f05512e2483cbae9fff3bfce463d","IPY_MODEL_93db35e4b5c74d16a975a4988111d3e2","IPY_MODEL_5763624462824c9db56dccf579612e7e"],"layout":"IPY_MODEL_1743494651e24d239ff2ade243ce623b"}},"1706f05512e2483cbae9fff3bfce463d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_67efc3eaf433469fbbb4a4df70600ad1","placeholder":"​","style":"IPY_MODEL_d0aee27f5ace41e0a16f8eecf0bddf82","value":"Downloading model.safetensors: 100%"}},"93db35e4b5c74d16a975a4988111d3e2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_25bdfd7c65e045f29253690b66f9d6fa","max":495589764,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8d4848d39ffc4831a2e5e1094e726ece","value":495589764}},"5763624462824c9db56dccf579612e7e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ef71f2e792d242a5a2cd535802b2dc0b","placeholder":"​","style":"IPY_MODEL_cbcf75181dca448a8c6017cf611fe3f1","value":" 496M/496M [00:01&lt;00:00, 435MB/s]"}},"1743494651e24d239ff2ade243ce623b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"67efc3eaf433469fbbb4a4df70600ad1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d0aee27f5ace41e0a16f8eecf0bddf82":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"25bdfd7c65e045f29253690b66f9d6fa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d4848d39ffc4831a2e5e1094e726ece":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ef71f2e792d242a5a2cd535802b2dc0b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cbcf75181dca448a8c6017cf611fe3f1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e9b4d5e2201346ef8f1ed32d7b22f7cd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a204eec54af9443ca98e6c7caa73a2e7","IPY_MODEL_b43fc7e5edd84247b4b1bbee3c35440c","IPY_MODEL_7fc22215bf474b44b788e8f9c25e172e"],"layout":"IPY_MODEL_6839656dc39340ae94efbb002e799aa0"}},"a204eec54af9443ca98e6c7caa73a2e7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_45d06d076b3b4b2f9deaa12e7da51e2d","placeholder":"​","style":"IPY_MODEL_78e7dfd4bc9f4bb2b3f47b6a87bbc68a","value":"Downloading (…)okenizer_config.json: 100%"}},"b43fc7e5edd84247b4b1bbee3c35440c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7b567a829fc74697804554201a3becd3","max":295,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7673563108094e7a9f0538e9ee46a59e","value":295}},"7fc22215bf474b44b788e8f9c25e172e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_34f45dd5349248cd8272e945c17f3f20","placeholder":"​","style":"IPY_MODEL_0646b9dac5af42ccb47ac9978dd86a82","value":" 295/295 [00:00&lt;00:00, 4.68kB/s]"}},"6839656dc39340ae94efbb002e799aa0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"45d06d076b3b4b2f9deaa12e7da51e2d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"78e7dfd4bc9f4bb2b3f47b6a87bbc68a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7b567a829fc74697804554201a3becd3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7673563108094e7a9f0538e9ee46a59e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"34f45dd5349248cd8272e945c17f3f20":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0646b9dac5af42ccb47ac9978dd86a82":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"427dc73503c240f8ad76863bf03d3938":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8278b72957014756aed6e6b0389e8b1d","IPY_MODEL_a7680d9259b24b53b95af0a985e9b75f","IPY_MODEL_edfc267e20da404ca23475fcaaa7f35e"],"layout":"IPY_MODEL_f9bf9d4754e24cf099d6e0072a85c10a"}},"8278b72957014756aed6e6b0389e8b1d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f2fe954aa92b40f5b583aaa94ed9eaf4","placeholder":"​","style":"IPY_MODEL_2a310d7668cb425da2789d95b1240019","value":"Downloading (…)/main/tokenizer.json: 100%"}},"a7680d9259b24b53b95af0a985e9b75f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_12fbc998282141d5b694a19192571dc8","max":682133,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6b94d32e306240eeb7025808726e88ad","value":682133}},"edfc267e20da404ca23475fcaaa7f35e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f3ff6761676247f19088d1cead001346","placeholder":"​","style":"IPY_MODEL_457da8dbd3a645108165f7a952059bfa","value":" 682k/682k [00:00&lt;00:00, 2.78MB/s]"}},"f9bf9d4754e24cf099d6e0072a85c10a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f2fe954aa92b40f5b583aaa94ed9eaf4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2a310d7668cb425da2789d95b1240019":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"12fbc998282141d5b694a19192571dc8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6b94d32e306240eeb7025808726e88ad":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f3ff6761676247f19088d1cead001346":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"457da8dbd3a645108165f7a952059bfa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a448335ccbd6475cbf4c0ea9d3a078d9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5ffb043f86344413bbef3edc3e938d6b","IPY_MODEL_5472f4d0202641d3b5f1d5ab8bf0aca9","IPY_MODEL_24d5d784f6a44d508bd62a2e15f0f591"],"layout":"IPY_MODEL_910cbfb9e1184d1ba185bbee1ccff90d"}},"5ffb043f86344413bbef3edc3e938d6b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4f77a5f9392e48f2a946df5a58da7691","placeholder":"​","style":"IPY_MODEL_d704fd20ad60420c897f7d19f93ecbd0","value":"Downloading (…)cial_tokens_map.json: 100%"}},"5472f4d0202641d3b5f1d5ab8bf0aca9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_15b34314e8ba413db7d895d7bada4038","max":109,"min":0,"orientation":"horizontal","style":"IPY_MODEL_955d3fcd69e4462b82e742b8393e7232","value":109}},"24d5d784f6a44d508bd62a2e15f0f591":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_140de3d8f60a4784b9b3b5637a01b2d2","placeholder":"​","style":"IPY_MODEL_12ad4e7b59ee49068167acf613191cfb","value":" 109/109 [00:00&lt;00:00, 2.54kB/s]"}},"910cbfb9e1184d1ba185bbee1ccff90d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4f77a5f9392e48f2a946df5a58da7691":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d704fd20ad60420c897f7d19f93ecbd0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"15b34314e8ba413db7d895d7bada4038":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"955d3fcd69e4462b82e742b8393e7232":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"140de3d8f60a4784b9b3b5637a01b2d2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"12ad4e7b59ee49068167acf613191cfb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5e2af436a813410d99ca6df8beb50dbf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4577023b41394a1bbca8feed02376bde","IPY_MODEL_d4f6d755b2684ac391d4709295c97b4d","IPY_MODEL_8b6849bfd30a4ef8837310820b5901bc"],"layout":"IPY_MODEL_e7634e8495f84aa39954c43a3b704a2b"}},"4577023b41394a1bbca8feed02376bde":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6c3485544e53455e87eadb29b99771d2","placeholder":"​","style":"IPY_MODEL_5c2cecb6559a4e99acc4eeed2e5aa695","value":"Downloading (…)lve/main/config.json: 100%"}},"d4f6d755b2684ac391d4709295c97b4d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_11975e3389eb489784759ab33a3ecbaa","max":1199,"min":0,"orientation":"horizontal","style":"IPY_MODEL_180be3c52e1c4c1c953b31fe743e09bd","value":1199}},"8b6849bfd30a4ef8837310820b5901bc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d9c5c1f5989f4ab2a18b941cdcf49eef","placeholder":"​","style":"IPY_MODEL_5219b37ad9f14da6935c9ee8d15e57e7","value":" 1.20k/1.20k [00:00&lt;00:00, 26.9kB/s]"}},"e7634e8495f84aa39954c43a3b704a2b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c3485544e53455e87eadb29b99771d2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5c2cecb6559a4e99acc4eeed2e5aa695":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"11975e3389eb489784759ab33a3ecbaa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"180be3c52e1c4c1c953b31fe743e09bd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d9c5c1f5989f4ab2a18b941cdcf49eef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5219b37ad9f14da6935c9ee8d15e57e7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b842a58584f3444da6d79b3c2065ad2b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c13f80bd0ba440b9be72743a60b0fcc8","IPY_MODEL_a60a7383c8044b15b00dc6c2825695c5","IPY_MODEL_44cd9c5d914546b5a100c28d1e5b3394"],"layout":"IPY_MODEL_de684416484848f28d9fd205dca62cdd"}},"c13f80bd0ba440b9be72743a60b0fcc8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_580d2a93f1e344cbba55def1d1dfaf4e","placeholder":"​","style":"IPY_MODEL_dfc068c2702945f99524d4cb379c9fbd","value":"Downloading pytorch_model.bin: 100%"}},"a60a7383c8044b15b00dc6c2825695c5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_38c0983a15824bd4b1e849f3b2f0683f","max":495656447,"min":0,"orientation":"horizontal","style":"IPY_MODEL_13e05f3422d944989d93b7580a005f18","value":495656447}},"44cd9c5d914546b5a100c28d1e5b3394":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8e717e6ac826414aa95cb507b27b0001","placeholder":"​","style":"IPY_MODEL_71c2f4b2de3d4b79b659eb482baf85b8","value":" 496M/496M [00:06&lt;00:00, 77.0MB/s]"}},"de684416484848f28d9fd205dca62cdd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"580d2a93f1e344cbba55def1d1dfaf4e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dfc068c2702945f99524d4cb379c9fbd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"38c0983a15824bd4b1e849f3b2f0683f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"13e05f3422d944989d93b7580a005f18":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8e717e6ac826414aa95cb507b27b0001":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"71c2f4b2de3d4b79b659eb482baf85b8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}